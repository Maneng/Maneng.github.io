[{"title":"Implementing a Custom Spring AOP Annotation","date":"2017-06-18T14:55:13.900Z","path":"2017/06/18/Implementing a Custom Spring AOP Annotation/","text":"1. Introduction在本文中，我们将使用Spring中的AOP支持来实现自定义AOP注释。 首先，我们将对AOP进行高级概述，说明它是什么以及它的优点。接下来，我们将逐步实施注释，逐步建立对AOP概念的更深入的了解。 结果将是对AOP的更好理解和将来创建我们的定制Spring注释的能力。 2. What is an AOP Annotation?要快速总结，AOP代表面向方面的编程。基本上，它是一种在不修改该代码的情况下向现有代码添加行为的方式。 有关AOP的详细介绍，有关于AOP切入点和建议的文章。本文假设我们已经有了基础知识 我们将在本文中实现的AOP的类型是注释驱动的。如果我们使用了Spring @Transactional注释，我们可能已经熟悉了这一点： 1234@Transactionalpublic void orderGoods(Order order) &#123; // A series of database calls to be performed in a transaction&#125; 这里的关键是非侵略性。通过使用注解元数据，我们的核心业务逻辑不会被我们的交易代码污染。这使得更容易理解，重构和隔离测试。 有时，开发Spring应用程序的人可以将其看作是“弹性魔法”，而不必考虑如何运作。在现实中，发生的事情并不是特别复杂。但是，一旦我们完成了本文中的步骤，我们将能够创建自己的自定义注释，以了解和利用AOP。 3. Maven Dependency首先，我们添加我们的Maven依赖关系。 对于这个例子，我们将使用Spring Boot，因为它的配置方法的惯例让我们尽可能快地起床和运行： 123456789101112&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.2.RELEASE&lt;/version&gt;&lt;/parent&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 请注意，我们已经包括了AOP启动器，它引入了我们开始实现方面所需的库。 4. Creating our Custom Annotation我们要创建的注释是用于记录执行方法所需的时间量的注释。我们创建我们的注释： 12345@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface LogExecutionTime &#123; &#125; 虽然相对简单的实现，值得注意的是使用两个元注释。 @Target注释告诉我们我们的注释将适用于何处。在这里我们使用ElementType.Method，这意味着它只适用于方法。如果我们试图在其他地方使用注释，那么我们的代码将无法编译。这种行为是有道理的，因为我们的注释将用于记录方法执行时间。 而@Retention只是说明注释是否在运行时可用于JVM。默认情况下不是这样，所以Spring AOP将无法看到注释。这就是为什么它被重新配置。 5. Creating our Aspect现在我们有了我们的注释，我们来创建我们的方面。这只是封装我们交叉关切的模块，我们的方法是执行时间记录。它是一个类，用@Aspect注释： 12345@Aspect@Componentpublic class ExampleAspect &#123; &#125; 6. Creating our Pointcut and Advice现在，我们来创建我们的切入点和建议。这将是一个注释的方法，它存在于我们的方面： 1234@Around(\"@annotation(LogExecutionTime)\")public Object logExecutionTime(ProceedingJoinPoint joinPoint) throws Throwable &#123; return joinPoint.proceed();&#125; 从技术上讲，这并没有改变任何事情的行为，但仍然有很多需求分析。 首先，我们用@Around注释了我们的方法。这是我们的建议，围绕建议意味着我们在方法执行之前和之后添加额外的代码。还有其他类型的建议，例如前后，但这些建议将被排除在本文的范围之外。 接下来，我们的@Around注释有一个切点参数。我们的切入点只是说，’应用这个建议任何方法用@LogExecutionTime注释’。还有很多其他类型的切入点，但是如果范围，它们将再次被忽略。 方法logExecutionTime（）本身就是我们的建议。有一个参数，即ProceedingJoinPoint。在我们的例子中，这将是一个已经用@LogExecutionTime注释的执行方法。 最后，当我们的注释方法最终被调用时，会发生什么，我们的建议将被首先调用。那么由我们的建议决定下一步做什么。在我们的例子中，我们的建议是除了调用proceed（）之外什么也没做，只是调用原来的注释方法。 7. Logging our Execution Time现在我们有了我们的骨架，我们需要做的就是为我们的建议添加一些额外的逻辑。除了调用原始方法之外，这将记录执行时间。让我们再补充一点： 1234567891011@Around(\"@annotation(LogExecutionTime)\")public Object logExecutionTime(ProceedingJoinPoint joinPoint) throws Throwable &#123; long start = System.currentTimeMillis(); Object proceed = joinPoint.proceed(); long executionTime = System.currentTimeMillis() - start; System.out.println(joinPoint.getSignature() + \" executed in \" + executionTime + \"ms\"); return proceed;&#125; 再次，我们没有做任何在这里特别复杂的事情。我们刚刚记录了当前的时间，执行了该方法，然后打印出控制台所需的时间。我们还记录了使用连接点实例提供的方法签名。如果我们想要，我们也可以访问其他信息位，例如方法参数。 现在，让我们尝试用@LogExecutionTime注释一个方法，然后执行它来看看会发生什么。请注意，这必须是一个Spring Bean才能正常工作： 1234@LogExecutionTimepublic void serve() throws InterruptedException &#123; Thread.sleep(2000);&#125; 执行后，我们应该看到以下记录到控制台： void org.baeldung.Service.serve() executed in 2030ms 8. Conclusion在本文中，我们利用Spring Boot AOP创建自定义注释，我们可以将其应用于Spring bean，以便在运行时向其注入额外的行为。","tags":[{"name":"spring","slug":"spring","permalink":"http://yoursite.com/tags/spring/"}]},{"title":"Intro to AspectJ","date":"2017-06-18T14:49:42.156Z","path":"2017/06/18/Intro to AspectJ/","text":"1. Introduction本文是对AspectJ的一个快速实用的介绍。 首先，我们将展示如何启用面向方面的编程，然后我们将重点介绍编译时，后期编译和加载时织入之间的区别。 我们首先简要介绍面向方面的编程（AOP）和AspectJ的基础知识。 2. OverviewAOP是一种编程范式，旨在通过允许分离交叉关切来增加模块化。它通过在现有代码中添加附加行为，而不会修改代码本身。相反，我们单独声明要修改哪个代码。 AspectJ使用Java编程语言的扩展来实现关注和织入横切问题。 3. Maven DependenciesAspectJ根据其使用情况提供不同的库。我们可以在Maven Central存储库中的org.aspectj组下找到Maven依赖项。 在本文中，我们关注使用编译时，后期编译和织入加载时间创建方面所需的依赖关系。 3.1. AspectJ Runtime运行AspectJ程序时，类路径应包含与AspectJ运行时库aspectjrt.jar一起的类和方面： 12345&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjrt&lt;/artifactId&gt; &lt;version&gt;1.8.9&lt;/version&gt;&lt;/dependency&gt; 3.2. AspectJWeaver除了AspectJ运行时依赖之外，我们还需要包含aspectjweaver.jar来在加载时向Java类介绍建议： 12345&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.8.9&lt;/version&gt;&lt;/dependency&gt; 4. Aspect CreationAspectJ提供了AOP的实现，并有三个核心概念： Join Point Pointcut Advice 我们将通过创建一个简单的程序来验证用户帐户余额来演示这些概念。 首先，我们创建一个具有给定余额的帐户类和一种撤销方法： 1234567891011public class Account &#123; int balance = 20; public boolean withdraw(int amount) &#123; if (balance &lt; amount) &#123; return false; &#125; balance = balance - amount; return true; &#125;&#125; 我们将创建一个AccountAspect.aj文件来记录帐户信息并验证帐户余额（请注意，AspectJ文件以“.aj”文件扩展名结尾）：","tags":[{"name":"spring,aop","slug":"spring-aop","permalink":"http://yoursite.com/tags/spring-aop/"}]},{"title":"Spring BeanCreationException","date":"2017-06-13T06:35:17.661Z","path":"2017/06/13/Spring BeanCreationException/","text":"Spring BeanCreationException1.概述在这片文章中，我们会讨论关于Spring的异常： Spring org.springframework.beans.factory.BeanCreationException 当BeanFactory创建定义的bean的时候，本文中将会讨论这种常见的异常，以及它们解决方案。 2.Cause: org.springframework.beans.factory.NoSuchBeanDefinitionExceptionBeanCreationException最常见的原因是Spring试图注入上下文中不存在的bean。 例如，BeanA尝试注入BeanB： 1234567@Componentpublic class BeanA &#123; @Autowired private BeanB dependency; ...&#125; 如果在上下文中找不到BeanB，则会抛出以下异常（创建Bean时出错）： 1234567Error creating bean with name 'beanA': Injection of autowired dependencies failed; nested exception is org.springframework.beans.factory.BeanCreationException: Could not autowire field: private org.baeldung.web.BeanB org.baeldung.web.BeanA.dependency; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type [org.baeldung.web.BeanB] found for dependency: expected at least 1 bean which qualifies as autowire candidate for this dependency. Dependency annotations: &#123;@org.springframework.beans.factory.annotation.Autowired(required=true)&#125; 要诊断这种类型的问题 - 首先，确保bean被声明： 在使用&lt;bean /&gt;元素的XML配置文件中 或通过@Bean注解在Java @Configuration类中 或者注解为：@Component，@Repository，@Service，@Controller和类路径扫描对于该包是active的 还要检查配置文件或类真正正确的由Spring获取到并加载到主上下文中。 3.Cause:org.springframework.beans.factory.NoUniqueBeanDefinitionExceptionbean创建异常的另一个类似原因是Spring试图通过类型（即其接口）注入一个bean，并在上下文中找到两个或更多个bean来实现该接口。 例如，BeanB1和BeanB2都实现了相同的接口： 123456789101112@Componentpublic class BeanB1 implements IBeanB &#123; ... &#125;@Componentpublic class BeanB2 implements IBeanB &#123; ... &#125; @Componentpublic class BeanA &#123; @Autowired private IBeanB dependency; ...&#125; 这将导致Spring bean工厂抛出以下异常： 123456Error creating bean with name 'beanA': Injection of autowired dependencies failed; nested exception is org.springframework.beans.factory.BeanCreationException: Could not autowire field: private org.baeldung.web.IBeanB org.baeldung.web.BeanA.b; nested exception is org.springframework.beans.factory.NoUniqueBeanDefinitionException: No qualifying bean of type [org.baeldung.web.IBeanB] is defined: expected single matching bean but found 2: beanB1,beanB2 4. Cause: org.springframework.beans.BeanInstantiationException4.1 自定义异常123456789@Componentpublic class BeanA &#123; public BeanA() &#123; super(); throw new NullPointerException(); &#125; ...&#125; 如预期的那样，这将导致Spring很快的失败，并且抛出异常： 12345Error creating bean with name 'beanA' defined in file [...BeanA.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Could not instantiate bean class [org.baeldung.web.BeanA]: Constructor threw exception; nested exception is java.lang.NullPointerException 4.2 java.lang.InstantiationExceptionBeanInstantiationException的另一个可能的发生是将抽象类定义为XML中的bean;这必须在XML中，因为在Java @Configuration文件中没有办法这样做，而类路径扫描将忽略抽象类： 12@Componentpublic abstract class BeanA implements IBeanA &#123; ... &#125; bean的XML定义： 1&lt;bean id=\"beanA\" class=\"org.baeldung.web.BeanA\" /&gt; 此设置将导致类似异常： 1234567org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'beanA' defined in class path resource [beansInXml.xml]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Could not instantiate bean class [org.baeldung.web.BeanA]: Is it an abstract class?; nested exception is java.lang.InstantiationException 4.3. java.lang.NoSuchMethodException如果一个bean没有默认构造函数，并且Spring尝试通过查找该构造函数实例化它，这将导致运行时异常;例如： 12345678@Componentpublic class BeanA implements IBeanA &#123; public BeanA(final String name) &#123; super(); System.out.println(name); &#125;&#125; 当这个bean被类路径扫描机制获取时，将会导致： 12345Error creating bean with name 'beanA' defined in file [...BeanA.class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Could not instantiate bean class [org.baeldung.web.BeanA]: No default constructor found; nested exception is java.lang.NoSuchMethodException: org.baeldung.web.BeanA.&lt;init&gt;() 当类中的Spring依赖关系不具有相同的版本时，可能会出现类似异常但是更难诊断的异常是由于API更改，此类版本不兼容可能会导致NoSuchMethodException异常。解决这个问题的方法是确保所有的Spring库在项目中都有完全相同的版本。 6.org.springframework.beans.NotWritablePropertyException另一个可能性是定义一个bean - BeanA - 引用另一个Bean - BeanB–在BeanA中没有相应的setter方法： 1234567@Componentpublic class BeanA &#123; private IBeanB dependency; ...&#125;@Componentpublic class BeanB implements IBeanB &#123; ... &#125; Spring XML配置： 123&lt;bean id=\"beanA\" class=\"org.baeldung.web.BeanA\"&gt; &lt;property name=\"beanB\" ref=\"beanB\" /&gt;&lt;/bean&gt; 再次，这只能发生在XML配置中，因为在使用Java @Configuration时，编译器会使此问题无法再现。 当然，为了解决这个问题，需要为IBeanB添加setter： 12345678@Componentpublic class BeanA &#123; private IBeanB dependency; public void setDependency(final IBeanB dependency) &#123; this.dependency = dependency; &#125;&#125; 6.org.springframework.beans.CannotLoadBeanClassException当Spring无法加载定义的bean的类时，抛出此异常 - 如果Spring XML配置包含一个根本没有相应类的bean，则可能会发生此异常。例如，如果类BeanZ不存在，以下定义将导致异常： 1&lt;bean id=\"beanZ\" class=\"org.baeldung.web.BeanZ\" /&gt; 根本原因是ClassNotFoundException这种异常： 123456nested exception is org.springframework.beans.factory.BeanCreationException: ...nested exception is org.springframework.beans.factory.CannotLoadBeanClassException: Cannot find class [org.baeldung.web.BeanZ] for bean with name 'beanZ'defined in class path resource [beansInXml.xml]; nested exception is java.lang.ClassNotFoundException: org.baeldung.web.BeanZ 7.org.springframework.beans.Children of BeanCreationException7.1. The org.springframework.beans.factory.BeanCurrentlyInCreationExceptionBeanCreationException的子类之一是BeanCurrentlyInCreationException;这通常在使用构造函数注入时出现 - 例如，在循环依赖性的情况下： 1234567891011121314151617181920@Componentpublic class BeanA implements IBeanA &#123; private IBeanB beanB; @Autowired public BeanA(final IBeanB beanB) &#123; super(); this.beanB = beanB; &#125;&#125;@Componentpublic class BeanB implements IBeanB &#123; final IBeanA beanA; @Autowired public BeanB(final IBeanA beanA) &#123; super(); this.beanA = beanA; &#125;&#125; Spring将无法解决这种情况，最终的结果将是： 123org.springframework.beans.factory.BeanCurrentlyInCreationException: Error creating bean with name 'beanA': Requested bean is currently in creation: Is there an unresolvable circular reference? 完整的异常是非常冗长的： 1234567891011121314151617181920212223org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'beanA' defined in file [...BeanA.class]: Unsatisfied dependency expressed through constructor argument with index 0 of type [org.baeldung.web.IBeanB]: : Error creating bean with name 'beanB' defined in file [...BeanB.class]: Unsatisfied dependency expressed through constructor argument with index 0 of type [org.baeldung.web.IBeanA]: : Error creating bean with name 'beanA': Requested bean is currently in creation: Is there an unresolvable circular reference?; nested exception is org.springframework.beans.factory.BeanCurrentlyInCreationException: Error creating bean with name 'beanA': Requested bean is currently in creation: Is there an unresolvable circular reference?; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'beanB' defined in file [...BeanB.class]: Unsatisfied dependency expressed through constructor argument with index 0 of type [org.baeldung.web.IBeanA]: : Error creating bean with name 'beanA': Requested bean is currently in creation: Is there an unresolvable circular reference?; nested exception is org.springframework.beans.factory.BeanCurrentlyInCreationException: Error creating bean with name 'beanA': Requested bean is currently in creation: Is there an unresolvable circular reference? 7.2. The org.springframework.beans.factory.BeanIsAbstractException当Bean Factory尝试检索和实例化被声明为抽象的bean时，可能会发生此实例化异常。例如： 123public abstract class BeanA implements IBeanA &#123; ...&#125; 在XML配置中声明为： 1&lt;bean id=\"beanA\" abstract=\"true\" class=\"org.baeldung.web.BeanA\" /&gt; 现在，如果我们尝试通过名称从Spring上下文中检索BeanA，例如实例化另一个bean： 1234567891011@Configurationpublic class Config &#123; @Autowired BeanFactory beanFactory; @Bean public BeanB beanB() &#123; beanFactory.getBean(\"beanA\"); return new BeanB(); &#125;&#125; 这将导致以下异常： 12345678org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'beanB' defined in class path resource [org/baeldung/spring/config/WebConfig.class]: Instantiation of bean failed; nested exception is org.springframework.beans.factory.BeanDefinitionStoreException: Factory method [public org.baeldung.web.BeanB org.baeldung.spring.config.WebConfig.beanB()] threw exception; nested exception is org.springframework.beans.factory.BeanIsAbstractException: Error creating bean with name 'beanA': Bean definition is abstract 8.总结 …在本文末尾，我们应该有一个清晰的地图来浏览可能导致Spring中的BeanCreationException异常的原因和问题，以及如何解决所有这些问题。 在Github项目中可以找到一些这些例外示例的实现这是一个基于Eclipse的项目，所以应该很容易导入和运行。","tags":[{"name":"springException","slug":"springException","permalink":"http://yoursite.com/tags/springException/"}]},{"title":"初探RxJS","date":"2017-05-26T08:31:47.113Z","path":"2017/05/26/初探RxJS/","text":"什么是RxJsRxJS是一个JavaScript库，将“反应式编程”的概念带入网络。 反应式编程只是构建软件应用程序的另一种方法。本质上，您的软件是为了对发生的变化进行“反应”（例如点击事件，获取的数据等），而不是典型的编写我们明确编写代码（也称为“命令式”编程）的软件来处理这些更改。对于熟悉的人，您可以将RxJS视为异步数据操作的lodash。 如果你仍然感到困惑，别担心，这通常没有什么意义。让我们用类比来更好地解释一下： 1RxJS is to Javascript as Henry Ford's assembly line was to cars. RxJS是为了像亨利·福特的装配线一样用于汽车。 我知道这听起来很棒，但是听到我的声音。 早在二十世纪初，产品完全由手工制造。所以任何产生的产品 - 让我们以座椅为例 - 是由一个人建造的。要做椅子，这个人会把木头切成适当的尺寸。然后，他们将这些块拼合在一起，将粗糙的边缘砂磨。然后他们会画它，完成它，最后卖掉它。然后他们将重复从步骤1的过程。 这可能听起来不是那么糟糕，但是考虑一下：定制颜色的椅子会花多少钱？你会认为这不会太多，对吧？实际上是相反的 - 不仅你会为自己的颜色付钱，而且你必须付钱给那个人整天坐下来，为你创造一个全新的椅子。所以你在宜家买的20美元的椅子可能会花费200美元以上。 为什么？因为这是不被分解成模块化和异步进程的系统的成本。 当亨利·福特（Henry Ford）批量生产第一辆燃烧车的时候，他有一个辉煌的想法：如果你将装配过程分解成由单人负责的模块化件？这样，大会的每一部分都是可以互换的，也消除了一个人负责创造整个汽车的巨大的低效率。事实上，一个人在一个12小时内搭建了一辆满车，他的装配线减少了两个半小时。 这也打开了通常成本高昂的定制和配置级别。例如，如果客户想要汽车的不同颜色的内部，那么他们可以简单地将完成的灯箱重定向到不同的工作人员。 装配线提供了两个主要优点：工人能够异步工作（导致完成所需的总工作时间大大减少），现在重新配置/定制最终产品将是非常便宜的。 1In this sense, RxJS (and reactive programming in general) can be thought of as writing assembly lines in your software applications. It allows you to write software that is reusable, configurable, and asynchronous. 在这个意义上，RxJS（一般说响应式编程）可以被认为是在您的软件应用程序中编写装配线。它允许您编写可重复使用，可配置和异步的软件。 我认为这里的关键词是异步的。大多数库/框架已经允许您编写可重用且可配置的代码，但可以从异步操作中轻松调用？例如，如果我们正在等待聊天消息从网络套接字回来，新聊天消息如何更新正在运行的应用程序的状态？如果你已经建立了一个有意义的大型实时应用程序，那么你知道写这种逻辑可能是多么痛苦。 虽然websockets和其他实时事件是RxJS真正闪耀的地方，但RxJS还提供了更强大的功能来执行甚至标准的AJAX请求。与promises（解决AJAX请求的正常方法）不同，RxJS的Observable序列是可以取消的。它们也可以轻松链接，操纵和配置。 1The possibilities are endless. You can create assembly lines (i.e. RxJS Observables) that can be chained together, split apart, configured slightly different, or just used without any modification at all. It's really up to you. 可能性是无止境的。您可以创建可以链接在一起，拆分，配置稍微不同或刚刚使用而不进行任何修改的装配线（即RxJS Observables）。这真的取决于你 就这样说，现在我们来探讨一些真正的RxJS和Observables的例子！ 重要的是覆盖RxJS包含的基本术语及其相应的功能，然后再继续实例。在上面的视频中，我们介绍了marble diagrams的可观察序列的总体思路，以及以下主题与之相互作用。 Observer 您通常不会直接与Observer对象进行交互，因为您可能会与主题进行交互（我们将在下面介绍），但重要的是要知道它的作用。 观察者允许您将新数据“推”到可观察的序列中。您可以将其视为修改可观察序列的“只写”方式（要回到我们类似的装配线，观察者只能将新车添加到装配线上）。 Observable 一个可观察的是我们可以用来听，又名订阅，也就是发现一个观察者发出的新的变化。将其视为“只读”装配线（只能观察新车从装配线中脱落）。 Subject 主题只是一个观察者和可观察者。您可以推新值并订阅。将其视为“读写”装配线（您可以将车辆添加到装配线上，观察从装配线下车的车辆）。 Operators RxJS中的运算符的目的与其他编程语言/库中的大多数运算符相同：它们允许您对代码执行操作。 在RxJS中，您可以将运算符视为在发送到Observable之前操纵来自主题（或观察者）的数据的一种方法。这相当于指示装配线以某种方式修改汽车（即涂漆黑色，闪耀等），然后将其返回到下一个装配线。 在RxJS中有一些不同类型的主题，但是在构建真实世界应用程序时弹出的最常见的主题是BehaviorSubject。 假设我们想要存储用户的名字，但是我们也希望他们能够更改它。我们想要存储一个初始名称，有能力更新它，并且还可以在任何给定的时间访问当前的名称设置。 这正是BehaviorSubject允许你做的事情。让我们看看这个例子的用例实际上是如何工作的： 使用初始值实例化一个新的BehaviorSubject 在这个例子中，初始值将是一个字符串（Eric） 1let currentNameSubject = new BehaviorSubject('Eric'); 要获取当前值，请调用getValue方法： 12currentNameSubject.getValue();// =&gt; 'Eric' 要更改现有BehaviorSubject的值，请使用新值调用下一个方法： 1currentNameSubject.next('Obama'); 如果我们再次调用getValue： 12currentNameSubject.getValue();// =&gt; 'Obama' 订阅值的变动使用RxJS的全部要点是跨应用程序异步更新和共享数据。这是通过订阅Observable而不是同步调用getValue完成的： 123456789101112let currentNameSubject = new BehaviorSubject('Eric');currentNameSubject.subscribe((val) =&gt; &#123; console.log(val);&#125;)// =&gt; 'Eric'currentNameSubject.next('Obama');// =&gt; 'Obama'currentNameSubject.next('Jacob');// =&gt; 'Jacob' 在RxJS世界中，被认为是最佳实践，仅将Subjects暴露给您的应用程序的部分，将新数据添加到Observable序列中。这只是允许对您的应用程序，私人和公共类成员等的某些部分进行写入访问的相同想法。 要从主题创建一个Observable，您可以在任何主题上简单地调用asObservable： 12let currentUserSubject = new BehaviorSubject&lt;string&gt;('Eric');let currentUser = currentUserSubject.asObservable(); 我们现在有一个名为currentUser的新变量，它是currentUserSubject的可观察序列的可观察值。要看看它是如何工作的，可以订阅currentUser observable，然后将一些数据添加到currentUserSubject： 12345678910let currentUserSubject = new BehaviorSubject&lt;string&gt;('Eric');let currentUser = currentUserSubject.asObservable();currentUserSubject.subscribe((val) =&gt; &#123; console.log(val)&#125;)// =&gt; 'Eric'currentUserSubject.next('hello');// =&gt; 'hello' 请注意，如果您尝试调用currentUser.next（），它将抛出一个错误，因为Observables只能观察序列 - 从而为您提供只读访问currentUserSubject Making our first HTTP request向API发出请求，使用observable来映射和返回数据 就像Angular 1.x一样，建议Http调用包含在服务中，而不是直接在组件中使用。这可以为您的应用程序结构提供更大的灵活性，因为您可以在整个应用程序中重用您的呼叫，以及实现更高级功能（如缓存）的能力。 要使用Http服务，我们需要（你猜到它）import＆并注入它： 12345678910111213141516import &#123; Injectable &#125; from '@angular/core';import &#123; Http, Response &#125; from '@angular/http';import 'rxjs/add/operator/map';@Injectable()export class UserService &#123; constructor ( private http: Http ) &#123;&#125; getUser() &#123; return this.http.get(`https://conduit.productionready.io/api/profiles/eric`) .map((res:Response) =&gt; res.json()); &#125;&#125; 我们需要从rxjs导入map才能使用地图运算符。 $ http从Angular 1.x和Http在Angular 2之间有一些区别。Http返回一个Observable与Response对象，而$ http返回Promises。 Promises和Observables之间的主要区别在于Observables可能会多次发布数据，这就是为什么它们可以被订阅和取消订阅。 $ http和Http之间的另一个主要区别是Http实际上没有向服务器发出请求，直到有一个订阅observable。 虽然可观察是在angular2处理数据的推荐方法，您可以通过导入rxjs / add / operator / toPromise然后调用您的observable的Promise（）将它们转换为promises。起初我发现自己想要使用像Angular 1的好日子这样的承诺，但是我最终发现Observables实际上是相当不错的，与你写承诺代码的方式没有太大的不同。 getUser方法从服务器上关闭对我的配置文件信息的GET请求。当数据回来时，我们使用map操作符来获取响应数据，将其转换为JSON，然后将其重新输入到等待数据解析的任何订阅者。 在home组件中，允许订阅该Observable并将返回给组件中的profile变量的数据分配： 123456789101112131415161718192021import &#123; Component &#125; from '@angular/core';import &#123; UserService &#125; from './shared/index';@Component(&#123; selector: 'home-page', template: ` &lt;div&gt; &lt;button (click)=\"loadUser()\"&gt;Load profile&lt;/button&gt; &#123;&#123; profile | json &#125;&#125; &lt;/div&gt; `&#125;)export class HomeComponent &#123; constructor(private userService: UserService) &#123;&#125; profile = &#123;&#125;; loadUser() &#123; this.userService.getUser().subscribe(data =&gt; this.profile = data); &#125;&#125;","tags":[{"name":"Rxjs","slug":"Rxjs","permalink":"http://yoursite.com/tags/Rxjs/"}]},{"title":"陌生单词笔记本","date":"2017-05-23T03:09:38.984Z","path":"2017/05/23/陌生单词笔记本/","text":"Robust 强大的 definitive 确定的 security landscape（风景，风景，山水） 安全形势 two-factor authentication 双因素认证 solid 坚实 alternative 可以供选择的 debate 争论 intelligently 智能的 properly 正确的 tactics 策略、 fluent 连贯 endpoint 端点 enforce 实施 强制 执行 encapsulate 封装 interchangeable 可交换的 Strategy 策略 vary 变化 DelegatingFilterProxy 委托过滤代理 hierarchies 阶层; 层次; 层次结构 outlines 概述 application 应用程式 应用、应用程序application framework 应用程式框架、应用框架 应用程序框架architecture 架构、系统架构 体系结构argument 参数（传给函式的值）。array 阵列 数组arrow operator arrow（箭头）运算子 箭头操作符assembly 装配件assembly language 组合语言 汇编语言assert(ion) 断言assign 指派、指定、设值、赋值 赋值assignment 指派、指定 赋值、分配assignment operator 指派（赋值）运算子 = 赋值操作符associated 相应的、相关的 相关的、关联、相应的associative container 关联式容器（对应 sequential container）关联式容器atomic 不可分割的 原子的attribute 属性 属性、特性audio 音讯 音频A.I. 人工智慧 人工智能 background 背景 背景（用於图形着色）後台（用於行程）backward compatible 回溯相容 向下兼容bandwidth 频宽 带宽base class 基础类别 基类base type 基础型别 (等同於base class) batch 批次（意思是整批作业） 批处理benefit 利益 收益best viable function 最佳可行函式 最佳可行函式binary search 二分搜寻法 二分查找binary tree 二元树 二叉树binary function 二元函式 双叁函数binary operator 二元运算子 二元操作符binding 系结 绑定bit 位元 位bit field 位元栏 位域bitmap 位元图 位图bitwise 以 bit 为单元逐一bitwise copy 以 bit 为单元进行复制；位元逐一复制 位拷贝block 区块,区段 块、区块、语句块boolean 布林值（真假值，true 或 false）布尔值border 边框、框线 边框brace(curly brace) 大括弧、大括号 花括弧、花括号bracket(square brakcet) 中括弧、中括号 方括弧、方括号breakpoint 中断点 断点build 建造、构筑、建置（MS 用语）build－in 内建 内置bus 汇流排 总线business 商务,业务 业务buttons 按钮 按钮byte 位元组（由 8 bits 组成） 字节 cache 快取 高速缓存call 呼叫、叫用 调用callback 回呼 回调call operator call（函式呼叫）运算子调用操作符candidate function 候选函式 候选函数chain 串链（例 chain of function calls） 链character 字元 字符check box 核取方块 (i.e. check button) 复选框checked exception 可控式异常check button 方钮 (i.e. check box) 复选按钮child class 子类别（或称为derived class, subtype） 子类class 类别 类class body 类别本体 类体class declaration 类别宣告、类别宣告式 类声明class definition 类别定义、类别定义式 类定义class derivation list 类别衍化列 类继承列表class head 类别表头 类头class hierarchy 类别继承体系, 类别阶层 类层次体系class library 类别程式库、类别库 类库class template 类别模板、类别范本 类模板class template partial specializations 类别模板偏特化 类模板部分特化class template specializations 类别模板特化 类模板特化cleanup 清理、善後 清理、清除client 客端、客户端、客户 客户client－server 主从架构 客户/服务器clipboard 剪贴簿 剪贴板clone 复制 克隆collection 群集 集合combo box 复合方块、复合框 组合框command line 命令列 命令行(系统文字模式下的整行执行命令)communication 通讯 通讯compatible 相容 兼容compile time 编译期 编译期、编译时compiler 编译器 编译器component 组件 组件composition 复合、合成、组合 组合computer 电脑、计算机 计算机、电脑concept 概念 概念concrete 具象的 实在的concurrent 并行 并发configuration 组态 配置connection 连接，连线（网络,资料库） 连接constraint 约束（条件）construct 构件 构件container 容器 容器(存放资料的某种结构如 list, vector…）containment 内含 包容context 背景关系、周遭环境、上下脉络 环境、上下文control 控制元件、控件 控件console 主控台 控制台const常数（constant 的缩写，C++ 关键字）constant 常数（相对於 variable） 常量constructor（ctor） 建构式 构造函数（与class 同名的一种 member functions）copy (v) 复制、拷贝 拷贝copy (n) 复件, 副本cover 涵盖 覆盖create 创建、建立、产生、生成 创建creation 产生、生成 创建cursor 游标 光标custom 订制、自定 定制 data 资料 数据database 资料库 数据库database schema 数据库结构纲目data member 资料成员、成员变数 数据成员、成员变量data structure 资料结构 数据结构datagram 资料元 数据报文dead lock 死结 死锁debug 除错 调试debugger 除错器 调试器declaration 宣告、宣告式 声明deduction 推导（例：template argument deduction） 推导、推断default 预设 缺省、默认defer 延缓 推迟define 定义 预定义definition 定义、定义区、定义式 定义delegate 委派、委托、代理delegation （同上）demarshal 反编列 散集dereference 提领（取出指标所指物体的内容） 解叁考dereference operator dereference（提领）运算子 * 解叁考操作符derived class 衍生类别 派生类design by contract 契约式设计design pattern 设计范式、设计样式 设计模式destroy 摧毁、销毁destructor 解构式 析构函数device 装置、设备 设备dialog 对话窗、对话盒 对话框directive 指令（例：using directive） (编译)指示符directory 目录 目录disk 碟 盘dispatch 分派 分派distributed computing 分布式计算 (分布式电算) 分布式计算 分散式计算 (分散式电算)document 文件 文档dot operator dot（句点）运算子 . (圆)点操作符driver 驱动程式 驱动（程序）dynamic binding 动态系结 动态绑定 efficiency 效率 效率efficient 高效 高效end user 终端用户entity 物体 实体、物体encapsulation 封装 封装enclosing class外围类别（与巢状类别 nested class 有关）外围类enum (enumeration) 列举（一种 C++ 资料型别） 枚举enumerators 列举元（enum 型别中的成员） 枚举成员、枚举器equal 相等 相等equality 相等性 相等性equality operator equality（等号）运算子 == 等号操作符equivalence 等价性、等同性、对等性 等价性equivalent 等价、等同、对等 等价escape code 转义码 转义码evaluate 评估、求值、核定 评估event 事件 事件event driven 事件驱动的 事件驱动的exception 异常情况 异常exception declaration 异常宣告（ref. C++ Primer 3/e, 11.3）异常声明exception handling 异常处理、异常处理机制 异常处理、异常处理机制exception specification 异常规格（ref. C++ Primer 3/e, 11.4）异常规范exit 退离（指离开函式时的那一个执行点） 退出explicit 明白的、明显的、显式 显式export 汇出 引出、导出 facility 设施、设备 设施、设备feature 特性field 栏位,资料栏（Java） 字段, 值域（Java）file 档案 文件firmware 韧体 固件flag 旗标 标记flash memory 快闪记忆体 闪存flexibility 弹性 灵活性flush 清理、扫清 刷新font 字型 字体form 表单（programming 用语） 窗体formal parameter形式叁数 形式叁数forward declaration 前置宣告 前置声明forwarding 转呼叫,转发 转发forwarding function 转呼叫函式,转发函式 转发函数fractal 碎形 分形framework 框架 框架full specialization 全特化（ref. partial specialization）function 函式、函数 函数function call operator 同call operator function object 函式物件（ref. C++ Primer 3/e, 12.3） 函数对象function overloaded resolution 函式多载决议程序 函数重载解决（方案）functionality 功能、机能 功能function template 函式模板、函式范本 函数模板functor 仿函式 仿函式、函子 game 游戏 游戏generate 生成generic 泛型、一般化的 一般化的、通用的、泛化generic algorithm 泛型演算法 通用算法getter (相对於 setter) 取值函式global 全域的（对应於 local） 全局的global object 全域物件 全局对象global scope resolution operator 全域生存空间（范围决议）运算子 :: 全局范围解析操作符group 群组group box 群组方块 分组框guard clause 卫述句 (Refactoring, p250) 卫语句GUI 图形介面 图形界面 hand shaking 握手协商handle 识别码、识别号、号码牌、权柄 句柄handler 处理常式 处理函数hard－coded 编死的 硬编码的hard－copy 硬拷图 屏幕截图hard disk硬碟 硬盘hardware 硬体 硬件hash table 杂凑表 哈希表、散列表header file 表头档、标头档 头文件heap 堆积 堆hierarchy 阶层体系 层次结构（体系）hook 挂钩 钩子hyperlink 超链结 超链接 icon 图示、图标 图标IDE 整合开发环境 集成开发环境identifier 识别字、识别符号 标识符if and only if 若且唯若 当且仅当Illinois 伊利诺 伊利诺斯image 影像 图象immediate base 直接的（紧临的）上层 base class。 直接上层基类immediate derived 直接的（紧临的）下层 derived class。 直接下层派生类immutability 不变性immutable 不可变（的）implement 实作、实现 实现implementation 实作品、实作体、实作码、实件 实现implicit 隐喻的、暗自的、隐式 隐式import 汇入 导入increment operator 累加运算子 ++ 增加操作符infinite loop 无穷回圈 无限循环infinite recursive 无穷递回 无限递归information 资讯 信息infrastructure 公共基础建设inheritance 继承、继承机制 继承、继承机制inline 行内 内联inline expansion 行内展开 内联展开initialization 初始化（动作） 初始化initialization list 初值列 初始值列表initialize 初始化 初始化inner class 内隐类别 内嵌类instance 实体 实例（根据某种表述而实际产生的「东西」）instantiated 具现化、实体化（常应用於 template） 实例化instantiation 具现体、具现化实体（常应用於 template） 实例integer (integral) 整数（的） 整型（的）integrate 整合 集成interacts 交谈、互动 交互interface 介面 接口interpreter 直译器 解释器invariants 恒常性,约束条件 约束条件invoke 唤起 调用iterate迭代（回圈一个轮回一个轮回地进行） 迭代iterative 反覆的，迭代的iterator 迭代器（一种泛型指标） 迭代器iteration 迭代（回圈每次轮回称为一个 iteration） 迭代item 项目、条款 项、条款、项目laser 雷射 激光level 阶 层 (级) 例 high level 高阶 高层library 程式库、函式库 库、函数库lifetime 生命期、寿命 生命期、寿命link 联结、连结 连接,链接linker 联结器、连结器 连接器literal constant 字面常数（例 3.14 或 “hi” 这等常数值） 字面常数list 串列（linked－list） 列表、表、链表list box 列表方块、列表框 列表框 load 载入 装载loader 载入器 装载器、载入器local 区域的（对应於 global） 局部的local object 区域物件 局部对象lock 机锁loop 回圈 循环lvalue 左值 左值 macro 巨集 宏magic number 魔术数字 魔法数maintain 维护 维护manipulator 操纵器（iostream 预先定义的一种东西） 操纵器marshal 编列 列集叁考demarshal mechanism 机制 机制member 成员 成员member access operator 成员取用运算子（有 dot 和 arrow 两种） 成员存取操作符member function 成员函式 成员函数member initialization list 成员初值列 成员初始值列表memberwise 以 member 为单元┅、members 逐一┅ 以成员为单位memberwise copy 以 members 为单元逐一复制memory 记忆体 内存menu 表单、选单 菜单message 讯息 消息message based 以讯息为基础的 基於消息的message loop 讯息回圈 消息环method 方法、行为、函式 方法meta－ 超－ 元－meta－programming 超编程 元编程micro 微 微middleware 中介层 中间件modeling 模塑modeling language 塑模语言，建模语言modem 数据机 调制解调器module 模组 模块modifier 饰词 修饰符most derived class 最末层衍生类别 最底层的派生类mouse 滑鼠 鼠标mutable可变的 可变的multi－tasking 多工 多任务 namespace 命名空间 名字空间、命名空间native 原生的 本地的、固有的nested class 巢状类别 嵌套类network 网路 网络network card 网路卡 网卡 object 物件 对象object based 以物件为基础的 基於对象的object file 目的档 目标文件object model 物件模型 对象模型object oriented 物件导向的 面向对象的online 线上 在线opaque 不透明的operand 运算元 操作数operating system (OS) 作业系统 操作系统operation 操作、操作行为 操作operator 运算子 操作符、运算符option 选项，可选方案 选项ordinary 常规的 常规的overflow 上限溢位（相对於 underflow） 溢出（underflow:下溢）overhead 额外负担、额外开销 额外开销overload 多载化、多载化、重载 重载overloaded function 多载化函式 重载的函数overloaded operator 多载化运算子 被重载的操作符overloaded set 多载集合 重载集合override 改写、覆写 重载、改写、重新定义（在 derived class 中重新定义虚拟函式) package 套件 包pair 对组palette 调色盘、组件盘、工具箱pane 窗格 窗格parallel 平行 并行parameter 叁数（函式叁数列上的变数） 叁数、形式叁数、形叁parameter list 叁数列 叁数列表parent class 父类别（或称 base class） 父类parentheses 小括弧、小括号 圆括弧、圆括号parse 解析 解析part 零件 部件partial specialization 偏特化（ref. C++ Primer 3/e, 16.10）局部特化pass by address 传址（函式引数的传递方式）（非正式用语）传地址pass by reference 传址（函式引数的一种传递方式） 传地址, 按引用传递pass by value 传值（函式引数的一种传递方式） 按值传递pattern 范式、样式 模式performance 效率、性能兼而有之 性能persistence 永续性 持久性pixel 图素、像素 像素platform 平台 平台pointer 指标 指针址位器（和址叁器 reference 形成对映，满好）poll 轮询 轮询polymorphism 多型 多态pop up 冒起式、弹出式 弹出式port 埠 端口postfix 後置式、後序式 後置式precedence 优先序（通常用於运算子的优先执行次序）prefix 前置式、前序式 前置式preprocessor 前处理器 预处理器prime 质数 素数primitive type 基本型别 (不同於 base class,基础类别)print 列印 打印printer 印表机 打印机priority 优先权 (通常用於执行绪获得 CPU 时间的优先次序）procedure 程序 过程procedural 程序性的、程序式的 过程式的、过程化的process 行程 进程profile 评测 评测profiler 效能（效率）评测器 效能（性能）评测器programmer 程式员 程序员programming 编程、程式设计、程式化 编程progress bar 进度指示器 进度指示器project 专案 项目、工程property 属性protocol 协定 协议pseudo code 假码、虚拟码、伪码 伪码 qualified 经过资格修饰（例如加上 scope 运算子） 限定qualifier 资格修饰词、饰词 限定修饰词quality 品质 质量queue 伫列 队列 radian 径度 弧度radio button 圆钮 单选按钮raise 引发（常用来表示发出一个 exception） 引起、引发random number 随机数、乱数 随机数range 范围、区间（用於 STL 时） 范围、区间rank 等级、分等（ref. C++Primer 3/e 9,15章） 等级raw 生鲜的、未经处理的 未经处理的record 记录 记录recordset 记录集 记录集recursive 递回 递归re－direction 重导向 重定向refactoring 重构、重整 重构refer 取用 叁考refer to 指向、指涉、指代reference 引用、叁考 址叁器,see pointer register 暂存器 寄存器reflection 反射 反射、映像relational database 关联式资料库 关系数据库represent 表述，表现 表述，表现resolve 决议（为算式中的符号名称寻找 解析对应之宣告式的过程）resolution 决议程序、决议过程 解析过程resolution 解析度 分辨率restriction 局限return 传回、回返 返回return type 回返型别 返回类型return value 回返值 返回值robust 强固、稳健 健壮robustness 强固性、稳健性 健壮性routine 常式 例程runtime 执行期 运行期、运行时common language runtime (CLR) 译为「通用语言执行层」rvalue 右值 右值 save 保存savepoint 保存点SAX (Simple API for XML)scalable 可伸缩的、可扩展的schedule 调度scheduler 调度程序schema 模式、纲目结构scroll bar 滚动条scope 作用域、生存空间scope operator 生存空间操作符scope resolution operator 生存空间解析操作符screen 屏幕SDK (Software Development Kit) 软件开发包sealed class 密封类search 查找semantics 语义semaphore 信号量sequential container序列式容器server 服务器、服务端serial 串行serialization/serialize 序列化server cursor 服务端游标、服务器游标session 会话setter 设值函数shared lock 共享锁sibling 同级side effect 副作用signature 签名single-threaded 单线程slider 滑块slot 槽smart pointer 智能指针SMTP (Simple Mail Transfer Protocol) 简单邮件传输协议snapshot 截屏图snapshot 快照specialization 特化specification 规范、规格splitter 切分窗口SOAP (simple object access protocol) 简单对象访问协议software 软件source code 源码、源代码SQL (Structured Query Language) 结构化查询语言stack 栈、堆栈stack unwinding 叠辗转开解(此词用于exception主题)standard library 标准库standard template library 标准模板库stateless 无状态的statement 语句、声明static cursor 静态游标static SQL statements 静态SQL语句stored procedure 存储过程status bar 状态条stream 流string 字符串stub 存根subobject 子对象subquery 子查询subroutine 子例程subscript operator 下标操作符subset 子集subtype 子类型support 支持suspend 挂起symbol 记号syntax 语法system databases 系统数据库system tables 系统表 tag标签 标记 索引标签,页签target 标的（例 target pointer：标的指标） 目标task switch 工作切换 任务切换template 模板、范本 模板template argument deduction 模板引数推导 模板叁数推导template explicit specialization 模板显式特化（版本） 模板显式特化template parameter 模板叁数 模板叁数temporary object 暂时物件 临时对象text文字 文本text file 程式本文档（放置程式原始码的档案） 文本文件thread 执行绪 线程thread safe 多绪安全 多线程安全throw 丢掷（常指发出一个 exception） 丢掷、引发token 语汇单元 符号、标记transaction 交易 事务transaction log 事务日志transaction rollback 事务回滚transactional replication 事务复制translation unit 翻译单元transparent(ly) 透通的(地)traverse 巡访（来回走动） 遍历trigger 触发 触发type 型别 类型table 表table lock 表锁table-level constraint 表级约束tape backup 磁带备份task switch 工作切换TCP (Transport Control Protocol) 传输控制协议temporary table 临时表thin client 瘦客户端third-party 第三方trace 跟踪traverse 遍历two-phase commit 两阶段提交tupletwo-phase lookup 两阶段查找 UML unified modeling language 统一建模语言unary function 一元函式 单叁函数unary operator 一元运算子 一元操作符underflow 下限溢位（相对於 overflow） 下溢unchecked exception 不可控异常unqualified 未经资格修饰（而直接取用）user 使用者、用户 用户user interface 使用者界面、用户界面、人机界面UDDI(Universary Description, Discovery and Integration)统一描述、查询与集成unboxing 拆箱、拆箱转换Union query 联合查询UNIQUE constraints UNIQUE约束unique index 唯一索引unmanaged code 非受控代码、非托管代码unmarshal 散集unqualified 未经限定的、未经修饰的URI (Uniform Resource identifier) 统一资源标识符URL (Uniform Resource Locator) 统一资源定位器 variable 变数（相对於常数 const） 变量vector 向量（一种容器，有点类似 array） 向量、矢量viable 可实行的、可行的 可行的viable function 可行函式 可行函数video 视讯 视频view (1) 视图(document/view) 文档/视图virtual function 虚拟函式 虚函数virtual machine 虚拟机器 虚拟机virtual memory虚拟记忆体 虚内存, 虚存volatile 易挥发的、易变的vowel 母音 元音字母 window 视窗 窗口window function 视窗函式 窗口函数window procedure 视窗函式 窗口过程word 字 单词word processor 文书处理器 字处理器wrapper 外覆、外包 包装Web Services web 服务WHERE clause WHERE子句wildcard characters 通配符字符wildcard search 通配符搜索Windows authentication Windows 身份验证wizard 向导write enable 写启用write-ahead log 预写日志write-only 只写WSDL (Web Service Description Language)Web Service 描述语言 XML (eXtensible Markup Language) 可扩展标记语言XSD (XML Schema Definition) XML 模式定义语言XSL (eXtensible Stylesheet Language) 可扩展样式表语言XSLT (eXtensible Stylesheet Language Transformation)可扩展样式表语言转换xxx based 基于xxx的xxx oriented 面向xxxXML (eXtensible Markup Language) 可扩展标记语言","tags":[{"name":"english learn","slug":"english-learn","permalink":"http://yoursite.com/tags/english-learn/"}]},{"title":"设计模式","date":"2017-05-20T03:42:48.025Z","path":"2017/05/20/设计模式/","text":"设计模式总结什么是设计模式设计模式是从许多优秀的软件系统中总觉出成功的可复用的设计方案。 每一个设计模式描述一个在我们周围不断重复发生的问题，以及该为题的解决方案的核心，这样，你就可以一次一次的使用该方案而不必做重复的劳动。 by – Alexander 建筑大师 尽管Alwxander 所指的是城市和建筑的设计模式，但他的思想也同样适用于面向对象设计模式，只是在面向对象的解决方案里，我们用对象和接口代替了墙壁和门窗。 记录一个设计模式需有四个基本的要素： 名称 问题 方案 效果 例如: 中介者模式： 名称 中介者 问题 用一个中介者来封装一系列的对象交互，中介者使各种对象不需要显示的相互引用，从而使其耦合松散，而且可以独立地改变他们之间的交互。 方案 中介者（Mediator） 接口，具体中介者（Concerte Mediator），同事（Colleague），具体同事（Concrete Colleagure） 效果 减少了子类的生成，将各个同事解耦，简化了对象的协议，控制集中化。 软件领域的设计模式起源于建筑学，一个好的设计系统往往是易维护，易扩展，易复用的。 什么是框架 框架不是模式，框架是针对某个领域，提供用于开发应用系统的类的集合，程序设计者可以使用框架提供的类设计一个应用程序，而且在设计应用程序时可以针对特定的问题使用某个模式。 面向对象的几个基本的原则 抽象类和接口 面向抽象所谓面向抽象编程，是指当设计一个类时，不让该类面向具体的类，而是面向抽象类或者接口，即所设计类中的重要数据是抽象类或接口声明的变量，而不是具体类声明的变量。3.开闭原则让设计对扩展开放，对修改关闭。4.多用组合少用继承原则5.高内聚-低耦合原则 在软件工程中，设计模式（design pattern）是对软件设计中普遍存在（反复出现）的各种问题，所提出的解决方案。这个术语是由埃里希·伽玛（Erich Gamma）等人在1990年代从建筑设计领域引入到计算机科学的。 设计模式并不直接用来完成代码的编写，而是描述在各种不同情况下，要怎么解决问题的一种方案。 面向对象设计模式通常以类或对象来描述其中的关系和相互作用，但不涉及用来完成应用程序的特定类或对象。设计模式能使不稳定依赖于相对稳定、具体依赖于相对抽象，避免会引起麻烦的紧耦合，以增强软件设计面对并适应变化的能力。 并非所有的软件模式都是设计模式，设计模式特指软件“设计”层次上的问题。还有其它非设计模式的模式，如架构模式。同时，算法不能算是一种设计模式，因为算法主要是用来解决计算上的问题，而非设计上的问题。 肯特·贝克和沃德·坎宁安在1987年，利用克里斯托佛·亚历山大在建筑设计领域里的思想开发了设计模式并把此思想应用在Smalltalk中的图形用户接口（GUI）的生成中。一年后埃里希·伽玛在他的苏黎世大学博士毕业论文中开始尝试把这种思想改写为适用于软件开发。与此同时James Coplien 在1989年至1991年也在利用相同的思想致力于C++的开发，而后于1991年发表了他的著作Advanced C++ Programming Styles and Idioms。同年Erich Gamma 得到了博士学位，然后去了美国，在那与Richard Helm, Ralph Johnson ,John Vlissides 合作出版了《设计模式：可复用面向对象软件的基础》（Design Patterns - Elements of Reusable Object-Oriented Software） 一书，在此书中共收录了23个设计模式。 这四位作者在软件开发领域里以“四人帮”（英语，Gang of Four，简称GoF）而闻名，并且他们在此书中的协作导致了软件设计模式的突破。有时，GoF也会用于代指《设计模式》这本书。 《设计模式》一书原先把设计模式分为创建型模式、结构型模式、行为型模式，把它们通过授权、聚合、诊断的概念来描述。若想更进一步了解关于面向对象设计的背景，参考接口模式、内聚。若想更进一步了解关于面向对象编程的背景，参考继承，接口，多态。 简单工厂模式活字印刷 面向对象话说三国时期，曹操带领百万大军攻打东吴，大军在长江赤壁驻扎，军船连成一片，眼看就要灭掉东吴，统一天下，曹操大悦，于是大宴众文武，在酒席间，曹操诗兴大发，不觉吟道：喝酒唱歌，人生真爽。众文武齐呼：“丞相好诗！于是一臣子速命印刷工匠刻板印刷，以便流传天下。” 样张出来给曹操一看，曹操感觉不妥，说到：“喝与唱，此话过俗，应该为‘对酒当歌’较好！”，于是此臣就命工匠重新来过。工匠眼看连夜刻板之工，彻底白费，心中叫苦不迭。只得照办。” 样张再次出来请曹操过目，曹操细细一品，感觉还是不好，说：“人生真爽太过直接，应改问语才够意境，因此应改为‘对酒当歌，人生几何？’当臣子转告工匠之时，工匠晕倒！” 为何三国时期的工匠有如此的问题？ 当时活字印刷还未发明，所以要改字的时候必须要整个刻板重刻。如果有活字印刷，则只需更改四个字就可，其余工作都未白做，岂不妙哉。 要改，只需要更改之字，此为可维护。 这写字并非用完这次就无用，完全可以在后来的印刷中重复使用，此乃可复用。 此诗若要加字，只需另刻字加入即可，这是可扩展。 字的排列其实可能是竖排也可能是横排，此时只需要将活字移动就可以做到满足排列需求，此是灵活性好 面对对象的分析设计编程思想，通过封装，继承多态把程序的耦合度降低，传统印刷术的问题就在于所有的字都刻在同一版面上造成耦合度太高所致，开始用设计模式使得程序更加灵活，易于修改，易于复用。 简单工厂模式例：计算器，到底要实例化谁，将来会不会增加实例化的对象，把很容易变化的地方用一个单独的类来做这个创造实例的过程，这个就是工厂。简单的运算工厂类 public class OperationFactory { public static operation createOperate(string operate) { Operation oper = null; switch (operate) { case &quot;+&quot;: oper = new OperationAdd(); break; case &quot;-&quot;: oper = new OperationSub(); break; case &quot;*&quot;: oper = new OperationMul(); break; case &quot;/&quot;: oper = new OperationDiv(); break; } return oper; } } 客户端代码 Operation oper; oper = OperationFactory.createOperate(&quot;+&quot;); oper.NumberA = 1; oper.NumberB = 2; double result = oper.GetResult(); 这样，以后需要增加各种复杂运算，比如平方根，立方根，自然对数等等，只要增加相对应的运算子类就可以了。 策略模式应用场景一个商场收银软件，营业员根据客户所购买的商品的单价和数量，向客户收费用两个文本框来输入单价和数量，一个确定按钮来算出每种商品的费用，用个列表框来记录商品的清单，一个标签来记录总计，一个重置按钮来重新开始。 double total = 0.0d; private void btn0k_Click(object sender, EventArgs e) { double totalPrices = Convert.ToDouble(txtPrice.Text) * Convert.ToDouble(txtNum.Text); total = total + totalPrices; IbxList.Items.Add(&quot;单价：&quot; +txtPrice.Text + &quot;数量：&quot; ＋ txtNum.Text + &quot;合计：&quot;+ totalPrices.ToString()); IblResult.Text = total.ToString(); } 比如遇到节假日 增加打折double total = 0.0d; private void Form_Load(object sender, EventArgs e) { cbxType.Items.AddRange(new object[] {&quot;正常收费&quot;,&quot;打八折&quot;,&quot;打五折&quot;}); cbxType.SlectedIndex = 0; } private void btn0k_Click(object sender, EventArgs e) { double totalPrices = 0.0d; switch(cbxType.Selectedindex) { case 0: totalPrices = Convert.ToDouble(txtPrice.Text) * Convert.ToDouble(txtNum.Text); case 1: totalPrices = Convert.ToDouble(txtPrice.Text) * Convert.ToDouble(txtNum.Text)*0.8; case 2: totalPrices = Convert.ToDouble(txtPrice.Text) * Convert.ToDouble(txtNum.Text)*0.5; } total = total + totalPrices; IbxList.Items.Add(&quot;单价：&quot; +txtPrice.Text + &quot;数量：&quot; ＋ txtNum.Text + &quot;合计：&quot;+ totalPrices.ToString()); IblResult.Text = total.ToString(); } 简单工厂实现面对对象的编程，并不是类越多越好，类的划分是为了封装，但是分装的基础是抽象，具有相同属性和功能的对象的抽象集合才是类。打一折和打九折只是形式的不同，抽象分析出来，所有的打折算法都是一样的，所以打折算法应该是一个类。 //现金收费抽象类 abstract class CashSuper { public abstract double acceptCash(double money); } //正常收费子类 class CashNormal: CashSuper { public override double acceptCash(double money) { return money; } } //打折收费子类 class CashRebate: CashSuper { private double moneyRebate = 1d; public Cash Rebebate(string moneyRebate) { this.moneyRebate = double.Parse(moneyRebate); } publci override double acceptCash(double money) { return money * moneyRebate; } } //返利收费子类 class cashReturn: CashSuper { private double moneyCondition = 0.0d; private double moneyreturn = 0.0d; public CashReturn(string moneyCondition, string moneyReturn) { this.moneyCondition = double.Parse(moneyCondtion); this.moneyReturn = double.Parse(moneyReturn); } public override double acceptCash(double money) { double result = money; if(money &gt;= moneyCondition) { result = money - Math.Floor(money / moneyCondition) * moneyReturn; } return result; } } //现金收费工厂类 class CashFactory { public static CashSuper createCashAccept(string type) { CashSuper cs = null; switch (type) { case:&quot;正常收费&quot;: cs = new CashNormal(); break; case:&quot;满300返100&quot;: CashReturn cr1 = new CashReturn(&quot;300&quot;,&quot;100&quot;); cs = cr1; break; case:&quot;打8折&quot;: CashRebate cr2 = new CashRebate(&quot;0,8&quot;); cs = cr2; break; } return cs; } } //客户端程序主要部分 double total = 0.0d; private void btn0k_clik(object sneder, EventArgs e) { cashSuper csuper = CashFactory.createCashAccept(cbxType.SelectedItem.ToString()); double totalPrices = 0d; totalPrices = csuper.acceptCash(Convert.ToDouble(txtPrice.txt)*Convert.ToDouble(txtNum.Text)); total = total + totalPrices; IbxList.Items.Add(&quot;单价：&quot; +txtPrice.Text + &quot;数量：&quot; ＋ txtNum.Text + &quot;合计：&quot;+ totalPrices.ToString()); IblResult.Text = total.ToString(); } 简单工厂模式虽然能解决这个问题，但是这个模式知识解决对象的创建问题，而且由于工厂本身包括了所有的收费方式，商场是可能经常性地更改打折额度和返利额度，每次维护或扩展收费方式都要改动这个工厂，以致代码需重新编译部署，这真的是很糟糕的处理方式，所以用它不是做好的办法，。面对算法的时常变动应该有更好的办法。 策略模式策略模式定义了算法家族，分别封装起来，让它们之间可以互相替换，此模式让算法的变化，不会影响到使用算法的客户。 //CashContext类 class CashContext { private CashSuper cs; public CashContext(CashSuper csuper) { this.cs = csuper; } public double GetResult(double money) { return cs.accptCash(money); } } //客户端主要代码 double total = 0.0d; private void btn0k_Click(object sender, EventArgs e) { CashContext cc = null; switch (cbxType.selectedItem.ToString()) { case: &quot;正常收费&quot;: cc = new CashContext(new CashNormal()); break; case: &quot;满300返100&quot;: cc = new CashContext(new CashReturn (&quot;300&quot;,&quot;100&quot;)); break; case: &quot;打8折&quot;: cc = new CashContext(new CashRebate(&quot;0.8&quot;)); break; } double totalPrices = 0d; totalPrices = cc.GetResult(convert.ToDouble(txtPrice.Text)*convert.ToDouble(txtNum.Text)); total = total + totalPrices; IbxList.Items.Add(&quot;单价：&quot; +txtPrice.Text + &quot;数量：&quot; ＋ txtNum.Text + &quot;合计：&quot;+ totalPrices.ToString()); IblResult.Text = total.ToString(); } 虽然策略模式写出来了，但是不应该让客户端去判断用哪一个算法。 策略与简单工厂结合class CashContext { CashSuper cs = null; public CashContext(String type) { switch(type) { case &quot;正常收费&quot;: CashNormal cs0 = new CashNormal(); cs = cs0; break; case &quot;满300返100&quot;: CashReturn cr1 = new CashReturn(&quot;300&quot;,&quot;100&quot;); cs = cr1; break; case &quot;打8折&quot;： CashReturn cr2 = new CashRebate(&quot;0.8&quot;); cs = cr2; break; } public double GetResult(double money) { return cs.acceptCash(money); } } } //客户端代码 double total = 0.0d; private void btn0k_Click(object sender, EvnetArgs e) { CashContext csuper = new CashContext(cbxType.slectedItem.ToString()); double totalPrices = 0d; totalPrices = csuper.GetResult(Convert.ToDouble(txtPrice.Text)*Convert.ToDouble(txtNum.Text)); total = total + totalPrices; IbxList.Items.Add(&quot;单价：&quot; +txtPrice.Text + &quot;数量：&quot; ＋ txtNum.Text + &quot;合计：&quot;+ totalPrices.ToString()); IblResult.Text = total.ToString(); } //简单工厂模式的用法 CashSuper csuper = CashFactory.CreateCashAccept(cbxType.SelectedItem.ToString()); =csuper.GetResult; //策略模式与简单工厂结合的用法 CashContext csuper = new (CashContext(cbxType.SelectedItem.ToString())); =csuper.GetResult; 简单工厂模式让客户端认识两个类， CashSuper和CashFactory,而策略模式与简单工厂结合的用法，客户端只需要认识一个类CashContext就可以了。耦合更加降低。 策略模式解析策略模式是一种定义一系列算法的方法，从概念上来看，所有这些算法完成的都是相通的工作，只是实现不同，它可以以相同的方式调用所有的算法，减少各种算法类和使用算法类之间的耦合。策略模式就是用来封装算法的，但是实践中，我们发现可以用它来分装几乎任何类型的规则，只要在分析过程中听到需要在不同的时间应用不同的业务规则，就可以考虑使用策略模式处理这种变化的可能性。 面向对象六大原则概述在工作初期，我们可能会经常会有这样的感觉，自己的代码接口设计混乱、代码耦合较为严重、一个类的代码过多等等，自己回头看的时候都觉得汗颜。再看那些知名的开源库，它们大多有着整洁的代码、清晰简单的接口、职责单一的类，这个时候我们通常会捶胸顿足而感叹：什么时候老夫才能写出这样的代码！ 相关资料iOSAFNetworking2.0源码解析 AFNetworking源码 单一原则(Single Responsibility Principle)简述SRP:就一个类而言，应该仅有一个引起它变化的原因。单一职责的划分界限并不是如马路上的行车道那么清晰，很多时候都是需要靠个人经验来界定。当然最大的问题就是对职责的定义，什么是类的职责，以及怎么划分类的职责。如果一个类承担的职责过多，就等于把这些职责耦合在一起，一个职责的变化可能会削弱或者抑制这个类完成其他职责的能力。这种耦合会导致脆弱的设计，当变化发生时，设计会遭受到意想不到的破坏。 当然，软件设计真正要做的许多内容，就是发现职责并把那些职责相互分离，就是抽象的能力。其实要去判断是否应该分离出类来，也不难，那就是如果你能想到多于一个的动机去改变一个类，那么这个类就具有多于一个的职责。 示例/** * An HTTP stack abstraction. */ public interface HttpStack { /** * 执行Http请求,并且返回一个HttpResponse */ public HttpResponse performRequest(Request&lt;?&gt; request, Map&lt;String, String&gt; additionalHeaders) throws IOException, AuthFailureError; } HttpStack中这个函数的职责就是执行网络请求并且返回一个Response。它的职责很单一，这样在需要修改执行网络请求的相关代码时我们只需要修改实现HttpStack接口的类，而不会影响其它的类的代码。如果某个类的职责包含有执行网络请求、解析网络请求、进行gzip压缩、封装请求参数等等，那么在你修改某处代码时你就必须谨慎，以免修改的代码影响了其它的功能。但是当职责单一的时候，你修改的代码能够基本上不影响其它的功能。这就在一定程度上保证了代码的可维护性。注意，单一职责原则并不是说一个类只有一个函数，而是说这个类中的函数所做的工作必须要是高度相关的，也就是高内聚。 里氏替换原则(Liskov Substitution Principle)简述肯定有不少人跟我刚看到这项原则的时候一样，对这个原则的名字充满疑惑。其实原因就是这项原则最早是在1988年，由麻省理工学院的一位姓里的女士（Barbara Liskov）提出来的。 定义1：如果对每一个类型为 T1的对象 o1，都有类型为 T2 的对象o2，使得以 T1定义的所有程序 P 在所有的对象 o1 都代换成 o2 时，程序 P 的行为没有发生变化，那么类型 T2 是类型 T1 的子类型。 定义2：所有引用基类的地方必须能透明地使用其子类的对象。 问题由来：有一功能P1，由类A完成。现需要将功能P1进行扩展，扩展后的功能为P，其中P由原有功能P1与新功能P2组成。新功能P由类A的子类B来完成，则子类B在完成新功能P2的同时，有可能会导致原有功能P1发生故障。 解决方案：当使用继承时，遵循里氏替换原则。类B继承类A时，除添加新的方法完成新增功能P2外，尽量不要重写父类A的方法，也尽量不要重载父类A的方法。 继承包含这样一层含义：父类中凡是已经实现好的方法（相对于抽象方法而言），实际上是在设定一系列的规范和契约，虽然它不强制要求所有的子类必须遵从这些契约，但是如果子类对这些非抽象方法任意修改，就会对整个继承体系造成破坏。而里氏替换原则就是表达了这一层含义。 继承作为面向对象三大特性之一，在给程序设计带来巨大便利的同时，也带来了弊端。比如使用继承会给程序带来侵入性，程序的可移植性降低，增加了对象间的耦合性，如果一个类被其他的类所继承，则当这个类需要修改时，必须考虑到所有的子类，并且父类修改后，所有涉及到子类的功能都有可能会产生故障。 里氏替换原则通俗的来讲就是：子类可以扩展父类的功能，但不能改变父类原有的功能。它包含以下4层含义： 子类可以实现父类的抽象方法，但不能覆盖父类的非抽象方法。 子类中可以增加自己特有的方法。 当子类的方法重载父类的方法时，方法的前置条件（即方法的形参）要比父类方法的输入参数更宽松。 当子类的方法实现父类的抽象方法时，方法的后置条件（即方法的返回值）要比父类更严格。 示例还是以HttpStack为例，Volley定义了HttpStack来表示执行网络请求这个抽象概念。在执行网络请求时，我们只需要定义一个HttpStack对象，然后调用performRequest即可。至于HttpStack的具体实现由更高层的调用者给出。示例如下 :123456789101112131415161718192021 public static RequestQueue newRequestQueue(Context context, HttpStack stack) &#123; File cacheDir = new File(context.getCacheDir(), DEFAULT_CACHE_DIR); String userAgent = &quot;volley/0&quot;; // 代码省略// 1、构造HttpStack对象 if (stack == null) &#123; if (Build.VERSION.SDK_INT &gt;= 9) &#123; stack = new HurlStack(); &#125; else &#123; // Prior to Gingerbread, HttpUrlConnection was unreliable. // See: http://android-developers.blogspot.com/2011/09/androids-http-clients.html stack = new HttpClientStack(AndroidHttpClient.newInstance(userAgent)); &#125; &#125;// 2、将HttpStack对象传递给Network对象 Network network = new BasicNetwork(stack);// 3、将network对象传递给网络请求队列 RequestQueue queue = new RequestQueue(new DiskBasedCache(cacheDir), network); queue.start(); return queue; &#125; BasicNetwork的代码如下: 1234567891011121314151617/** * A network performing Volley requests over an &#123;@link HttpStack&#125;. */public class BasicNetwork implements Network &#123; // HttpStack抽象对象 protected final HttpStack mHttpStack; protected final ByteArrayPool mPool; public BasicNetwork(HttpStack httpStack) &#123; this(httpStack, new ByteArrayPool(DEFAULT_POOL_SIZE)); &#125; public BasicNetwork(HttpStack httpStack, ByteArrayPool pool) &#123; mHttpStack = httpStack; mPool = pool; &#125;&#125; 上述代码中，BasicNetwork构造函数依赖的是HttpStack抽象接口，任何实现了HttpStack接口的类型都可以作为参数传递给BasicNetwork用以执行网络请求。这就是所谓的里氏替换原则，任何父类出现的地方子类都可以出现，这不就保证了可扩展性吗？ 减少LSP妨碍契约（Contracts）处理 LSP 过分妨碍的一个策略是使用契约，契约清单有 2 种形式：执行说明书（executable specifications）和错误处理，在执行说明书里，一个详细类库的契约也包括一组自动化测试，而错误处理是在代码里直接处理的，例如在前置条件，后置条件，常量检查等，可以从 Bertrand Miller 的大作《契约设计》中查看这个技术。虽然自动化测试和契约设计不在本篇文字的范围内，但当我们用的时候我还是推荐如下内容： 检查使用测试驱动开发（Test-Driven Development）来指导你代码的设计设计可重用类库的时候可随意使用契约设计技术对于你自己要维护和实现的代码，使用契约设计趋向于添加很多不必要的代码，如果你要控制输入，添加测试是非常有必要的，如果你是类库作者，使用契约设计，你要注意不正确的使用方法以及让你的用户使之作为一个测试工具。契约（Contracts） 处理 LSP 过分妨碍的一个策略是使用契约，契约清单有 2 种形式：执行说明书（executable specifications）和错误处理，在执行说明书里，一个详细类库的契约也包括一组自动化测试，而错误处理是在代码里直接处理的，例如在前置条件，后置条件，常量检查等，可以从 Bertrand Miller 的大作《契约设计》中查看这个技术。虽然自动化测试和契约设计不在本篇文字的范围内，但当我们用的时候我还是推荐如下内容： 检查使用测试驱动开发（Test-Driven Development）来指导你代码的设计设计可重用类库的时候可随意使用契约设计技术对于你自己要维护和实现的代码，使用契约设计趋向于添加很多不必要的代码，如果你要控制输入，添加测试是非常有必要的，如果你是类库作者，使用契约设计，你要注意不正确的使用方法以及让你的用户使之作为一个测试工具。 避免继承避免 LSP 妨碍的另外一个测试是：如果可能的话，尽量不用继承，在Gamma的大作《Design Patterns – Elements of Reusable Object-Orineted Software》中，我们可以看到如下建议： Favor object composition over class inheritance 尽量使用对象组合而不是类继承有些书里讨论了组合比继承好的唯一作用是静态类型，基于类的语言（例如，在运行时可以改变行为），与 JavaScript 相关的一个问题是耦合，当使用继承的时候，继承子类型和他们的基类型耦合在一起了，就是说基类型的改变会影响到继承子类型。组合倾向于对象更小化，更容易向静态和动态语言语言维护。 与行为有关，而不是继承到现在，我们讨论了和继承上下文在内的里氏替换原则，指示出 JavaScript 的面向对象实。不过，里氏替换原则（LSP）的本质不是真的和继承有关，而是行为兼容性。JavaScript 是一个动态语言，一个对象的契约行为不是对象的类型决定的，而是对象期望的功能决定的。里氏替换原则的初始构想是作为继承的一个原则指南，等价于对象设计中的隐式接口。 依赖倒置原则(Dependence Inversion Principle)应用场景电脑在以前维修的话是根本不可能的事，可是现在却特别容易，比如说内存坏了，买个内存条，硬盘坏了，买个硬盘换上。为啥这么方便？从修电脑里面就有面相对象的几大设计原则，比如单一职责原则，内存坏了，不应该成为更换CPU的理由，它们各自的职责是明确的。再比如开放－封闭原则，内存不够只要插槽足够就可以添加。还有依赖倒转原则，原话解释是抽象不应该依赖细节，细节应该依赖于抽象，说白了，就是要针对接口编程，不要对实现编程，无论主板，CPU，内存，硬盘都是针对接口设计的，如果是针对实现来设计，内存就要对应的某个品牌的主板，那就会出现换内存需要把主板也换了的尴尬。 为什么叫反转呢？ 面对过程开发时，为了使得常用代码可以复用，一般都会把这些常用代码写成许许多多函数的程序库，这样我们做新项目时，去调用这些底层的函数就可以了。比如我们做的项目大多要访问数据库，所以我们就把访问数据库的代码写成了函数，每次做新项目时就去调用，这就叫做高层模块依赖底层模块。 但是要做新项目是 业务逻辑的高层模块都是一样的，客户却希望使用不同的数据库或存储信息方式，这时出现麻烦了。我们希望能再次利用这些高层模块，但高层模块都是与底层的访问数据库绑定在一起的，没办法复用这些高层模块，这就非常糟糕了。就像刚才说的，PC里如果CPU，内存，硬盘都是需要依赖具体的主板，主板一坏，所有的部件都没法用了，显然不合理，而如果不管高层模块还是底层模块，它们都依赖于抽象，具体一点就是接口或者抽象类，只要接口是稳定的，那么任何一个的更改都不用担心其它受影响，这就使得无论高层模块还是底层模块都可以很容易被复用，这才是最好的办法。 实例依赖倒置原则基于这样一个事实：相对于细节的多变性，抽象的东西要稳定的多。以抽象为基础搭建起来的架构比以细节为基础搭建起来的架构要稳定的多。在java中，抽象指的是接口或者抽象类，细节就是具体的实现类，使用接口或者抽象类的目的是制定好规范和契约，而不去涉及任何具体的操作，把展现细节的任务交给他们的实现类去完成。 依赖倒置原则的核心思想是面向接口编程，我们依旧用一个例子来说明面向接口编程比相对于面向实现编程好在什么地方。场景是这样的，母亲给孩子讲故事，只要给她一本书，她就可以照着书给孩子讲故事了。代码如下： 1234567891011121314151617181920class Book&#123; public String getContent()&#123; return &quot;很久很久以前有一个阿拉伯的故事……&quot;; &#125; &#125; class Mother&#123; public void narrate(Book book)&#123; System.out.println(&quot;妈妈开始讲故事&quot;); System.out.println(book.getContent()); &#125; &#125; public class Client&#123; public static void main(String[] args)&#123; Mother mother = new Mother(); mother.narrate(new Book()); &#125; &#125; 运行良好，假如有一天，需求变成这样：不是给书而是给一份报纸，让这位母亲讲一下报纸上的故事，报纸的代码如下： 12345class Newspaper&#123; public String getContent()&#123; return &quot;林书豪38+7领导尼克斯击败湖人……&quot;; &#125; &#125; 这位母亲却办不到，因为她居然不会读报纸上的故事，这太荒唐了，只是将书换成报纸，居然必须要修改Mother才能读。假如以后需求换成杂志呢？换成网页呢？还要不断地修改Mother，这显然不是好的设计。原因就是Mother与Book之间的耦合性太高了，必须降低他们之间的耦合度才行。我们引入一个抽象的接口IReader。读物，只要是带字的都属于读物： 1234567interface IReader&#123; public String getContent(); &#125; ``` Mother类与接口IReader发生依赖关系，而Book和Newspaper都属于读物的范畴，他们各自都去实现IReader接口，这样就符合依赖倒置原则了，代码修改为： class Newspaper implements IReader { public String getContent(){ return “林书豪17+9助尼克斯击败老鹰……”; }}class Book implements IReader{ public String getContent(){ return “很久很久以前有一个阿拉伯的故事……”; }} class Mother{ public void narrate(IReader reader){ System.out.println(“妈妈开始讲故事”); System.out.println(reader.getContent()); }} public class Client{ public static void main(String[] args){ Mother mother = new Mother(); mother.narrate(new Book()); mother.narrate(new Newspaper()); }}1234567891011121314151617181920212223242526272829这样修改后，无论以后怎样扩展Client类，都不需要再修改Mother类了。这只是一个简单的例子，实际情况中，代表高层模块的Mother类将负责完成主要的业务逻辑，一旦需要对它进行修改，引入错误的风险极大。所以遵循依赖倒置原则可以降低类之间的耦合性，提高系统的稳定性，降低修改程序造成的风险。 采用依赖倒置原则给多人并行开发带来了极大的便利，比如上例中，原本Mother类与Book类直接耦合时，Mother类必须等Book类编码完成后才可以进行编码，因为Mother类依赖于Book类。修改后的程序则可以同时开工，互不影响，因为Mother与Book类一点关系也没有。参与协作开发的人越多、项目越庞大，采用依赖导致原则的意义就越重大。现在很流行的TDD开发模式就是依赖倒置原则最成功的应用。传递依赖关系有三种方式，以上的例子中使用的方法是接口传递，另外还有两种传递方式：构造方法传递和setter方法传递，相信用过Spring框架的，对依赖的传递方式一定不会陌生。在实际编程中，我们一般需要做到如下3点：* 低层模块尽量都要有抽象类或接口，或者两者都有。* 变量的声明类型尽量是抽象类或接口。* 使用继承时遵循里氏替换原则。依赖倒置原则的核心就是要我们面向接口编程，理解了面向接口编程，也就理解了依赖倒置。# 接口隔离原则(Interface Segregation Principle)## 简介接口隔离原则（英语：interface-segregation principles， 缩写：ISP）指明没有客户(client)应该被迫依赖于它不使用方法。接口隔离原则(ISP)拆分非常庞大臃肿的接口成为更小的和更具体的接口，这样客户将会只需要知道他们感兴趣的方法。这种缩小的接口也被称为角色接口（role interfaces）。接口隔离原则(ISP)的目的是系统解开耦合，从而容易重构，更改和重新部署。接口隔离原则是在SOLID (面向对象设计)中五个面向对象设计(OOD)的原则之一，类似于在GRASP (面向对象设计)中的高内聚性。## 实例定义：客户端不应该依赖它不需要的接口；一个类对另一个类的依赖应该建立在最小的接口上。问题由来：类A通过接口I依赖类B，类C通过接口I依赖类D，如果接口I对于类A和类B来说不是最小接口，则类B和类D必须去实现他们不需要的方法。解决方案：将臃肿的接口I拆分为独立的几个接口，类A和类C分别与他们需要的接口建立依赖关系。也就是采用接口隔离原则。举例来说明接口隔离原则：![enter description here][1]这个图的意思是：类A依赖接口I中的方法1、方法2、方法3，类B是对类A依赖的实现。类C依赖接口I中的方法1、方法4、方法5，类D是对类C依赖的实现。对于类B和类D来说，虽然他们都存在着用不到的方法（也就是图中红色字体标记的方法），但由于实现了接口I，所以也必须要实现这些用不到的方法。对类图不熟悉的可以参照程序代码来理解，代码如下： interface I { public void method1(); public void method2(); public void method3(); public void method4(); public void method5();} class A{ public void depend1(I i){ i.method1(); } public void depend2(I i){ i.method2(); } public void depend3(I i){ i.method3(); }} class B implements I{ public void method1() { System.out.println(“类B实现接口I的方法1”); } public void method2() { System.out.println(“类B实现接口I的方法2”); } public void method3() { System.out.println(“类B实现接口I的方法3”); } //对于类B来说，method4和method5不是必需的，但是由于接口A中有这两个方法， //所以在实现过程中即使这两个方法的方法体为空，也要将这两个没有作用的方法进行实现。 public void method4() {} public void method5() {}} class C{ public void depend1(I i){ i.method1(); } public void depend2(I i){ i.method4(); } public void depend3(I i){ i.method5(); }} class D implements I{ public void method1() { System.out.println(“类D实现接口I的方法1”); } //对于类D来说，method2和method3不是必需的，但是由于接口A中有这两个方法， //所以在实现过程中即使这两个方法的方法体为空，也要将这两个没有作用的方法进行实现。 public void method2() {} public void method3() {} public void method4() { System.out.println(&quot;类D实现接口I的方法4&quot;); } public void method5() { System.out.println(&quot;类D实现接口I的方法5&quot;); } } public class Client{ public static void main(String[] args){ A a = new A(); a.depend1(new B()); a.depend2(new B()); a.depend3(new B()); C c = new C(); c.depend1(new D()); c.depend2(new D()); c.depend3(new D()); } } 1234可以看到，如果接口过于臃肿，只要接口中出现的方法，不管对依赖于它的类有没有用处，实现类中都必须去实现这些方法，这显然不是好的设计。如果将这个设计修改为符合接口隔离原则，就必须对接口I进行拆分。在这里我们将原有的接口I拆分为三个接口，拆分后的设计如图2所示：![][2] interface I1 { public void method1();} interface I2 { public void method2(); public void method3();} interface I3 { public void method4(); public void method5();} class A{ public void depend1(I1 i){ i.method1(); } public void depend2(I2 i){ i.method2(); } public void depend3(I2 i){ i.method3(); }} class B implements I1, I2{ public void method1() { System.out.println(“类B实现接口I1的方法1”); } public void method2() { System.out.println(“类B实现接口I2的方法2”); } public void method3() { System.out.println(“类B实现接口I2的方法3”); }} class C{ public void depend1(I1 i){ i.method1(); } public void depend2(I3 i){ i.method4(); } public void depend3(I3 i){ i.method5(); }} class D implements I1, I3{ public void method1() { System.out.println(“类D实现接口I1的方法1”); } public void method4() { System.out.println(“类D实现接口I3的方法4”); } public void method5() { System.out.println(“类D实现接口I3的方法5”); }}1234567891011121314151617181920212223242526272829303132333435 接口隔离原则的含义是：建立单一接口，不要建立庞大臃肿的接口，尽量细化接口，接口中的方法尽量少。也就是说，我们要为各个类建立专用的接口，而不要试图去建立一个很庞大的接口供所有依赖它的类去调用。本文例子中，将一个庞大的接口变更为3个专用的接口所采用的就是接口隔离原则。在程序设计中，依赖几个专用的接口要比依赖一个综合的接口更灵活。接口是设计时对外部设定的“契约”，通过分散定义多个接口，可以预防外来变更的扩散，提高系统的灵活性和可维护性。 说到这里，很多人会觉的接口隔离原则跟之前的单一职责原则很相似，其实不然。其一，单一职责原则原注重的是职责；而接口隔离原则注重对接口依赖的隔离。其二，单一职责原则主要是约束类，其次才是接口和方法，它针对的是程序中的实现和细节；而接口隔离原则主要约束接口接口，主要针对抽象，针对程序整体框架的构。 采用接口隔离原则对接口进行约束时，要注意以下几点： * 接口尽量小，但是要有限度。对接口进行细化可以提高程序设计灵活性是不挣的事实，但是如果过小，则会造成接口数量过多，使设计复杂化。所以一定要适度。* 为依赖接口的类定制服务，只暴露给调用的类它需要的方法，它不需要的方法则隐藏起来。只有专注地为一个模块提供定制服务，才能建立最小的依赖关系。* 提高内聚，减少对外交互。使接口用最少的方法去完成最多的事情。运用接口隔离原则，一定要适度，接口设计的过大或过小都不好。设计接口的时候，只有多花些时间去思考和筹划，才能准确地实践这一原则。 # 迪米特原则( Law of Demeter)## 简介得墨忒耳定律（Law of Demeter，缩写LoD）亦稱為“最少知识原则（Principle of Least Knowledge）”，是一种软件开发的设计指導原則，特别是面向对象的程序设计。得墨忒耳定律是松耦合的一种具體案例。該原則是美國東北大學在1987年末在發明的，可以簡單地以下面任一種方式總結:每个单元对于其他的单元只能拥有有限的知识：只是与当前单元紧密联系的单元；每个单元只能和它的朋友交谈：不能和陌生单元交谈；只和自己直接的朋友交谈。这个原理的名称来源于希腊神话中的农业女神，孤独的得墨忒耳。很多面向对象程序设计语言用&quot;.&quot;表示对象的域的解析算符，因此得墨忒耳定律可以简单地陈述为“只使用一个.算符”。因此，a.b.Method()违反了此定律，而a.Method()不违反此定律。一个简单例子是，人可以命令一条狗行走（walk），但是不应该直接指挥狗的腿行走，应该由狗去指挥控制它的腿如何行走。## 实例**定义**：一个对象应该对其他对象保持最少的了解。问题由来：类与类之间的关系越密切，耦合度越大，当一个类发生改变时，对另一个类的影响也越大。**解决方案**：尽量降低类与类之间的耦合。自从我们接触编程开始，就知道了软件编程的总的原则：低耦合，高内聚。无论是面向过程编程还是面向对象编程，只有使各个模块之间的耦合尽量的低，才能提高代码的复用率。低耦合的优点不言而喻，但是怎么样编程才能做到低耦合呢？那正是迪米特法则要去完成的。迪米特法则又叫最少知道原则，最早是在1987年由美国Northeastern University的Ian Holland提出。通俗的来讲，就是一个类对自己依赖的类知道的越少越好。也就是说，对于被依赖的类来说，无论逻辑多么复杂，都尽量地的将逻辑封装在类的内部，对外除了提供的public方法，不对外泄漏任何信息。迪米特法则还有一个更简单的定义：只与直接的朋友通信。首先来解释一下什么是直接的朋友：每个对象都会与其他对象有耦合关系，只要两个对象之间有耦合关系，我们就说这两个对象之间是朋友关系。耦合的方式很多，依赖、关联、组合、聚合等。其中，我们称出现成员变量、方法参数、方法返回值中的类为直接的朋友，而出现在局部变量中的类则不是直接的朋友。也就是说，陌生的类最好不要作为局部变量的形式出现在类的内部。举一个例子：有一个集团公司，下属单位有分公司和直属部门，现在要求打印出所有下属单位的员工ID。先来看一下违反迪米特法则的设计。 //总公司员工class Employee{ private String id; public void setId(String id){ this.id = id; } public String getId(){ return id; }} //分公司员工class SubEmployee{ private String id; public void setId(String id){ this.id = id; } public String getId(){ return id; }} class SubCompanyManager{ public List getAllEmployee(){ List list = new ArrayList(); for(int i=0; i&lt;100; i++){ SubEmployee emp = new SubEmployee(); //为分公司人员按顺序分配一个ID emp.setId(“分公司”+i); list.add(emp); } return list; }} class CompanyManager{ public List&lt;Employee&gt; getAllEmployee(){ List&lt;Employee&gt; list = new ArrayList&lt;Employee&gt;(); for(int i=0; i&lt;30; i++){ Employee emp = new Employee(); //为总公司人员按顺序分配一个ID emp.setId(&quot;总公司&quot;+i); list.add(emp); } return list; } public void printAllEmployee(SubCompanyManager sub){ List&lt;SubEmployee&gt; list1 = sub.getAllEmployee(); for(SubEmployee e:list1){ System.out.println(e.getId()); } List&lt;Employee&gt; list2 = this.getAllEmployee(); for(Employee e:list2){ System.out.println(e.getId()); } } } public class Client{ public static void main(String[] args){ CompanyManager e = new CompanyManager(); e.printAllEmployee(new SubCompanyManager()); }}12现在这个设计的主要问题出在CompanyManager中，根据迪米特法则，只与直接的朋友发生通信，而SubEmployee类并不是CompanyManager类的直接朋友（以局部变量出现的耦合不属于直接朋友），从逻辑上讲总公司只与他的分公司耦合就行了，与分公司的员工并没有任何联系，这样设计显然是增加了不必要的耦合。按照迪米特法则，应该避免类中出现这样非直接朋友关系的耦合。修改后的代码如下: class SubCompanyManager{ public List getAllEmployee(){ List list = new ArrayList(); for(int i=0; i","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://yoursite.com/tags/设计模式/"}]},{"title":"面向对象设计原则","date":"2017-05-03T00:35:32.794Z","path":"2017/05/03/面向对象设计原则/","text":"面向对象的三个基本特征：封装，继承，多态面向对象设计原则 迪米特法则：一个软件实体应当尽可能少地与其他实体发生相互作用 又叫最少知道原则。是强调了类之间的松耦合，类之间的耦合越弱,越有利于复用，一个处在弱耦合的类被修改，不会对有关系的类造成影响，也就是说，信息的隐藏促进了软件的复用。 里氏代换原则：所有引用基类对象的地方能够透明地使用其子类的对象 定义1: 如果对每一个类型为 T1的对象 o1，都有类型为 T2 的对象o2，使得以 T1定义的所有程序 P 在所有的对象 o1 都代换成 o2 时，程序 P 的行为没有发生变化，那么类型 T2 是类型 T1 的子类型。 定义2：子类型必须能够替换掉它们的父类型 开闭原则: 软件实体应对扩展开放，而对修改关闭 开闭原则就是说对扩展开放，对修改关闭。在程序需要进行拓展的时候，不能去修改原有的代码，实现一个热插拔的效果。所以一句话概括就是：为了使程序的扩展性好，易于维护和升级。想要达到这样的效果，我们需要使用接口和抽象类，后面的具体设计中我们会提到这点。 单一职责原则:一个类只负责一个功能领域中的相应职责 不要存在多于一个导致类变更的原因。通俗的说，即一个类只负责一项职责，应该仅有一个引起它变化的原因。 遵循单一职责原的优点有： 可以降低类的复杂度，一个类只负责一项职责，其逻辑肯定要比负责多项职责简单的多； 提高类的可读性，提高系统的可维护性； 变更引起的风险降低，变更是必然的，如果单一职责原则遵守的好，当修改一个功能时，可以显著降低对其他功能的影响。 依赖倒转原则：抽象不应该依赖于细节，细节应该依赖于抽象 高层模块不应该依赖低层模块，二者都应该依赖其抽象；抽象不应该依赖细节；细节应该依赖抽象。即针对接口编程，不要针对实现编程。 在实际编程中，我们一般需要做到如下3点： 低层模块尽量都要有抽象类或接口，或者两者都有。 变量的声明类型尽量是抽象类或接口。 使用继承时遵循里氏替换原则。 接口隔离原则：使用多个专门的接口，而不使用单一的总接口 使用多个隔离的接口，比使用单个接口要好。还是一个降低类之间的耦合度的意思，从这儿我们看出，其实设计模式就是一个软件的设计思想，从大型软件架构出发，为了升级和维护方便。所以上文中多次出现：降低依赖，降低耦合。 合成复用原则：尽量使用对象组合，而不是继承来达到复用的目的 要尽量的使用合成和聚合，而不是继承关系达到复用的目的. 该原则就是在一个新的对象里面使用一些已有的对象，使之成为新对象的一部分： 新的对象通过向这些对象的委派达到复用已有功能的目的。","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://yoursite.com/tags/设计模式/"}]},{"title":"理解ThreadLocal","date":"2017-05-02T14:28:08.066Z","path":"2017/05/02/理解ThreadLocal/","text":"理解ThreadLocaljava中可以使用public static设置一个全局变量，所有线程都共享这个变量。但是有时，我们需要每一个线程都有一个自己的共享变量，ThreadLocal就是一个不错的解决方案。 java8中对ThreadLocal的解释12345This class provides thread-local variables. These variables differ from their normal counterparts in that each thread that accesses one (via its get or set method)has its own, independently initialized copy of the variable. ThreadLocal instances are typically private static fields in classes that wish to associate state with a thread (e.g., a user ID or Transaction ID). 对其理解： 每个线程单独保存这个变量，对其他线程不可见。 ThreadLocal可以给一个初始值，而每个线程都会获得这个初始化值的一个副本，也可以new的方式为线程创建一个变量。 ThreadLocal 不是用于解决共享变量的问题的，不是为了协调线程同步而存在，而是为了方便每个线程处理自己的状态而引入的一个机制。 ThreadLocal的使用 ThreadLocal几个主要操作方法 1234public T get() &#123;...&#125;//获取线程变量对象public void remove() &#123;...&#125;//移除线程变量对象，将对线程变量对象的引用设置为nullpublic void set(T value) &#123;...&#125;//添加线程变量对象protected T initialValue() &#123;...&#125;//设置初始化数据，覆盖该方法可以设置初始默认值 使用的小demo 123456789101112131415161718192021public class ThreadLocalDemo &#123; private static ThreadLocal&lt;Integer&gt; local=() -&gt; 0;//覆盖initialValue方法设置初始值。 public static void main(String[] args) &#123; Thread[] threads=new Thread[3]; for(int i=0;i&lt;3;i++)&#123; threads[i]=() -&gt; &#123; int mun=local.get(); for(int j=0;j&lt;10;j++)&#123; mun=mun+1; &#125; local.set(mun); System.out.println(Thread.currentThread().getName()+\"===\"+local.get()); &#125;; &#125; for(Thread t:threads)&#123; t.start(); &#125; &#125;&#125; 运行结果123Thread-3===10Thread-2===10Thread-1===10 可以看出线程之间互不影响。 实现原理 ThreadLocal中的静态内部类ThreadLocalMap可以看到Entry 类继承了 WeakReference","tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]},{"title":"synchronized","date":"2017-05-02T14:13:12.023Z","path":"2017/05/02/synchronized/","text":"synchronized同步方法 方法的变量不存在非线程安全问题，永远都是线程安全的。 实例变量为非线程安全。 多个对象则有多个锁。非静态同步方法的锁为对象锁，当存在多个对象的时候，JVM就会创建多个锁。 锁对象。 所有的非静态同步方法用的都是同一把锁——实例对象本身 也就是说如果一个实例对象的非静态同步方法获取锁后，该实例对象的其他非静态同步方法必须等待获取锁的方法释放锁后才能获取锁，可是别的实例对象的非静态同步方法因为跟该实例对象的非静态同步方法用的是不同的锁，所以毋须等待该实例对象已获取锁的非静态同步方法释放锁就可以获取他们自己的锁。 所有的静态同步方法用的也是同一把锁——类对象本身 静态同步方法与非静态同步方法之间是不会有竞态条件的。但是一旦一个静态同步方法获取锁后，其他的静态同步方法都必须等待该方法释放锁后才能获取锁，而不管是同一个实例对象的静态同步方法之间，还是不同的实例对象的静态同步方法之间，只要它们同一个类的实例对象！ 只有共享资源的读写访问需要同步化，如果非共享资源，则根本没有同步化的必要。 A线程先持有对象的Lock锁，B线程可以异步的方式调用该对象的非synchronized方法；A线程先持有对象的Lock锁，B线程此时调用该对象的synchronized方法，则需要等待，也就是同步。 同步不可以继承。要想子类的方法同步，也需要加上synchronized关键字。 出现异常，自动释放锁。当一个线程执行的代码出现异常时，其所持有的锁会自动释放。 锁重入。在一个synchronized方法/块内部调用本类的其他的synchronized方法/块时，是永远可以得到锁的；当存在父子类继承关系时，子类完全可以通过”可重入锁”调用父类的同步方法的。 脏读。生脏读的情况是在读取实例变量时，此值已经被其他线程更改过了，脏读一定发生在操作实例变量的情况下，这就是不同线程“争抢”实例变量的结果。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748 //测试synchronized类public class PublicVar &#123; public String username=\"A\"; public String password=\"AA\"; synchronized public void setValue(String username,String password)&#123; try &#123; this.username=username; Thread.sleep(1000); this.password=password; System.out.println(\"thread:\"+Thread.currentThread().getName()+ \" username\"+this.username+\" password\"+this.password); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; public void getValue()&#123; System.out.println(\"thread:\"+Thread.currentThread().getName()+ \" username\"+this.username+\" password\"+this.password); &#125;&#125;//测试线程public class ThreadA extends Thread &#123; private PublicVar publicVar; public ThreadA(PublicVar publicVar) &#123; super(); this.publicVar = publicVar; &#125; @Override public void run() &#123; super.run(); publicVar.setValue(\"B\",\"BB\"); &#125;&#125;//测试入口public class DrMain &#123; public static void main(String args[])&#123; try &#123; PublicVar publicVar=new PublicVar(); ThreadA threadA=new ThreadA(publicVar); threadA.start(); threadA.sleep(200); publicVar.getValue(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 123结果：thread:main usernameB passwordAA //发生了脏读thread:Thread-0 usernameB passwordBB synchronized同步代码块 synchronized方法是对当前对象加锁，而synchronized同步代码块是对某一个对象进行加锁。 在synchronized同步代码块中的就是同步执行，不在就是异步执行。 静态同步synchronized方法和synchronized(class)代码块的锁都是*.java文件对应的Class类进行持锁。 同步synchronized代码块不使用String作为锁对象，因为String的常量池的影响，而改用其他，比如new Object()实例化对象 参考: JAVA多线程编程核心技术 JAVA编程思想","tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]},{"title":"clean-code-js","date":"2017-04-30T03:18:30.969Z","path":"2017/04/30/clean-code-js/","text":"Original Repository: ryanmcdermott/clean-code-javascript JavaScript 风格指南目录 介绍 变量 函数 对象和数据结构 类 测试 并发 错误处理 格式化 注释 介绍作者根据 Robert C. Martin 《代码整洁之道》总结了适用于 JavaScript 的软件工程原则《Clean Code JavaScript》。 本文是对其的翻译。 不必严格遵守本文的所有原则，有时少遵守一些效果可能会更好，具体应根据实际情况决定。这是根据《代码整洁之道》作者多年经验整理的代码优化建议，但也仅仅只是一份建议。 软件工程已经发展了 50 多年，至今仍在不断前进。现在，把这些原则当作试金石，尝试将他们作为团队代码质量考核的标准之一吧。 最后你需要知道的是，这些东西不会让你立刻变成一个优秀的工程师，长期奉行他们也并不意味着你能够高枕无忧不再犯错。千里之行，始于足下。我们需要时常和同行们进行代码评审，不断优化自己的代码。不要惧怕改善代码质量所需付出的努力，加油。 变量使用有意义，可读性好的变量名反例:1var yyyymmdstr = moment().format('YYYY/MM/DD'); 正例:1var yearMonthDay = moment().format('YYYY/MM/DD'); 回到目录 使用 ES6 的 const 定义常量反例中使用”var”定义的”常量”是可变的。 在声明一个常量时，该常量在整个程序中都应该是不可变的。 反例:1var FIRST_US_PRESIDENT = \"George Washington\"; 正例:1const FIRST_US_PRESIDENT = \"George Washington\"; 回到目录 对功能类似的变量名采用统一的命名风格反例:123getUserInfo();getClientData();getCustomerRecord(); 正例:1getUser(); 回到目录 使用易于检索名称我们需要阅读的代码远比自己写的要多，使代码拥有良好的可读性且易于检索非常重要。阅读变量名晦涩难懂的代码对读者来说是一种相当糟糕的体验。让你的变量名易于检索。 反例:1234// 525600 是什么?for (var i = 0; i &lt; 525600; i++) &#123; runCronJob();&#125; 正例:12345// Declare them as capitalized `var` globals.var MINUTES_IN_A_YEAR = 525600;for (var i = 0; i &lt; MINUTES_IN_A_YEAR; i++) &#123; runCronJob();&#125; 回到目录 使用说明变量(即有意义的变量名)反例:12const cityStateRegex = /^(.+)[,\\\\s]+(.+?)\\s*(\\d&#123;5&#125;)?$/;saveCityState(cityStateRegex.match(cityStateRegex)[1], cityStateRegex.match(cityStateRegex)[2]); 正例:12345const cityStateRegex = /^(.+)[,\\\\s]+(.+?)\\s*(\\d&#123;5&#125;)?$/;const match = cityStateRegex.match(cityStateRegex)const city = match[1];const state = match[2];saveCityState(city, state); 回到目录 不要绕太多的弯子显式优于隐式。 反例:12345678910var locations = ['Austin', 'New York', 'San Francisco'];locations.forEach((l) =&gt; &#123; doStuff(); doSomeOtherStuff(); ... ... ... // l是什么？ dispatch(l);&#125;); 正例:123456789var locations = ['Austin', 'New York', 'San Francisco'];locations.forEach((location) =&gt; &#123; doStuff(); doSomeOtherStuff(); ... ... ... dispatch(location);&#125;); 回到目录 避免重复的描述当类/对象名已经有意义时，对其变量进行命名不需要再次重复。 反例:123456789var Car = &#123; carMake: 'Honda', carModel: 'Accord', carColor: 'Blue'&#125;;function paintCar(car) &#123; car.carColor = 'Red';&#125; 正例:123456789var Car = &#123; make: 'Honda', model: 'Accord', color: 'Blue'&#125;;function paintCar(car) &#123; car.color = 'Red';&#125; 回到目录 避免无意义的条件判断反例:12345678function createMicrobrewery(name) &#123; var breweryName; if (name) &#123; breweryName = name; &#125; else &#123; breweryName = 'Hipster Brew Co.'; &#125;&#125; 正例:123function createMicrobrewery(name) &#123; var breweryName = name || 'Hipster Brew Co.'&#125; 回到目录 函数函数参数 (理想情况下应不超过 2 个)限制函数参数数量很有必要，这么做使得在测试函数时更加轻松。过多的参数将导致难以采用有效的测试用例对函数的各个参数进行测试。 应避免三个以上参数的函数。通常情况下，参数超过两个意味着函数功能过于复杂，这时需要重新优化你的函数。当确实需要多个参数时，大多情况下可以考虑这些参数封装成一个对象。 JS 定义对象非常方便，当需要多个参数时，可以使用一个对象进行替代。 反例:123function createMenu(title, body, buttonText, cancellable) &#123; ...&#125; 正例:12345678910var menuConfig = &#123; title: 'Foo', body: 'Bar', buttonText: 'Baz', cancellable: true&#125;function createMenu(menuConfig) &#123; ...&#125; 回到目录 函数功能的单一性这是软件功能中最重要的原则之一。 功能不单一的函数将导致难以重构、测试和理解。功能单一的函数易于重构，并使代码更加干净。 反例:12345678function emailClients(clients) &#123; clients.forEach(client =&gt; &#123; let clientRecord = database.lookup(client); if (clientRecord.isActive()) &#123; email(client); &#125; &#125;);&#125; 正例:12345678910111213141516function emailClients(clients) &#123; clients.forEach(client =&gt; &#123; emailClientIfNeeded(client); &#125;);&#125;function emailClientIfNeeded(client) &#123; if (isClientActive(client)) &#123; email(client); &#125;&#125;function isClientActive(client) &#123; let clientRecord = database.lookup(client); return clientRecord.isActive();&#125; 回到目录 函数名应明确表明其功能反例:1234567function dateAdd(date, month) &#123; // ...&#125;let date = new Date();// 很难理解dateAdd(date, 1)是什么意思 正例:123456function dateAddMonth(date, month) &#123; // ...&#125;let date = new Date();dateAddMonth(date, 1); 回到目录 函数应该只做一层抽象当函数的需要的抽象多于一层时通常意味着函数功能过于复杂，需将其进行分解以提高其可重用性和可测试性。 反例:12345678910111213141516171819202122function parseBetterJSAlternative(code) &#123; let REGEXES = [ // ... ]; let statements = code.split(' '); let tokens; REGEXES.forEach((REGEX) =&gt; &#123; statements.forEach((statement) =&gt; &#123; // ... &#125;) &#125;); let ast; tokens.forEach((token) =&gt; &#123; // lex... &#125;); ast.forEach((node) =&gt; &#123; // parse... &#125;)&#125; 正例:1234567891011121314151617181920212223242526272829303132function tokenize(code) &#123; let REGEXES = [ // ... ]; let statements = code.split(' '); let tokens; REGEXES.forEach((REGEX) =&gt; &#123; statements.forEach((statement) =&gt; &#123; // ... &#125;) &#125;); return tokens;&#125;function lexer(tokens) &#123; let ast; tokens.forEach((token) =&gt; &#123; // lex... &#125;); return ast;&#125;function parseBetterJSAlternative(code) &#123; let tokens = tokenize(code); let ast = lexer(tokens); ast.forEach((node) =&gt; &#123; // parse... &#125;)&#125; 回到目录 移除重复的代码永远、永远、永远不要在任何循环下有重复的代码。 这种做法毫无意义且潜在危险极大。重复的代码意味着逻辑变化时需要对不止一处进行修改。JS 弱类型的特点使得函数拥有更强的普适性。好好利用这一优点吧。 反例:1234567891011121314151617181920212223242526272829function showDeveloperList(developers) &#123; developers.forEach(developer =&gt; &#123; var expectedSalary = developer.calculateExpectedSalary(); var experience = developer.getExperience(); var githubLink = developer.getGithubLink(); var data = &#123; expectedSalary: expectedSalary, experience: experience, githubLink: githubLink &#125;; render(data); &#125;);&#125;function showManagerList(managers) &#123; managers.forEach(manager =&gt; &#123; var expectedSalary = manager.calculateExpectedSalary(); var experience = manager.getExperience(); var portfolio = manager.getMBAProjects(); var data = &#123; expectedSalary: expectedSalary, experience: experience, portfolio: portfolio &#125;; render(data); &#125;);&#125; 正例:123456789101112131415161718192021function showList(employees) &#123; employees.forEach(employee =&gt; &#123; var expectedSalary = employee.calculateExpectedSalary(); var experience = employee.getExperience(); var portfolio; if (employee.type === 'manager') &#123; portfolio = employee.getMBAProjects(); &#125; else &#123; portfolio = employee.getGithubLink(); &#125; var data = &#123; expectedSalary: expectedSalary, experience: experience, portfolio: portfolio &#125;; render(data); &#125;);&#125; 回到目录 采用默认参数精简代码反例:1234function writeForumComment(subject, body) &#123; subject = subject || 'No Subject'; body = body || 'No text';&#125; 正例:123function writeForumComment(subject = 'No subject', body = 'No text') &#123; ...&#125; 回到目录 使用 Object.assign 设置默认对象反例:12345678910111213141516var menuConfig = &#123; title: null, body: 'Bar', buttonText: null, cancellable: true&#125;function createMenu(config) &#123; config.title = config.title || 'Foo' config.body = config.body || 'Bar' config.buttonText = config.buttonText || 'Baz' config.cancellable = config.cancellable === undefined ? config.cancellable : true;&#125;createMenu(menuConfig); 正例:1234567891011121314151617181920var menuConfig = &#123; title: 'Order', // User did not include 'body' key buttonText: 'Send', cancellable: true&#125;function createMenu(config) &#123; config = Object.assign(&#123; title: 'Foo', body: 'Bar', buttonText: 'Baz', cancellable: true &#125;, config); // config now equals: &#123;title: \"Order\", body: \"Bar\", buttonText: \"Send\", cancellable: true&#125; // ...&#125;createMenu(menuConfig); 回到目录 不要使用标记(Flag)作为函数参数这通常意味着函数的功能的单一性已经被破坏。此时应考虑对函数进行再次划分。 反例:1234567function createFile(name, temp) &#123; if (temp) &#123; fs.create('./temp/' + name); &#125; else &#123; fs.create(name); &#125;&#125; 正例:12345678910function createTempFile(name) &#123; fs.create('./temp/' + name);&#125;----------function createFile(name) &#123; fs.create(name);&#125; 回到目录 避免副作用当函数产生了除了“接受一个值并返回一个结果”之外的行为时，称该函数产生了副作用。比如写文件、修改全局变量或将你的钱全转给了一个陌生人等。 程序在某些情况下确实需要副作用这一行为，如先前例子中的写文件。这时应该将这些功能集中在一起，不要用多个函数/类修改某个文件。用且只用一个 service 完成这一需求。 反例:1234567891011// Global variable referenced by following function.// If we had another function that used this name, now it'd be an array and it could break it.var name = 'Ryan McDermott';function splitIntoFirstAndLastName() &#123; name = name.split(' ');&#125;splitIntoFirstAndLastName();console.log(name); // ['Ryan', 'McDermott']; 正例:123456789function splitIntoFirstAndLastName(name) &#123; return name.split(' ');&#125;var name = 'Ryan McDermott'var newName = splitIntoFirstAndLastName(name);console.log(name); // 'Ryan McDermott';console.log(newName); // ['Ryan', 'McDermott']; 回到目录 不要写全局函数在 JS 中污染全局是一个非常不好的实践，这么做可能和其他库起冲突，且调用你的 API 的用户在实际环境中得到一个 exception 前对这一情况是一无所知的。 想象以下例子：如果你想扩展 JS 中的 Array，为其添加一个 diff 函数显示两个数组间的差异，此时应如何去做？你可以将 diff 写入 Array.prototype，但这么做会和其他有类似需求的库造成冲突。如果另一个库对 diff 的需求为比较一个数组中首尾元素间的差异呢？ 使用 ES6 中的 class 对全局的 Array 做简单的扩展显然是一个更棒的选择。 反例:12345678910111213141516Array.prototype.diff = function(comparisonArray) &#123; var values = []; var hash = &#123;&#125;; for (var i of comparisonArray) &#123; hash[i] = true; &#125; for (var i of this) &#123; if (!hash[i]) &#123; values.push(i); &#125; &#125; return values;&#125; 正例:12345678910111213141516171819202122class SuperArray extends Array &#123; constructor(...args) &#123; super(...args); &#125; diff(comparisonArray) &#123; var values = []; var hash = &#123;&#125;; for (var i of comparisonArray) &#123; hash[i] = true; &#125; for (var i of this) &#123; if (!hash[i]) &#123; values.push(i); &#125; &#125; return values; &#125;&#125; 回到目录 采用函数式编程函数式的编程具有更干净且便于测试的特点。尽可能的使用这种风格吧。 反例:123456789101112131415161718192021const programmerOutput = [ &#123; name: 'Uncle Bobby', linesOfCode: 500 &#125;, &#123; name: 'Suzie Q', linesOfCode: 1500 &#125;, &#123; name: 'Jimmy Gosling', linesOfCode: 150 &#125;, &#123; name: 'Gracie Hopper', linesOfCode: 1000 &#125;];var totalOutput = 0;for (var i = 0; i &lt; programmerOutput.length; i++) &#123; totalOutput += programmerOutput[i].linesOfCode;&#125; 正例:12345678910111213141516171819const programmerOutput = [ &#123; name: 'Uncle Bobby', linesOfCode: 500 &#125;, &#123; name: 'Suzie Q', linesOfCode: 1500 &#125;, &#123; name: 'Jimmy Gosling', linesOfCode: 150 &#125;, &#123; name: 'Gracie Hopper', linesOfCode: 1000 &#125;];var totalOutput = programmerOutput .map((programmer) =&gt; programmer.linesOfCode) .reduce((acc, linesOfCode) =&gt; acc + linesOfCode, 0); 回到目录 封装判断条件反例:123if (fsm.state === 'fetching' &amp;&amp; isEmpty(listNode)) &#123; /// ...&#125; 正例:1234567function shouldShowSpinner(fsm, listNode) &#123; return fsm.state === 'fetching' &amp;&amp; isEmpty(listNode);&#125;if (shouldShowSpinner(fsmInstance, listNodeInstance)) &#123; // ...&#125; 回到目录 避免“否定情况”的判断反例:1234567function isDOMNodeNotPresent(node) &#123; // ...&#125;if (!isDOMNodeNotPresent(node)) &#123; // ...&#125; 正例:1234567function isDOMNodePresent(node) &#123; // ...&#125;if (isDOMNodePresent(node)) &#123; // ...&#125; 回到目录 避免条件判断这看起来似乎不太可能。 大多人听到这的第一反应是：“怎么可能不用 if 完成其他功能呢？”许多情况下通过使用多态(polymorphism)可以达到同样的目的。 第二个问题在于采用这种方式的原因是什么。答案是我们之前提到过的：保持函数功能的单一性。 反例:12345678910111213class Airplane &#123; //... getCruisingAltitude() &#123; switch (this.type) &#123; case '777': return getMaxAltitude() - getPassengerCount(); case 'Air Force One': return getMaxAltitude(); case 'Cessna': return getMaxAltitude() - getFuelExpenditure(); &#125; &#125;&#125; 正例:123456789101112131415161718192021222324class Airplane &#123; //...&#125;class Boeing777 extends Airplane &#123; //... getCruisingAltitude() &#123; return getMaxAltitude() - getPassengerCount(); &#125;&#125;class AirForceOne extends Airplane &#123; //... getCruisingAltitude() &#123; return getMaxAltitude(); &#125;&#125;class Cessna extends Airplane &#123; //... getCruisingAltitude() &#123; return getMaxAltitude() - getFuelExpenditure(); &#125;&#125; 回到目录 避免类型判断(part 1)JS 是弱类型语言，这意味着函数可接受任意类型的参数。 有时这会对你带来麻烦，你会对参数做一些类型判断。有许多方法可以避免这些情况。 反例:1234567function travelToTexas(vehicle) &#123; if (vehicle instanceof Bicycle) &#123; vehicle.peddle(this.currentLocation, new Location('texas')); &#125; else if (vehicle instanceof Car) &#123; vehicle.drive(this.currentLocation, new Location('texas')); &#125;&#125; 正例:123function travelToTexas(vehicle) &#123; vehicle.move(this.currentLocation, new Location('texas'));&#125; 回到目录 避免类型判断(part 2)如果需处理的数据为字符串，整型，数组等类型，无法使用多态并仍有必要对其进行类型检测时，可以考虑使用 TypeScript。 反例:12345678function combine(val1, val2) &#123; if (typeof val1 == \"number\" &amp;&amp; typeof val2 == \"number\" || typeof val1 == \"string\" &amp;&amp; typeof val2 == \"string\") &#123; return val1 + val2; &#125; else &#123; throw new Error('Must be of type String or Number'); &#125;&#125; 正例:123function combine(val1, val2) &#123; return val1 + val2;&#125; 回到目录 避免过度优化现代的浏览器在运行时会对代码自动进行优化。有时人为对代码进行优化可能是在浪费时间。 这里可以找到许多真正需要优化的地方 反例:1234567// 这里使用变量len是因为在老式浏览器中，// 直接使用正例中的方式会导致每次循环均重复计算list.length的值，// 而在现代浏览器中会自动完成优化，这一行为是没有必要的for (var i = 0, len = list.length; i &lt; len; i++) &#123; // ...&#125; 正例:123for (var i = 0; i &lt; list.length; i++) &#123; // ...&#125; 回到目录 删除无效的代码不再被调用的代码应及时删除。 反例:12345678910function oldRequestModule(url) &#123; // ...&#125;function newRequestModule(url) &#123; // ...&#125;var req = newRequestModule;inventoryTracker('apples', req, 'www.inventory-awesome.io'); 正例:123456function newRequestModule(url) &#123; // ...&#125;var req = newRequestModule;inventoryTracker('apples', req, 'www.inventory-awesome.io'); 回到目录 对象和数据结构使用 getters 和 settersJS 没有接口或类型，因此实现这一模式是很困难的，因为我们并没有类似 public 和 private 的关键词。 然而，使用 getters 和 setters 获取对象的数据远比直接使用点操作符具有优势。为什么呢？ 当需要对获取的对象属性执行额外操作时。 执行 set 时可以增加规则对要变量的合法性进行判断。 封装了内部逻辑。 在存取时可以方便的增加日志和错误处理。 继承该类时可以重载默认行为。 从服务器获取数据时可以进行懒加载。 反例:12345678910class BankAccount &#123; constructor() &#123; this.balance = 1000; &#125;&#125;let bankAccount = new BankAccount();// Buy shoes...bankAccount.balance = bankAccount.balance - 100; 正例:1234567891011121314151617class BankAccount &#123; constructor() &#123; this.balance = 1000; &#125; // It doesn't have to be prefixed with `get` or `set` to be a getter/setter withdraw(amount) &#123; if (verifyAmountCanBeDeducted(amount)) &#123; this.balance -= amount; &#125; &#125;&#125;let bankAccount = new BankAccount();// Buy shoes...bankAccount.withdraw(100); 回到目录 让对象拥有私有成员可以通过闭包完成 反例:12345678910111213var Employee = function(name) &#123; this.name = name;&#125;Employee.prototype.getName = function() &#123; return this.name;&#125;var employee = new Employee('John Doe');console.log('Employee name: ' + employee.getName()); // Employee name: John Doedelete employee.name;console.log('Employee name: ' + employee.getName()); // Employee name: undefined 正例:1234567891011121314var Employee = (function() &#123; function Employee(name) &#123; this.getName = function() &#123; return name; &#125;; &#125; return Employee;&#125;());var employee = new Employee('John Doe');console.log('Employee name: ' + employee.getName()); // Employee name: John Doedelete employee.name;console.log('Employee name: ' + employee.getName()); // Employee name: John Doe 回到目录 类单一职责原则 (SRP)如《代码整洁之道》一书中所述，“修改一个类的理由不应该超过一个”。 将多个功能塞进一个类的想法很诱人，但这将导致你的类无法达到概念上的内聚，并经常不得不进行修改。 最小化对一个类需要修改的次数是非常有必要的。如果一个类具有太多太杂的功能，当你对其中一小部分进行修改时，将很难想象到这一修够对代码库中依赖该类的其他模块会带来什么样的影响。 反例:123456789101112131415class UserSettings &#123; constructor(user) &#123; this.user = user; &#125; changeSettings(settings) &#123; if (this.verifyCredentials(user)) &#123; // ... &#125; &#125; verifyCredentials(user) &#123; // ... &#125;&#125; 正例:1234567891011121314151617181920212223class UserAuth &#123; constructor(user) &#123; this.user = user; &#125; verifyCredentials() &#123; // ... &#125;&#125;class UserSettings &#123; constructor(user) &#123; this.user = user; this.auth = new UserAuth(user) &#125; changeSettings(settings) &#123; if (this.auth.verifyCredentials()) &#123; // ... &#125; &#125;&#125; 回到目录 开/闭原则 (OCP)“代码实体(类，模块，函数等)应该易于扩展，难于修改。” 这一原则指的是我们应允许用户方便的扩展我们代码模块的功能，而不需要打开 js 文件源码手动对其进行修改。 反例:123456789101112class AjaxRequester &#123; constructor() &#123; // What if we wanted another HTTP Method, like DELETE? We would have to // open this file up and modify this and put it in manually. this.HTTP_METHODS = ['POST', 'PUT', 'GET']; &#125; get(url) &#123; // ... &#125;&#125; 正例:12345678910111213class AjaxRequester &#123; constructor() &#123; this.HTTP_METHODS = ['POST', 'PUT', 'GET']; &#125; get(url) &#123; // ... &#125; addHTTPMethod(method) &#123; this.HTTP_METHODS.push(method); &#125;&#125; 回到目录 利斯科夫替代原则 (LSP)“子类对象应该能够替换其超类对象被使用”。 也就是说，如果有一个父类和一个子类，当采用子类替换父类时不应该产生错误的结果。 反例:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354class Rectangle &#123; constructor() &#123; this.width = 0; this.height = 0; &#125; setColor(color) &#123; // ... &#125; render(area) &#123; // ... &#125; setWidth(width) &#123; this.width = width; &#125; setHeight(height) &#123; this.height = height; &#125; getArea() &#123; return this.width * this.height; &#125;&#125;class Square extends Rectangle &#123; constructor() &#123; super(); &#125; setWidth(width) &#123; this.width = width; this.height = width; &#125; setHeight(height) &#123; this.width = height; this.height = height; &#125;&#125;function renderLargeRectangles(rectangles) &#123; rectangles.forEach((rectangle) =&gt; &#123; rectangle.setWidth(4); rectangle.setHeight(5); let area = rectangle.getArea(); // BAD: Will return 25 for Square. Should be 20. rectangle.render(area); &#125;)&#125;let rectangles = [new Rectangle(), new Rectangle(), new Square()];renderLargeRectangles(rectangles); 正例:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364class Shape &#123; constructor() &#123;&#125; setColor(color) &#123; // ... &#125; render(area) &#123; // ... &#125;&#125;class Rectangle extends Shape &#123; constructor() &#123; super(); this.width = 0; this.height = 0; &#125; setWidth(width) &#123; this.width = width; &#125; setHeight(height) &#123; this.height = height; &#125; getArea() &#123; return this.width * this.height; &#125;&#125;class Square extends Shape &#123; constructor() &#123; super(); this.length = 0; &#125; setLength(length) &#123; this.length = length; &#125; getArea() &#123; return this.length * this.length; &#125;&#125;function renderLargeShapes(shapes) &#123; shapes.forEach((shape) =&gt; &#123; switch (shape.constructor.name) &#123; case 'Square': shape.setLength(5); case 'Rectangle': shape.setWidth(4); shape.setHeight(5); &#125; let area = shape.getArea(); shape.render(area); &#125;)&#125;let shapes = [new Rectangle(), new Rectangle(), new Square()];renderLargeShapes(shapes); 回到目录 接口隔离原则 (ISP)“客户端不应该依赖它不需要的接口；一个类对另一个类的依赖应该建立在最小的接口上。” 在 JS 中，当一个类需要许多参数设置才能生成一个对象时，或许大多时候不需要设置这么多的参数。此时减少对配置参数数量的需求是有益的。 反例:123456789101112131415161718192021class DOMTraverser &#123; constructor(settings) &#123; this.settings = settings; this.setup(); &#125; setup() &#123; this.rootNode = this.settings.rootNode; this.animationModule.setup(); &#125; traverse() &#123; // ... &#125;&#125;let $ = new DOMTraverser(&#123; rootNode: document.getElementsByTagName('body'), animationModule: function() &#123;&#125; // Most of the time, we won't need to animate when traversing. // ...&#125;); 正例:1234567891011121314151617181920212223242526272829class DOMTraverser &#123; constructor(settings) &#123; this.settings = settings; this.options = settings.options; this.setup(); &#125; setup() &#123; this.rootNode = this.settings.rootNode; this.setupOptions(); &#125; setupOptions() &#123; if (this.options.animationModule) &#123; // ... &#125; &#125; traverse() &#123; // ... &#125;&#125;let $ = new DOMTraverser(&#123; rootNode: document.getElementsByTagName('body'), options: &#123; animationModule: function() &#123;&#125; &#125;&#125;); 回到目录 依赖反转原则 (DIP)该原则有两个核心点： 高层模块不应该依赖于低层模块。他们都应该依赖于抽象接口。 抽象接口应该脱离具体实现，具体实现应该依赖于抽象接口。 反例:12345678910111213141516171819202122232425262728class InventoryTracker &#123; constructor(items) &#123; this.items = items; // BAD: We have created a dependency on a specific request implementation. // We should just have requestItems depend on a request method: `request` this.requester = new InventoryRequester(); &#125; requestItems() &#123; this.items.forEach((item) =&gt; &#123; this.requester.requestItem(item); &#125;); &#125;&#125;class InventoryRequester &#123; constructor() &#123; this.REQ_METHODS = ['HTTP']; &#125; requestItem(item) &#123; // ... &#125;&#125;let inventoryTracker = new InventoryTracker(['apples', 'bananas']);inventoryTracker.requestItems(); 正例:12345678910111213141516171819202122232425262728293031323334353637class InventoryTracker &#123; constructor(items, requester) &#123; this.items = items; this.requester = requester; &#125; requestItems() &#123; this.items.forEach((item) =&gt; &#123; this.requester.requestItem(item); &#125;); &#125;&#125;class InventoryRequesterV1 &#123; constructor() &#123; this.REQ_METHODS = ['HTTP']; &#125; requestItem(item) &#123; // ... &#125;&#125;class InventoryRequesterV2 &#123; constructor() &#123; this.REQ_METHODS = ['WS']; &#125; requestItem(item) &#123; // ... &#125;&#125;// By constructing our dependencies externally and injecting them, we can easily// substitute our request module for a fancy new one that uses WebSockets.let inventoryTracker = new InventoryTracker(['apples', 'bananas'], new InventoryRequesterV2());inventoryTracker.requestItems(); 回到目录 使用 ES6 的 classes 而不是 ES5 的 Function典型的 ES5 的类(function)在继承、构造和方法定义方面可读性较差。 当需要继承时，优先选用 classes。 但是，当在需要更大更复杂的对象时，最好优先选择更小的 function 而非 classes。 反例:1234567891011121314151617181920212223242526272829303132333435var Animal = function(age) &#123; if (!(this instanceof Animal)) &#123; throw new Error(\"Instantiate Animal with `new`\"); &#125; this.age = age;&#125;;Animal.prototype.move = function() &#123;&#125;;var Mammal = function(age, furColor) &#123; if (!(this instanceof Mammal)) &#123; throw new Error(\"Instantiate Mammal with `new`\"); &#125; Animal.call(this, age); this.furColor = furColor;&#125;;Mammal.prototype = Object.create(Animal.prototype);Mammal.prototype.constructor = Mammal;Mammal.prototype.liveBirth = function() &#123;&#125;;var Human = function(age, furColor, languageSpoken) &#123; if (!(this instanceof Human)) &#123; throw new Error(\"Instantiate Human with `new`\"); &#125; Mammal.call(this, age, furColor); this.languageSpoken = languageSpoken;&#125;;Human.prototype = Object.create(Mammal.prototype);Human.prototype.constructor = Human;Human.prototype.speak = function() &#123;&#125;; 正例:12345678910111213141516171819202122232425class Animal &#123; constructor(age) &#123; this.age = age; &#125; move() &#123;&#125;&#125;class Mammal extends Animal &#123; constructor(age, furColor) &#123; super(age); this.furColor = furColor; &#125; liveBirth() &#123;&#125;&#125;class Human extends Mammal &#123; constructor(age, furColor, languageSpoken) &#123; super(age, furColor); this.languageSpoken = languageSpoken; &#125; speak() &#123;&#125;&#125; 回到目录 使用方法链这里我们的理解与《代码整洁之道》的建议有些不同。 有争论说方法链不够干净且违反了德米特法则，也许这是对的，但这种方法在 JS 及许多库(如 JQuery)中显得非常实用。 因此，我认为在 JS 中使用方法链是非常合适的。在 class 的函数中返回 this，能够方便的将类需要执行的多个方法链接起来。 反例:1234567891011121314151617181920212223242526272829class Car &#123; constructor() &#123; this.make = 'Honda'; this.model = 'Accord'; this.color = 'white'; &#125; setMake(make) &#123; this.name = name; &#125; setModel(model) &#123; this.model = model; &#125; setColor(color) &#123; this.color = color; &#125; save() &#123; console.log(this.make, this.model, this.color); &#125;&#125;let car = new Car();car.setColor('pink');car.setMake('Ford');car.setModel('F-150')car.save(); 正例:1234567891011121314151617181920212223242526272829303132333435class Car &#123; constructor() &#123; this.make = 'Honda'; this.model = 'Accord'; this.color = 'white'; &#125; setMake(make) &#123; this.name = name; // NOTE: Returning this for chaining return this; &#125; setModel(model) &#123; this.model = model; // NOTE: Returning this for chaining return this; &#125; setColor(color) &#123; this.color = color; // NOTE: Returning this for chaining return this; &#125; save() &#123; console.log(this.make, this.model, this.color); &#125;&#125;let car = new Car() .setColor('pink') .setMake('Ford') .setModel('F-150') .save(); 回到目录 优先使用组合模式而非继承在著名的设计模式一书中提到，应多使用组合模式而非继承。 这么做有许多优点，在想要使用继承前，多想想能否通过组合模式满足需求吧。 那么，在什么时候继承具有更大的优势呢？这取决于你的具体需求，但大多情况下，可以遵守以下三点： 继承关系表现为”是一个”而非”有一个”(如动物-&gt;人 和 用户-&gt;用户细节) 可以复用基类的代码(“Human”可以看成是”All animal”的一种) 希望当基类改变时所有派生类都受到影响(如修改”all animals”移动时的卡路里消耗量) 反例:12345678910111213141516171819class Employee &#123; constructor(name, email) &#123; this.name = name; this.email = email; &#125; // ...&#125;// Bad because Employees \"have\" tax data. EmployeeTaxData is not a type of Employeeclass EmployeeTaxData extends Employee &#123; constructor(ssn, salary) &#123; super(); this.ssn = ssn; this.salary = salary; &#125; // ...&#125; 正例:123456789101112131415161718192021class Employee &#123; constructor(name, email) &#123; this.name = name; this.email = email; &#125; setTaxData(ssn, salary) &#123; this.taxData = new EmployeeTaxData(ssn, salary); &#125; // ...&#125;class EmployeeTaxData &#123; constructor(ssn, salary) &#123; this.ssn = ssn; this.salary = salary; &#125; // ...&#125; 回到目录 测试一些好的覆盖工具。 一些好的 JS 测试框架。 单一的测试每个概念反例:12345678910111213141516171819const assert = require('assert');describe('MakeMomentJSGreatAgain', function() &#123; it('handles date boundaries', function() &#123; let date; date = new MakeMomentJSGreatAgain('1/1/2015'); date.addDays(30); date.shouldEqual('1/31/2015'); date = new MakeMomentJSGreatAgain('2/1/2016'); date.addDays(28); assert.equal('02/29/2016', date); date = new MakeMomentJSGreatAgain('2/1/2015'); date.addDays(28); assert.equal('03/01/2015', date); &#125;);&#125;); 正例:123456789101112131415161718192021const assert = require('assert');describe('MakeMomentJSGreatAgain', function() &#123; it('handles 30-day months', function() &#123; let date = new MakeMomentJSGreatAgain('1/1/2015'); date.addDays(30); date.shouldEqual('1/31/2015'); &#125;); it('handles leap year', function() &#123; let date = new MakeMomentJSGreatAgain('2/1/2016'); date.addDays(28); assert.equal('02/29/2016', date); &#125;); it('handles non-leap year', function() &#123; let date = new MakeMomentJSGreatAgain('2/1/2015'); date.addDays(28); assert.equal('03/01/2015', date); &#125;);&#125;); 回到目录 并发用 Promises 替代回调回调不够整洁并会造成大量的嵌套。ES6 内嵌了 Promises，使用它吧。 反例:1234567891011121314require('request').get('https://en.wikipedia.org/wiki/Robert_Cecil_Martin', function(err, response) &#123; if (err) &#123; console.error(err); &#125; else &#123; require('fs').writeFile('article.html', response.body, function(err) &#123; if (err) &#123; console.error(err); &#125; else &#123; console.log('File written'); &#125; &#125;) &#125;&#125;) 正例:12345678910require('request-promise').get('https://en.wikipedia.org/wiki/Robert_Cecil_Martin') .then(function(response) &#123; return require('fs-promise').writeFile('article.html', response); &#125;) .then(function() &#123; console.log('File written'); &#125;) .catch(function(err) &#123; console.error(err); &#125;) 回到目录 Async/Await 是较 Promises 更好的选择Promises 是较回调而言更好的一种选择，但 ES7 中的 async 和 await 更胜过 Promises。 在能使用 ES7 特性的情况下可以尽量使用他们替代 Promises。 反例:12345678910require('request-promise').get('https://en.wikipedia.org/wiki/Robert_Cecil_Martin') .then(function(response) &#123; return require('fs-promise').writeFile('article.html', response); &#125;) .then(function() &#123; console.log('File written'); &#125;) .catch(function(err) &#123; console.error(err); &#125;) 正例:123456789101112async function getCleanCodeArticle() &#123; try &#123; var request = await require('request-promise') var response = await request.get('https://en.wikipedia.org/wiki/Robert_Cecil_Martin'); var fileHandle = await require('fs-promise'); await fileHandle.writeFile('article.html', response); console.log('File written'); &#125; catch(err) &#123; console.log(err); &#125;&#125; 回到目录 错误处理错误抛出是个好东西！这使得你能够成功定位运行状态中的程序产生错误的位置。 别忘了捕获错误对捕获的错误不做任何处理是没有意义的。 代码中 try/catch 的意味着你认为这里可能出现一些错误，你应该对这些可能的错误存在相应的处理方案。 反例:12345try &#123; functionThatMightThrow();&#125; catch (error) &#123; console.log(error);&#125; 正例:1234567891011try &#123; functionThatMightThrow();&#125; catch (error) &#123; // One option (more noisy than console.log): console.error(error); // Another option: notifyUserOfError(error); // Another option: reportErrorToService(error); // OR do all three!&#125; 不要忽略被拒绝的 promises理由同 try/catch。 反例:1234567getdata().then(data =&gt; &#123; functionThatMightThrow(data);&#125;).catch(error =&gt; &#123; console.log(error);&#125;); 正例:12345678910111213getdata().then(data =&gt; &#123; functionThatMightThrow(data);&#125;).catch(error =&gt; &#123; // One option (more noisy than console.log): console.error(error); // Another option: notifyUserOfError(error); // Another option: reportErrorToService(error); // OR do all three!&#125;); 回到目录 格式化格式化是一件主观的事。如同这里的许多规则一样，这里并没有一定/立刻需要遵守的规则。可以在这里完成格式的自动化。 大小写一致JS 是弱类型语言，合理的采用大小写可以告诉你关于变量/函数等的许多消息。 这些规则是主观定义的，团队可以根据喜欢进行选择。重点在于无论选择何种风格，都需要注意保持一致性。 反例:1234567891011var DAYS_IN_WEEK = 7;var daysInMonth = 30;var songs = ['Back In Black', 'Stairway to Heaven', 'Hey Jude'];var Artists = ['ACDC', 'Led Zeppelin', 'The Beatles'];function eraseDatabase() &#123;&#125;function restore_database() &#123;&#125;class animal &#123;&#125;class Alpaca &#123;&#125; 正例:1234567891011var DAYS_IN_WEEK = 7;var DAYS_IN_MONTH = 30;var songs = ['Back In Black', 'Stairway to Heaven', 'Hey Jude'];var artists = ['ACDC', 'Led Zeppelin', 'The Beatles'];function eraseDatabase() &#123;&#125;function restoreDatabase() &#123;&#125;class Animal &#123;&#125;class Alpaca &#123;&#125; 回到目录 调用函数的函数和被调函数应放在较近的位置当函数间存在相互调用的情况时，应将两者置于较近的位置。 理想情况下，应将调用其他函数的函数写在被调用函数的上方。 反例:1234567891011121314151617181920212223242526272829303132333435class PerformanceReview &#123; constructor(employee) &#123; this.employee = employee; &#125; lookupPeers() &#123; return db.lookup(this.employee, 'peers'); &#125; lookupMananger() &#123; return db.lookup(this.employee, 'manager'); &#125; getPeerReviews() &#123; let peers = this.lookupPeers(); // ... &#125; perfReview() &#123; getPeerReviews(); getManagerReview(); getSelfReview(); &#125; getManagerReview() &#123; let manager = this.lookupManager(); &#125; getSelfReview() &#123; // ... &#125;&#125;let review = new PerformanceReview(user);review.perfReview(); 正例:1234567891011121314151617181920212223242526272829303132333435class PerformanceReview &#123; constructor(employee) &#123; this.employee = employee; &#125; perfReview() &#123; getPeerReviews(); getManagerReview(); getSelfReview(); &#125; getPeerReviews() &#123; let peers = this.lookupPeers(); // ... &#125; lookupPeers() &#123; return db.lookup(this.employee, 'peers'); &#125; getManagerReview() &#123; let manager = this.lookupManager(); &#125; lookupMananger() &#123; return db.lookup(this.employee, 'manager'); &#125; getSelfReview() &#123; // ... &#125;&#125;let review = new PerformanceReview(employee);review.perfReview(); 回到目录 注释只对存在一定业务逻辑复杂性的代码进行注释注释并不是必须的，好的代码是能够让人一目了然，不用过多无谓的注释。 反例:1234567891011121314151617function hashIt(data) &#123; // The hash var hash = 0; // Length of string var length = data.length; // Loop through every character in data for (var i = 0; i &lt; length; i++) &#123; // Get character code. var char = data.charCodeAt(i); // Make the hash hash = ((hash &lt;&lt; 5) - hash) + char; // Convert to 32-bit integer hash = hash &amp; hash; &#125;&#125; 正例:12345678910111213function hashIt(data) &#123; var hash = 0; var length = data.length; for (var i = 0; i &lt; length; i++) &#123; var char = data.charCodeAt(i); hash = ((hash &lt;&lt; 5) - hash) + char; // Convert to 32-bit integer hash = hash &amp; hash; &#125;&#125; 回到目录 不要在代码库中遗留被注释掉的代码版本控制的存在是有原因的。让旧代码存在于你的 history 里吧。 反例:1234doStuff();// doOtherStuff();// doSomeMoreStuff();// doSoMuchStuff(); 正例:1doStuff(); 回到目录 不需要版本更新类型注释记住，我们可以使用版本控制。废代码、被注释的代码及用注释记录代码中的版本更新说明都是没有必要的。 需要时可以使用 git log 获取历史版本。 反例:123456789/** * 2016-12-20: Removed monads, didn't understand them (RM) * 2016-10-01: Improved using special monads (JP) * 2016-02-03: Removed type-checking (LI) * 2015-03-14: Added combine with type-checking (JR) */function combine(a, b) &#123; return a + b;&#125; 正例:123function combine(a, b) &#123; return a + b;&#125; 回到目录 避免位置标记这些东西通常只能代码麻烦，采用适当的缩进就可以了。 反例:1234567891011121314////////////////////////////////////////////////////////////////////////////////// Scope Model Instantiation////////////////////////////////////////////////////////////////////////////////let $scope.model = &#123; menu: 'foo', nav: 'bar'&#125;;////////////////////////////////////////////////////////////////////////////////// Action setup////////////////////////////////////////////////////////////////////////////////let actions = function() &#123; // ...&#125; 正例:12345678let $scope.model = &#123; menu: 'foo', nav: 'bar'&#125;;let actions = function() &#123; // ...&#125; 回到目录 避免在源文件中写入法律评论将你的 LICENSE 文件置于源码目录树的根目录。 反例:123456789101112131415161718192021222324252627/*The MIT License (MIT)Copyright (c) 2016 Ryan McDermottPermission is hereby granted, free of charge, to any person obtaining a copyof this software and associated documentation files (the \"Software\"), to dealin the Software without restriction, including without limitation the rightsto use, copy, modify, merge, publish, distribute, sublicense, and/or sellcopies of the Software, and to permit persons to whom the Software isfurnished to do so, subject to the following conditions:The above copyright notice and this permission notice shall be included in allcopies or substantial portions of the Software.THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS ORIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THEAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHERLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THESOFTWARE*/function calculateBill() &#123; // ...&#125; 正例:123function calculateBill() &#123; // ...&#125; 回到目录","tags":[{"name":"javascript","slug":"javascript","permalink":"http://yoursite.com/tags/javascript/"}]},{"title":"HTTP状态码","date":"2017-04-09T12:36:27.352Z","path":"2017/04/09/HTTP状态码/","text":"HTTP状态码 100 请求者应继续进行请求。服务器返回此代码以表示，服务器已收到某项请求的第一部分，正等待接收剩余部分。 101 请求者已要求服务器切换协议，服务器已确认并准备切换。 200 服务器已成功处理相应请求。通常，这表示服务器提供了请求的网页。如果您的 robots.txt 文件显示为此状态，则表示 Googlebot 已成功检索到该文件。 201 请求成功且服务器创建了新的资源。 202 服务器已接受相应请求，但尚未对其进行处理。 203 服务器已成功处理相应请求，但返回了可能来自另一来源的信息。 204 服务器已成功处理相应请求，但未返回任何内容。 205 服务器已成功处理相应请求，但未返回任何内容。与 204 响应不同，此响应要求请求者重置文档视图（例如清除表单内容以输入新内容） 206 服务器成功处理了部分 GET 请求。 300 服务器可以根据请求来执行多项操作，例如：按照请求者（用户代理）的要求来选择某项操作或者展示列表以便请求者选择其中某项操作。 301 请求的网页已被永久迁移至新位置。服务器返回此响应（作为对 GET 或 HEAD 请求的响应）时，会自动将请求者转到新位置。您应使用此代码通知 Googlebot 某个网页或网站已被永久迁移至新位置。 302 服务器目前正从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。此代码与响应 GET 和 HEAD 请求的 301 代码类似，会自动将请求者转到不同的位置。但由于 Googlebot 会继续抓取原有位置并将其编入索引，因此您不应使用此代码来通知 Googlebot 某个页面或网站已被迁移。 303 当请求者应对不同的位置进行单独的 GET 请求以检索响应时，服务器会返回此代码。对于除 HEAD 请求之外的所有请求，服务器会自动转到其他位置。 304 请求的网页自上次请求后再也没有修改过。当服务器返回此响应时，不会返回相关网页的内容。如果网页自请求者上次请求后再也没有更改过，您应当将服务器配置为返回此响应（称为 If Modified-Since HTTP 标头）。服务器可以告诉 Googlebot 自从上次抓取后网页没有变更，进而节省带宽和开销。 305 请求者只能使用代理访问请求的网页。如果服务器返回此响应，那么服务器还会指明请求者应当使用的代理。 307 服务器目前正从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。此代码与响应 GET 和 HEAD 请求的 301 代码类似，会自动将请求者转到不同的位置。但由于 Googlebot 会继续抓取原有位置并将其编入索引，因此您不应使用此代码来通知 Googlebot 某个页面或网站已被迁移。 400 服务器不理解请求的语法。 401 请求要求进行身份验证。登录后，服务器可能会返回对页面的此响应。 403 服务器正在拒绝相应请求。如果 Googlebot 在尝试抓取网站的有效网页时收到此状态代码（您可在 Google Search Console 中运行状况下的抓取错误页上进行查看），则可能是因为您的服务器或主机正在阻止 Googlebot 进行访问。 404 服务器找不到请求的网页。例如，如果相应请求是针对服务器上不存在的网页进行的，那么服务器通常会返回此代码。如果您的网站上没有 robots.txt 文件，而您在 Google Search Console 中的已拦截的网址页上看到此状态，那么这就是正确的状态。但是，如果您有 robots.txt 文件而又看到此状态，则说明您的 robots.txt 文件可能命名错误或位于错误的位置（该文件应当位于顶级域名上，且应当名为 robots.txt）。如果您在 Googlebot 尝试抓取的网址上看到此状态，那么这表示 Googlebot 追踪的可能是另一网页中的无效链接（旧链接或输入有误的链接）。 405 禁用请求中所指定的方法。 406 无法使用请求的内容特性来响应请求的网页。 407 此状态代码与 401（未授权）类似，但却指定了请求者应当使用代理进行授权。如果服务器返回此响应，那么，服务器还会指明请求者应当使用的代理。 408 服务器等待请求超时。 409 服务器在完成请求时遇到冲突。服务器必须在响应中包含该冲突的相关信息。服务器在响应与前一个请求相冲突的 PUT 请求时可能会返回此代码，同时会提供两个请求的差异列表。 410 如果请求的资源已被永久移除，那么，服务器会返回此响应。该代码与 404（未找到）代码类似，但在资源以前有但现在已经不复存在的情况下，有时会替代 404 代码出现。如果资源已被永久删除，那么，您应当使用 301 代码指定该资源的新位置。 411 服务器不会接受包含无效内容长度标头字段的请求。 412 服务器未满足请求者在请求中设置的其中一个前提条件。 413 服务器无法处理请求，因为请求实体过大，已超出服务器的处理能力。 414 请求的 URI（通常为网址）过长，服务器无法进行处理。 415 请求的格式不受请求页面的支持。 416 如果相应请求是针对网页的无效范围进行的，那么服务器会返回此状态代码。 417 服务器未满足“期望”请求标头字段的要求。 500 服务器遇到错误，无法完成请求。 501 服务器不具备完成相应请求的功能。例如，当服务器无法识别请求方法时，可能便会返回此代码。 502 服务器作为网关或代理，从上游服务器收到了无效的响应。 503 目前无法使用服务器（由于超载或进行停机维护）。通常，这只是一种暂时的状态。 504 服务器作为网关或代理，未及时从上游服务器接收请求。 505 服务器不支持相应请求中所用的 HTTP 协议版本。","tags":[{"name":"HTTP","slug":"HTTP","permalink":"http://yoursite.com/tags/HTTP/"}]},{"title":"Java8 Lambda表达式","date":"2017-04-09T12:05:07.732Z","path":"2017/04/09/Java8 Lambda表达式/","text":"Java8 Lambda表达式1. 什么是λ表达式 λ表达式本质上是一个匿名方法。让我们来看下面这个例子： public int add(int x, int y) { return x + y; } 转成λ表达式后是这个样子： (int x, int y) -&gt; x + y; 参数类型也可以省略，Java编译器会根据上下文推断出来： (x, y) -&gt; x + y; //返回两数之和 或者 (x, y) -&gt; { return x + y; } //显式指明返回值 可见λ表达式有三部分组成：参数列表，箭头（-&gt;），以及一个表达式或语句块。 下面这个例子里的λ表达式没有参数，也没有返回值（相当于一个方法接受0个参数，返回void，其实就是Runnable里run方法的一个实现）： () -&gt; { System.out.println(&quot;Hello Lambda!&quot;); } 如果只有一个参数且可以被Java推断出类型，那么参数列表的括号也可以省略： c -&gt; { return c.size(); } 2. λ表达式的类型（它是Object吗？） λ表达式可以被当做是一个Object（注意措辞）。λ表达式的类型，叫做“目标类型（target type）”。λ表达式的目标类型是“函数接口（functional interface）”，这是Java8新引入的概念。它的定义是：一个接口，如果只有一个显式声明的抽象方法，那么它就是一个函数接口。一般用@FunctionalInterface标注出来（也可以不标）。举例如下： @FunctionalInterface public interface Runnable { void run(); } public interface Callable&lt;V&gt; { V call() throws Exception; } public interface ActionListener { void actionPerformed(ActionEvent e); } public interface Comparator&lt;T&gt; { int compare(T o1, T o2); boolean equals(Object obj); } 注意最后这个Comparator接口。它里面声明了两个方法，貌似不符合函数接口的定义，但它的确是函数接口。这是因为equals方法是Object的，所有的接口都会声明Object的public方法——虽然大多是隐式的。所以，Comparator显式的声明了equals不影响它依然是个函数接口。 你可以用一个λ表达式为一个函数接口赋值： Runnable r1 = () -&gt; {System.out.println(&quot;Hello Lambda!&quot;);}; 然后再赋值给一个Object： Object obj = r1; 但却不能这样干： Object obj = () -&gt; {System.out.println(&quot;Hello Lambda!&quot;);}; // ERROR! Object is not a functional interface! 必须显式的转型成一个函数接口才可以： Object o = (Runnable) () -&gt; { System.out.println(&quot;hi&quot;); }; // correct 一个λ表达式只有在转型成一个函数接口后才能被当做Object使用。所以下面这句也不能编译： System.out.println( () -&gt; {} ); //错误! 目标类型不明 必须先转型: System.out.println( (Runnable)() -&gt; {} ); // 正确 假设你自己写了一个函数接口，长的跟Runnable一模一样： @FunctionalInterface public interface MyRunnable { public void run(); } 那么 Runnable r1 = () -&gt; {System.out.println(&quot;Hello Lambda!&quot;);}; MyRunnable2 r2 = () -&gt; {System.out.println(&quot;Hello Lambda!&quot;);}; JDK预定义了很多函数接口以避免用户重复定义。最典型的是Function： @FunctionalInterface public interface Function&lt;T, R&gt; { R apply(T t); } 这个接口代表一个函数，接受一个T类型的参数，并返回一个R类型的返回值。 另一个预定义函数接口叫做Consumer，跟Function的唯一不同是它没有返回值。 @FunctionalInterface public interface Consumer&lt;T&gt; { void accept(T t); } 还有一个Predicate，用来判断某项条件是否满足。经常用来进行筛滤操作： @FunctionalInterface public interface Predicate&lt;T&gt; { boolean test(T t); } 综上所述，一个λ表达式其实就是定义了一个匿名方法，只不过这个方法必须符合至少一个函数接口。 3. λ表达式的使用 3.1 λ表达式用在何处 λ表达式主要用于替换以前广泛使用的内部匿名类，各种回调，比如事件响应器、传入Thread类的Runnable等。看下面的例子： Thread oldSchool = new Thread( new Runnable () { @Override public void run() { System.out.println(&quot;This is from an anonymous class.&quot;); } } ); Thread gaoDuanDaQiShangDangCi = new Thread( () -&gt; { System.out.println(&quot;This is from an anonymous method (lambda exp).&quot;); } ); 注意第二个线程里的λ表达式，你并不需要显式地把它转成一个Runnable，因为Java能根据上下文自动推断出来：一个Thread的构造函数接受一个Runnable参数，而传入的λ表达式正好符合其run()函数，所以Java编译器推断它为Runnable。 从形式上看，λ表达式只是为你节省了几行代码。但将λ表达式引入Java的动机并不仅仅为此。Java8有一个短期目标和一个长期目标。短期目标是：配合“集合类批处理操作”的内部迭代和并行处理（下面将要讲到）；长期目标是将Java向函数式编程语言这个方向引导（并不是要完全变成一门函数式编程语言，只是让它有更多的函数式编程语言的特性），也正是由于这个原因，Oracle并没有简单地使用内部类去实现λ表达式，而是使用了一种更动态、更灵活、易于将来扩展和改变的策略（invokedynamic）。 3.2 λ表达式与集合类批处理操作（或者叫块操作） 上文提到了集合类的批处理操作。这是Java8的另一个重要特性，它与λ表达式的配合使用乃是Java8的最主要特性。集合类的批处理操作API的目的是实现集合类的“内部迭代”，并期望充分利用现代多核CPU进行并行计算。Java8之前集合类的迭代（Iteration）都是外部的，即客户代码。而内部迭代意味着改由Java类库来进行迭代，而不是客户代码。例如： for(Object o: list) { // 外部迭代 System.out.println(o); } 可以写成 //forEach函数实现内部迭代 list.forEach(o -&gt; {System.out.println(o);}); 集合类（包括List）现在都有一个forEach方法，对元素进行迭代（遍历），所以我们不需要再写for循环了。forEach方法接受一个函数接口Consumer做参数，所以可以使用λ表达式。 这种内部迭代方法广泛存在于各种语言，如C++的STL算法库、Python、ruby、Scala等。 Java8为集合类引入了另一个重要概念：流（stream）。一个流通常以一个集合类实例为其数据源，然后在其上定义各种操作。流的API设计使用了管道（pipelines）模式。对流的一次操作会返回另一个流。如同IO的API或者StringBuffer的append方法那样，从而多个不同的操作可以在一个语句里串起来。看下面的例子： List&lt;Shape&gt; shapes = ... shapes.stream() .filter(s -&gt; s.getColor() == BLUE) .forEach(s -&gt; s.setColor(RED)); 首先调用stream方法，以集合类对象shapes里面的元素为数据源，生成一个流。然后在这个流上调用filter方法，挑出蓝色的，返回另一个流。最后调用forEach方法将这些蓝色的物体喷成红色。（forEach方法不再返回流，而是一个终端方法，类似于StringBuffer在调用若干append之后的那个toString） filter方法的参数是Predicate类型，forEach方法的参数是Consumer类型，它们都是函数接口，所以可以使用λ表达式。 还有一个方法叫parallelStream()，顾名思义它和stream()一样，只不过指明要并行处理，以期充分利用现代CPU的多核特性。 shapes.parallelStream(); // 或shapes.stream().parallel() 来看更多的例子。下面是典型的大数据处理方法，Filter-Map-Reduce： //给出一个String类型的数组，找出其中所有不重复的素数 public void distinctPrimary(String... numbers) { List&lt;String&gt; l = Arrays.asList(numbers); List&lt;Integer&gt; r = l.stream() .map(e -&gt; new Integer(e)) .filter(e -&gt; Primes.isPrime(e)) .distinct() .collect(Collectors.toList()); System.out.println(&quot;distinctPrimary result is: &quot; + r); } 第一步：传入一系列String（假设都是合法的数字），转成一个List，然后调用stream()方法生成流。 第二步：调用流的map方法把每个元素由String转成Integer，得到一个新的流。map方法接受一个Function类型的参数，上面介绍了，Function是个函数接口，所以这里用λ表达式。 第三步：调用流的filter方法，过滤那些不是素数的数字，并得到一个新流。filter方法接受一个Predicate类型的参数，上面介绍了，Predicate是个函数接口，所以这里用λ表达式。 第四步：调用流的distinct方法，去掉重复，并得到一个新流。这本质上是另一个filter操作。 第五步：用collect方法将最终结果收集到一个List里面去。collect方法接受一个Collector类型的参数，这个参数指明如何收集最终结果。在这个例子中，结果简单地收集到一个List中。我们也可以用Collectors.toMap(e-&gt;e, e-&gt;e)把结果收集到一个Map中，它的意思是：把结果收到一个Map，用这些素数自身既作为键又作为值。toMap方法接受两个Function类型的参数，分别用以生成键和值，Function是个函数接口，所以这里都用λ表达式。 你可能会觉得在这个例子里，List l被迭代了好多次，map，filter，distinct都分别是一次循环，效率会不好。实际并非如此。这些返回另一个Stream的方法都是“懒（lazy）”的，而最后返回最终结果的collect方法则是“急（eager）”的。在遇到eager方法之前，lazy的方法不会执行。 当遇到eager方法时，前面的lazy方法才会被依次执行。而且是管道贯通式执行。这意味着每一个元素依次通过这些管道。例如有个元素“3”，首先它被map成整数型3；然后通过filter，发现是素数，被保留下来；又通过distinct，如果已经有一个3了，那么就直接丢弃，如果还没有则保留。这样，3个操作其实只经过了一次循环。 除collect外其它的eager操作还有forEach，toArray，reduce等。 下面来看一下也许是最常用的收集器方法，groupingBy： //给出一个String类型的数组，找出其中各个素数，并统计其出现次数 public void primaryOccurrence(String... numbers) { List&lt;String&gt; l = Arrays.asList(numbers); Map&lt;Integer, Integer&gt; r = l.stream() .map(e -&gt; new Integer(e)) .filter(e -&gt; Primes.isPrime(e)) .collect( Collectors.groupingBy(p-&gt;p, Collectors.summingInt(p-&gt;1)) ); System.out.println(&quot;primaryOccurrence result is: &quot; + r); } 注意这一行： Collectors.groupingBy(p-&gt;p, Collectors.summingInt(p-&gt;1)) 它的意思是：把结果收集到一个Map中，用统计到的各个素数自身作为键，其出现次数作为值。 下面是一个reduce的例子： //给出一个String类型的数组，求其中所有不重复素数的和 public void distinctPrimarySum(String... numbers) { List&lt;String&gt; l = Arrays.asList(numbers); int sum = l.stream() .map(e -&gt; new Integer(e)) .filter(e -&gt; Primes.isPrime(e)) .distinct() .reduce(0, (x,y) -&gt; x+y); // equivalent to .sum() System.out.println(&quot;distinctPrimarySum result is: &quot; + sum); } reduce方法用来产生单一的一个最终结果。 流有很多预定义的reduce操作，如sum()，max()，min()等。 再举个现实世界里的例子比如： // 统计年龄在25-35岁的男女人数、比例 public void boysAndGirls(List&lt;Person&gt; persons) { Map&lt;Integer, Integer&gt; result = persons.parallelStream().filter(p -&gt; p.getAge()&gt;=25 &amp;&amp; p.getAge()&lt;=35). collect( Collectors.groupingBy(p-&gt;p.getSex(), Collectors.summingInt(p-&gt;1)) ); System.out.print(&quot;boysAndGirls result is &quot; + result); System.out.println(&quot;, ratio (male : female) is &quot; + (float)result.get (Person.MALE)/result.get(Person.FEMALE)); } 3.3 λ表达式的更多用法 // 嵌套的λ表达式 Callable&lt;Runnable&gt; c1 = () -&gt; () -&gt; { System.out.println(&quot;Nested lambda&quot;); }; c1.call().run(); // 用在条件表达式中 Callable&lt;Integer&gt; c2 = true ? (() -&gt; 42) : (() -&gt; 24); System.out.println(c2.call()); // 定义一个递归函数，注意须用this限定 protected UnaryOperator&lt;Integer&gt; factorial = i -&gt; i == 0 ? 1 : i * this.factorial.apply( i - 1 ); ... System.out.println(factorial.apply(3)); 在Java中，随声明随调用的方式是不行的，比如下面这样，声明了一个λ表达式(x, y) -&gt; x + y，同时企图通过传入实参(2, 3)来调用它： int five = ( (x, y) -&gt; x + y ) (2, 3); // ERROR! try to call a lambda in-place 这在C++中是可以的，但Java中不行。Java的λ表达式只能用作赋值、传参、返回值等。 4. 其它相关概念 4.1 捕获（Capture） 捕获的概念在于解决在λ表达式中我们可以使用哪些外部变量（即除了它自己的参数和内部定义的本地变量）的问题。 答案是：与内部类非常相似，但有不同点。不同点在于内部类总是持有一个其外部类对象的引用。而λ表达式呢，除非在它内部用到了其外部类（包围类）对象的方法或者成员，否则它就不持有这个对象的引用。 在Java8以前，如果要在内部类访问外部对象的一个本地变量，那么这个变量必须声明为final才行。在Java8中，这种限制被去掉了，代之以一个新的概念，“effectively final”。它的意思是你可以声明为final，也可以不声明final但是按照final来用，也就是一次赋值永不改变。换句话说，保证它加上final前缀后不会出编译错误。 在Java8中，内部类和λ表达式都可以访问effectively final的本地变量。λ表达式的例子如下： ... int tmp1 = 1; //包围类的成员变量 static int tmp2 = 2; //包围类的静态成员变量 public void testCapture() { int tmp3 = 3; //没有声明为final，但是effectively final的本地变量 final int tmp4 = 4; //声明为final的本地变量 int tmp5 = 5; //普通本地变量 Function&lt;Integer, Integer&gt; f1 = i -&gt; i + tmp1; Function&lt;Integer, Integer&gt; f2 = i -&gt; i + tmp2; Function&lt;Integer, Integer&gt; f3 = i -&gt; i + tmp3; Function&lt;Integer, Integer&gt; f4 = i -&gt; i + tmp4; Function&lt;Integer, Integer&gt; f5 = i -&gt; { tmp5 += i; // 编译错！对tmp5赋值导致它不是effectively final的 return tmp5; }; ... tmp5 = 9; // 编译错！对tmp5赋值导致它不是effectively final的 } ... Java要求本地变量final或者effectively final的原因是多线程并发问题。内部类、λ表达式都有可能在不同的线程中执行，允许多个线程同时修改一个本地变量不符合Java的设计理念。 4.2 方法引用（Method reference） 任何一个λ表达式都可以代表某个函数接口的唯一方法的匿名描述符。我们也可以使用某个类的某个具体方法来代表这个描述符，叫做方法引用。例如： Integer::parseInt //静态方法引用 System.out::print //实例方法引用 Person::new //构造器引用 下面是一组例子，教你使用方法引用代替λ表达式： //c1 与 c2 是一样的（静态方法引用） Comparator&lt;Integer&gt; c2 = (x, y) -&gt; Integer.compare(x, y); Comparator&lt;Integer&gt; c1 = Integer::compare; //下面两句是一样的（实例方法引用1） persons.forEach(e -&gt; System.out.println(e)); persons.forEach(System.out::println); //下面两句是一样的（实例方法引用2） persons.forEach(person -&gt; person.eat()); persons.forEach(Person::eat); //下面两句是一样的（构造器引用） strList.stream().map(s -&gt; new Integer(s)); strList.stream().map(Integer::new); 使用方法引用，你的程序会变得更短些。现在distinctPrimarySum方法可以改写如下： public void distinctPrimarySum(String... numbers) { List&lt;String&gt; l = Arrays.asList(numbers); int sum = l.stream().map(Integer::new).filter(Primes::isPrime).distinct().sum(); System.out.println(&quot;distinctPrimarySum result is: &quot; + sum); } 还有一些其它的方法引用: super::toString //引用某个对象的父类方法 String[]::new //引用一个数组的构造器 4.3 默认方法（Default method） Java8中，接口声明里可以有方法实现了，叫做默认方法。在此之前，接口里的方法全部是抽象方法。 public interface MyInterf { String m1(); default String m2() { return &quot;Hello default method!&quot;; } } 这实际上混淆了接口和抽象类，但一个类仍然可以实现多个接口，而只能继承一个抽象类。 这么做的原因是：由于Collection库需要为批处理操作添加新的方法，如forEach()，stream()等，但是不能修改现有的Collection接口——如果那样做的话所有的实现类都要进行修改，包括很多客户自制的实现类。所以只好使用这种妥协的办法。 如此一来，我们就面临一种类似多继承的问题。如果类Sub继承了两个接口，Base1和Base2，而这两个接口恰好具有完全相同的两个默认方法，那么就会产生冲突。这时Sub类就必须通过重载来显式指明自己要使用哪一个接口的实现（或者提供自己的实现）： public class Sub implements Base1, Base2 { public void hello() { Base1.super.hello(); //使用Base1的实现 } } 除了默认方法，Java8的接口也可以有静态方法的实现： public interface MyInterf { String m1(); default String m2() { return &quot;Hello default method!&quot;; } static String m3() { return &quot;Hello static method in Interface!&quot;; } } 4.4 生成器函数（Generator function） 有时候一个流的数据源不一定是一个已存在的集合对象，也可能是个“生成器函数”。一个生成器函数会产生一系列元素，供给一个流。Stream.generate(Supplier s)就是一个生成器函数。其中参数Supplier是一个函数接口，里面有唯一的抽象方法 get()。 下面这个例子生成并打印5个随机数： Stream.generate(Math::random).limit(5).forEach(System.out::println); 注意这个limit(5)，如果没有这个调用，那么这条语句会永远地执行下去。也就是说这个生成器是无穷的。这种调用叫做终结操作，或者短路（short-circuiting）操作。","tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]},{"title":"java类加载机制","date":"2017-04-07T06:39:29.810Z","path":"2017/04/07/java类加载机制/","text":"类加载过程 大致过程java中的类只有被JVM加载之后才能在程序中使用，加载的过程大致为加载-连接-初始化，其中连接又分为验证-准备-解析。所以细分为加载-验证-准备-解析-初始化五个阶段。其中加载、验证、准备和初始化这四个阶段发生的顺序是确定的，而解析阶段则不一定，有时为了动态绑定也会以在初始化阶段之后开始。类生命周期： 类加载的条件JVM肯定不会无缘无故就去加载.class，只有主动使用时才会初始化。主动使用有以下几种情况： 当创建一个类的实例时，比如使用new或者反射，克隆，反序列化。 当调用类的静态方法时，即使用了字节码invokestatic指令。 当时用类或接口的静态字段时(final常量除外)，即使用了字节码的getstatic和putstatic指令。 当使用了java.lang.reflect包中的方法反射类的方法时。 当初始化子类时，要求先初始化父类。 作为启动虚拟机，含有main()方法那个类。 12345678910111213141516public class Parent&#123; static&#123; System.out.println(&quot;parent init&quot;); &#125; public static int v=100;&#125;public class Child extends Parent&#123; static&#123; System.out.println(&quot;child init&quot;); &#125;&#125;public class Main&#123; public static void main(String args[])&#123; System.out.println(Child.v); &#125;&#125; 运行输出： 12parent init100 可以看到只有父类被初始化，子类没有。可见，引用一个子类时(例子中的v)，只有直接定义该字段的类(例子中的父类)，才会被初始化。注意，child虽然没有被初始化但是已经被加载。 类加载的过程-加载 目的：查找并加载类的二进制数据 加载一个类时，JVM需要完成的工作。 通过类的全名，获取类的二进制数据流。 解析类的二进制数据流为方法区内的数据结构。 创建java.lang.Class类的实例，表示该类型。 类加载的过程-验证 目的：确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。 验证阶段是非常重要的，但不是必须的，它对程序运行期没有影响。如果所引用的类经过反复验证，那么可以考虑采用-Xverifynone参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间。 验证阶段大致4个阶段： 文件格式验证验证字节流是否符合Class文件格式的规范；例如：是否以0xCAFEBABE开头、主次版本号是否在当前虚拟机的处理范围之内、常量池中的常量是否有不被支持的类型。 元数据验证对字节码描述的信息进行语义分析（注意：对比javac编译阶段的语义分析），以保证其描述的信息符合Java语言规范的要求；例如：这个类是否有父类，除了java.lang.Object之外。 字节码验证通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。 符号引用验证确保解析动作能正确执行。 类加载的过程-准备 目的：为类的静态变量分配内存，并将其初始化为默认值 准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都在方法区中进行分配。 注意： 这时候进行内存分配的仅包括类变量，而不包括实例变量，实例变量会在对象实例化的时候随着对象一起分配在Java堆中； 这里所说的初始值“通常情况”下是数据类型的零值：假设一个类变量的定义为： public static int value = 123;那变量value在准备阶段过后的初始值为0而不是123，因为此时尚未开始执行任何Java方法，而把value赋值为123的putstatic指令是在程序被编译之后， 存放于类构造器方法中，所以把value赋值为123的动作将在初始化阶段才会执行。但是假设类变量value的定义为：public static final int value = 123;在准备阶段虚拟机就会根据ConstantValue的设置将value赋值为123。JAVA类变量默认值： 类加载的过程-解析目的： 把类中的符号引用转换为直接引用 解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程，解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行。 符号引用： 符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可。符号引用与虚拟机实现的内存布局无关，引用的目标并不一定已经加载到内存当中。各种虚拟机实现的内存布局可以各不相同，但是它们能接受的符号引用必须都是一致的，因为符号引用的字面量形式明确定义在Java虚拟机规范的Class文件格式中。 直接引用: 直接引用可以是直接指向目标的指针、相对偏移量或者是一个能简介定位到目标的句柄。直接引用是和虚拟机实现的内存布局息息相关的，同一个符号引用在不同虚拟机实例上翻译出来的直接引用一般不会相同。如果有了直接引用，那引用的目标必定已经在内存中存在。 类加载的过程-初始化除了在加载阶段用户应用程序可以通过自定义类加载器参与之外，其余动作均由虚拟机主导和控制。到了初始化阶段，才真正开始执行类中定义的Java程序代码（或者说是字节码）。初始化阶段是执行类构造器clinit方法的过程。在Java中对类变量进行初始值设定有两种方式：①声明类变量是指定初始值②使用静态代码块为类变量指定初始值。clinit方法 由编译器收集类中的所有类变量的赋值动作（如果仅仅只是声明，不会被收集）和静态语句块中的语句合并产生的，收集顺序按照语句在源文件中出现的顺序所决定；在静态语句块中只能访问定义在静态语句之前的变量；而对于定义在静态语句块之后的变量，可以进行赋值，但是不能够访问。 不需要显示调用父类构造器，虚拟机会保证在子类的clinit()方法执行之前，父类的clinit()方法已经执行完毕，所以，第一个被执行的clinit()方法的类肯定是java.lang.Object。 父类中定义的静态语句块优先于子类的静态语句。 此方法对类和接口都不是必须的，若类中没有静态语句块和静态变量赋值操作，则不会生成clinit()方法。 接口会生成此方法，因为对接口的字段可以进行赋值操作。执行接口的clinit()方法不需要先执行父接口的clinit()方法，只有在使用父接口的变量时，才会进行初始化；接口的实现类在初始化时也不会执行接口的clinit()方法。 此方法在多线程环境中会被正确的加锁、同步。 类加载器 类加载器种类1. Bootstrap ClassLoader(启动类加载器)一般由C++实现，是虚拟机的一部分。该类加载器主要职责是将JAVA_HOME路径下的\\lib目录中能被虚拟机识别的类库(比如rt.jar)加载到虚拟机内存中。Java程序无法直接引用该类加载器2. Extension ClassLoader(扩展类加载器)由Java实现，独立于虚拟机的外部。该类加载器主要职责将JAVA_HOME路径下的\\lib\\ext目录中的所有类库，开发者可直接使用扩展类加载器。 该加载器是由sun.misc.Launcher$ExtClassLoader实现。3 Application ClassLoader(应用程序类加载器)该加载器是由sun.misc.Launcher$AppClassLoader实现，该类加载器负责加载用户类路径上所指定的类库。开发者可通过ClassLoader.getSystemClassLoader()方法直接获取，故又称为系统类加载器。当应用程序没有自定义类加载器时，默认采用该类加载器。 双亲委托模式 如果一个类加载器收到了类加载请求，他不会尝试自己去加载，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有类加载的请求最终都应该传到顶层的启动类加载器中，只有当父类加载器反馈自己无法完成这个类加载的请求时，子类才会尝试自己加载。但也有弊端， 顶层的ClassLoader无法访问底层的ClassLoader所加载的类所造成的问题。 使用双亲委托模型来组织类加载器之间的关系，有一个显而易见的好处就是Java类随着它的类加载器一起具备了一种带有优先级的层次关系，例如java.lang.Object存放在rt.jar之中，无论那个类加载器要加载这个类，最终都是委托给启动类加载器进行加载，因此Object类在程序的各种类加载器环境中都是同一个类，相反，如果没有双亲委托模型，由各个类加载器去完成的话，如果用户自己写一个名为java.lang.Object的类，并放在classpath中，应用程序中可能会出现多个不同的Object类，java类型体系中最基本安全行为也就无法保证。 java.lang.ClassLoaderjava.lang.ClassLoader类的基本职责就是根据一个指定的类的名称，找到或者生成其对应的字节代码，然后从这些字节代码中定义出一个Java类,还负责加载 Java 应用所需的资源，如图像文件和配置文件等.ClassLoader 中与加载类相关的方法: 方法 说明 getParent() 返回该类加载器的父类加载器。 loadClass(String name) 加载名称为 name 的类，返回的结果是 java.lang.Class 类的实例。 findClass(String name) 查找名称为 name 的类，返回的结果是 java.lang.Class 类的实例。 findLoadedClass(String name) 查找名称为 name 的已经被加载过的类，返回的结果是 java.lang.Class 类的实例。 defineClass(String name, byte[] b, int off, int len) 把字节数组 b 中的内容转换成 Java 类，返回的结果是 java.lang.Class 类的实例。这个方法被声明为 final 的。 resolveClass(Class&lt;?&gt; c) 链接指定的 Java 类。 自定义类加载器定义类加载器可以选择 继承ClassLoader类，重写里面的方法来实现。loadClass()方法重写的话可能会破坏双亲委托模型，不推荐重写；defineClass：主要用于将原始字节转换为Class对象，不需要重写；findClass：根据名称来查找类，一般就重写这个方法。12345678910111213141516171819202122232425262728293031323334 public class Main &#123; static class MyClassLoader extends ClassLoader &#123; private String classPath; public MyClassLoader(String classPath) &#123; this.classPath = classPath; &#125; private byte[] loadByte(String name) throws Exception &#123; name = name.replaceAll(&quot;\\\\.&quot;, &quot;/&quot;); FileInputStream fis = new FileInputStream(classPath + &quot;/&quot; + name + &quot;.class&quot;); int len = fis.available(); byte[] data = new byte[len]; fis.read(data); fis.close(); return data; &#125; protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; try &#123; byte[] data = loadByte(name); return defineClass(name, data, 0, data.length); &#125; catch (Exception e) &#123; e.printStackTrace(); throw new ClassNotFoundException(); &#125; &#125; &#125;; public static void main(String args[]) throws Exception &#123; MyClassLoader classLoader = new MyClassLoader(&quot;D:/test&quot;); Class clazz = classLoader.loadClass(&quot;com.huachao.cl.Test&quot;); Object obj = clazz.newInstance(); Method helloMethod = clazz.getDeclaredMethod(&quot;hello&quot;, null); helloMethod.invoke(obj, null); &#125;&#125; 参考 《实战java虚拟机》 http://www.jianshu.com/p/11cc2de9dbc2 http://www.cnblogs.com/leesf456/p/5269545.html http://www.jsondream.com/2016/11/16/jvm-class-load-parent-Delegate.html https://www.ibm.com/developerworks/cn/java/j-lo-classloader/#download http://www.jianshu.com/p/acc7595f1b9d?utm_source=tuicool&amp;utm_medium=referral","tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]},{"title":"java注解总结","date":"2017-04-07T06:33:42.788Z","path":"2017/04/07/java注解总结/","text":"注解分类 源码注解： 只在源码中存在，编译成.class就不存在了。 编译时注解： 源码和.class中都存在，比如@Override，@Deprecated等 运行时注解： 在运行时注解，比如spring的@Component，@AutoWired等 标准注解 注解标识 作用 @Override 覆盖超类中的方法 @Deprecated 声明过期 @SuppressWarnings 关闭不当的编译器警告信息 自定义注解 元注解 用于自定义注解 元注解类型 @Target @Retention @Documented @Inherited @Target 定义注解将应用于什么地方,当注解未指定Target值时，此注解可以使用任何元素之上,取值(ElementType)有: TYPE: 接口、类、枚举、注解 FIELD: 字段、枚举的常量 METHOD: 方法 PARAMETER: 方法参数 CONSTRUCTOR: 构造器 LOCAL_VARIABLE: 局部变量 ANNOTATION_TYPE: 注解类型 PACKAGE: 包 TYPE_PARAMETER: 类型参数声明(1.8新增)。 比如public class MyList&lt;@MySet T&gt; {}，在定义@MySet，必须在MySet的@Target设置 ElementType.TYPE_PARAMETER ，表示这个注解可以用来标注类型参数。 TYPE_USE: 类型使用声明(1.8新增)。只要是类型名称，都可以进行注解，以下的使用注解都是可以的: 123456List&lt;@Test Comparable&gt; list1 = new ArrayList&lt;&gt;();List&lt;? extends Comparable&gt; list2 = new ArrayList&lt;@Test Comparable&gt;();@Test String text;text = (@Test String)new Object();java.util. @Test Scanner console;console = new java.util.@Test Scanner(System.in); @Retention 定义注解在哪一个级别可用，当注解未定义Retention值时，默认值是CLASS，在源代码中，类文件中或者运行时，取值(RetentionPoicy)有： SOURCE ：注解将被编译器丢弃（该类型的注解信息只会保留在源码里，源码经过编译后，注解信息会被丢弃，不会保留在编译好的class文件里) CLASS ：注解在class文件中可用，但会被JVM丢弃（该类型的注解信息会保留在源码里和class文件里，在执行的时候，不会加载到虚拟机（JVM）中） RUNTIME ：JVM将在运行期也保留注解信息，因此可以通过反射机制读取注解的信息（源码、class文件和执行的时候都有注解的信息） @Documented 用于描述其它类型的annotation应该被作为被标注的程序成员的公共API，因此可以被例如javadoc此类的工具文档化。是一个标记注解，没有成员。 @Inherited 阐述了某个被标注的类型是被继承的。如果一个使用了@Inherited修饰的annotation类型被用于一个class，则这个annotation将被用于该class的子类。是一个标记注解，没有成员。 示例 12345678@Target(&#123;ElementType.METHOD,ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Inherited@Documentedpublic @interface Desc &#123; String value(); String desc() default &quot;description：&quot;;&#125; 注意事项 注解可以设定初始值，使用default就可以实现。 注解只有一个元素的时候，该元素名称必须是value，并且在使用该注解的时候可以省略”value=”。 注解的值必须是确定的，且不能使用null作为值。 注解可能的类型： 基本类型（int,float,boolean,byte,double,char,long,short） String Class enum Annotation 以上类型的数组 如果使用了其他类型，那编译器就会报错。也不允许使用任何包装类型。注解也可以作为元素的类型，也就是注解可以嵌套。 元素的修饰符，只能用 public 或 default 编写注解解析器 要想注添加逻辑，需要反射或者字节码操作获取注解信息 被注解的测试类 123@Desc(value = &quot;test&quot;,desc = &quot;Test is a type&quot;) public class Test &#123;&#125; 反射获取注解信息 123456789101112 public class Main &#123; public static void main(String[] args) throws Exception&#123; Class&lt;?&gt; c=Class.forName(&quot;me.jcala.tip.annotation.Test&quot;); Annotation annotation=c.getAnnotation(Desc.class); if (annotation!=null)&#123; Desc desc=(Desc)annotation; System.out.println(&quot;value:&quot;+desc.value()); System.out.println(&quot;description:&quot;+desc.desc()); &#125; &#125; &#125;&#125;","tags":[{"name":"java,注解","slug":"java-注解","permalink":"http://yoursite.com/tags/java-注解/"}]},{"title":"volatile 学习","date":"2017-04-07T06:32:41.368Z","path":"2017/04/07/volatile 学习/","text":"volatile 作用: 保证变量对所有线程的可见性，即一个线程修改了某个值，新值对其他线程来说是立即可见的。(强制从公共堆栈中取得变量的值，而不是从线程私有数据栈中取得变量的值。) Java内存模型规定，对于多个线程共享的变量，存储在主内存当中，每个线程都有自己独立的工作内存（比如CPU的寄存器），线程只能访问自己的工作内存，不可以访问其它线程的工作内存。工作内存中保存了主内存共享变量的副本，线程要操作这些共享变量，只能通过操作工作内存中的副本来实现，操作完毕之后再同步回到主内存当中。volatile保在每次访问变量时都会进行一次刷新，因此每次访问都是主内存中最新的版本。 禁止指令重排序 指令重排序是JVM为了优化指令，提高程序运行效率，在不影响单线程程序执行结果的前提下，尽可能地提高并行度。但是指令重排序在多线程时会出现一些问题。如下： 1234567891011121314在线程A中:context = loadContext();inited = true;在线程B中:while(!inited )&#123; //根据线程A中对inited变量的修改决定是否使用context变量 sleep(100);&#125;doSomethingwithconfig(context);假设线程A中发生了指令重排序:inited = true;context = loadContext();那么B中很可能就会拿到一个尚未初始化或尚未初始化完成的context,从而引发程序错误。 而volatile使用内存屏障可以禁用指令重排序，避免这种问题。 与synchronized对比: volatile可以保证数据的可见性，但不可以保证原子性 synchronized可以保证原子性，也可以间接保证可见性 synchronized有volatile同步的功能 volatile性能一般高于synchronized 正确使用 volatile 变量的条件 对变量的写操作不依赖于当前值。(不能是自增自减等操作) 该变量没有包含在具有其他变量的不变式中。包含在具有其他变量的不变式中的情况(包含了一个不变式 —— 下界总是小于或等于上界)：123456789101112131415public class NumberRange &#123; private int lower, upper; public int getLower() &#123; return lower; &#125; public int getUpper() &#123; return upper; &#125; public void setLower(int value) &#123; if (value &gt; upper) throw new IllegalArgumentException(&quot;&quot;); lower = value; &#125; public void setUpper(int value) &#123; if (value &lt; lower) throw new IllegalArgumentException(&quot;&quot;); upper = value; &#125;&#125; 如果凑巧两个线程在同一时间使用不一致的值执行 setLower 和 setUpper 的话，则会使范围处于不一致的状态.例如，如果初始状态是(0, 5)，同一时间内，线程 A 调用 setLower(4) 并且线程 B 调用 setUpper(3)，显然这两个操作交叉存入的值是不符合条件的，那么两个线程都会通过用于保护不变式的检查，使得最后的范围值是 (4, 3) —— 一个无效值。 volatile可以解决的问题示例:123456789101112131415161718192021222324252627282930public class RunThread extends Thread&#123; private boolean isRunning=true; public boolean isRunning()&#123; return isRunning; &#125; public void setRunning(boolean isRunning)&#123; this.isRunning=isRunning; &#125; @Override public void run()&#123; System.out.println(&quot;进入run了&quot;); while (isRunning==true)&#123; &#125; System.out.println(&quot;线程被停止了&quot;); &#125;&#125;public class Main&#123; public static void main(String args[])&#123; try&#123; RunThread thread=new RunThread(); thread.start(); Thread.sleep(1000); thread.setRunning(false); System.out.println(&quot;已经赋值为false&quot;); &#125;catch (InterruptedException e)&#123; e.printStackTrace(); &#125; &#125;&#125; 运行时加入JVM参数, -server。查看结果发现System.out.println(“线程被停止了”);从未执行。 因为JVM被设置为-server模式时为了线程的运行效率，线程一直在私有堆栈中取得isRunning的值为true，而更新的却是公共堆栈中的isRunning。 解决方法：volatile private boolean isRunning=true; 线程工作内存和主工作内存之间通过8中原子操作实现 lock（锁定）：作用于主内存的变量，它把一个变量标识为一条线程独占的状态。 unlock（解锁）：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其它线程锁定。 read（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的load动作使用。 load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。 use（使用）：作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作。 assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。 store（存储）：作用于工作内存的变量，它把工作内存中一个变量的值传送给主内存中，以便随后的write操作使用。 write（写入）：作用于主内存的变量，它把store操作从工作内存中得到的变量的值放入主内存的变量中。 ***对于volatile修饰的变量，只能保证从主内存到工作内存的值是最新的，但像use和assign这些操作并不是原子性的，因此volatile无法保证原子性*** 使用原子类进行i++操作123456789101112131415161718192021import java.util.concurrent.atomic.AtomicInteger; public class AddCountThread extends Thread&#123; private AtomicInteger count=new AtomicInteger(0); @Override public void run()&#123; for (int i=0;i&lt;1000;i++)&#123; System.out.println(count.incrementAndGet()); &#125; &#125;&#125;public class Main&#123; public static void main(String args[])&#123; AddCountThread thread=new AddCountThread(); new Thread(thread).start(); new Thread(thread).start(); new Thread(thread).start(); new Thread(thread).start(); new Thread(thread).start(); &#125;&#125; 原子类也不完全安全123456789101112131415161718192021222324252627282930313233343536373839import java.util.concurrent.atomic.AtomicLong;public class MyService&#123; public static AtomicLong aiRef=new AtomicLong(); public void addNum()&#123; System.out.println(Thread.currentThread().getName()+&quot;加了100后的值是:&quot;+aiRef.addAndGet(100)); aiRef.addAndGet(1); &#125;&#125;public class MyThread extends Thread&#123; private MyService myService; public MyThread(MyService myService)&#123; super(); this.myService=myService; &#125; @Override public void run()&#123; myService.addNum(); &#125;&#125;public class Main&#123; public static void main(String args[])&#123; try&#123; MyService service=new MyService(); MyThread[] myThreads=new MyThread[5]; for (int i=0;i&lt;myThreads.length;i++)&#123; myThreads[i]=new MyThread(service); &#125; for (int i=0;i&lt;myThreads.length;i++)&#123; myThreads[i].start(); &#125; Thread.sleep(1000); System.out.println(service.aiRef.get()); &#125;catch (InterruptedException e)&#123; e.printStackTrace(); &#125; &#125;&#125; 运行发现打印出错，这是因为addAndGet()方法虽然是原子性的，但方法与方法之间的调用不是原子性的。 参考: JAVA多线程编程核心技术 深入理解Java虚拟机 http://www.codeceo.com/article/jvm-memory-model-visual.html?utm_source=tuicool&amp;utm_medium=referral http://www.importnew.com/23535.html?utm_source=tuicool&amp;utm_medium=referral http://www.jianshu.com/p/03a8f06ede46?utm_source=tuicool&amp;utm_medium=referral","tags":[{"name":"java,volatile","slug":"java-volatile","permalink":"http://yoursite.com/tags/java-volatile/"}]},{"title":"JPA参考手册","date":"2017-04-07T06:31:15.800Z","path":"2017/04/07/JPA参考手册/","text":"1. JPA普通注解 @Entity: 声明为一个实体。(修饰实体类) @Table: 指定实体所映射的表。(修饰实体类) 属性 是否必要 说明 name 否 设置实体映射的表名。不指定则与实体类的类名相同 catalog 否 设置实体映射的表放入指定的catalog中。不指定则放入默认的catalog中 schema 否 设置实体映射的表放入指定的schema中。 不指定则放入默认的schema中 uniqueConstraints 否 为实体映射的表设置唯一的约束。该属性可以是一个@UniqueConstraint Annotation数组 @Indexed：定义索引 12345678910111213141516@Entity@Table(name=&quot;person_table&quot;, indexes = &#123; @Index(name=&quot;idx_person&quot;, columnList=&quot;name&quot;) &#125;)@NamedQuery( name=&quot;simpleByTest&quot;, query=&quot;SELECT x FROM SimpleModel x WHERE x.test LIKE :test&quot; )public class Person &#123; @Id @GeneratedValue private Long id; private String name; //...&#125; @secondaryTable: 把实体的部分属性映射到第二个数据表。可通过@secondaryTable指定多个额外的数据表。(修饰实体类) 属性 是否必要 说明 name 否 指定新数据表的表名 catalog 否 设置实体映射的表放入指定的catalog中。不指定则放入默认的catalog中 schema 否 设置实体映射的表放入指定的schema中。 不指定则放入默认的schema中 uniqueConstraints 否 为实体映射的表设置唯一的约束。 pkJoinColumns 否 指定新数据表的一个或多个外键列，只有通过该外键列才可让新数据表中的记录参照到主表记录。该属性值是一个@PrimaryKeyJoinColumn数组 @PrimaryKeyJoinColumn: 用于定义在从表中定义的外键列的映射信息。 属性 是否必要 说明 name 否 指定从表中的外键列的列名 columnDefinition 否 指定JPA使用该属性值指定的SQL片段来创建外键列 referencedColumnName 否 指定从表中外键参照的数据列的列名 1234567891011121314@Entity@Table(name=&quot;person_table&quot;)@SecondaryTable(name=&quot;person_detail&quot;,pkJoinColumns=@PrimaryKeyJoinColumn(name=&quot;person_id&quot;))public class Person&#123;@Idprivate int id;@Column(name=&quot;person_name&quot;,length=50)private String name;@Column(table=&quot;person_detail&quot;,name=&quot;email&quot;)private String email;@Column(table=&quot;person_detail&quot;,name=&quot;phone&quot;)private String phone;&#125;指定将实体状态放入第二个person_detail数据表中，并指定email,phone两个属性放入person_detail数据表中 @Column: 指定属性映射的列信息，如列名，长度等。(修饰属性) 属性 是否必要 说明 name 否 指定该列的列名。默认为属性名 length 否 指定该列所能保存的数据的最大长度。默认为255 nullable 否 指定该列是否允许为null。默认为true unique 否 指定该列是否具有唯一约束。默认为false updatable 否 指定该列是否包含在JPA生成的update语句的列列表中。默认为true insertable 否 指定该列是否包含在JPA生成的insert语句的列列表中。默认为true @Id和@GeneratedValue：映射实体类的主键。(修饰属性)@Id定义主键，可以是基本类型，基本类型的包装类，String，Date等类型。@GeneratedValue：设置自动生成属性值，属性如下： 属性 是否必要 说明 strategy 否 使用怎样的主键生成策略。GenerationType.AUTO：JPA自动选择最适合底层数据库的主键生成策略; GenerationType.IDENTITY: 对于mysql，sqlserver这样的数据库选择自增长的主键生成策略；GenerationType.SEQUENCE: 对于oracle这样的数据库，选择使用基于sequence的主键生成策略，应与@SequenceGenderator一起使用；GenerationType.TABLE：使用一个辅助表来生成主键，应与@TableGenderator一起使用 generator 否 当使用GenerationType.SEQUENCE,GenerationType.TABLE主键生成策略时，该属性指定sequence,辅助表的名称 @Transient: 修饰不想持久保存的属性。(修饰属性) @Enumerated： 修饰枚举类型。(修饰属性) 123当@Enumerated的value属性为EnumType.STRING时，底层数据库保存的是枚举值的名称；当@Enumerated的value属性为EnumType.ORDINAL时，保存枚举值的序号。如@Enumerated(EnumType.ORDINAL). @Lob:修饰大数据类型，对应JDBC的java.sql.Clob类型或者java.sql.Blob类型。(修饰属性) 12当修饰的属性为byte[],Byte[],java.io.Serializable类型时，将映射为数据库底层的Blob列；当修饰的属性为char[],Character[]或java.lang.String类型时，映射为底层的Clob列。 @Basic：用于延迟加载操作。(修饰属性) 12345678比如JPA加载Person实体时并不需要立即加载它的pic属性，而只加载一个&quot;虚拟的&quot;代理，真正需要pic属性再从数据库加载。@Basic可以指定的属性：fetch:指定是否需要延迟加载该属性。FetchType.EAGER不使用延迟加载，Fetch.LAZY使用延迟加载。optional：指定映射的数据列是否允许使用null值。例如：@Lob@Basic(fetch=FetchType.LAZY)private byte[] pic; @Temporal: 修饰日期类型。(修饰属性) 123@Temporal可以指定一个value属性，该属性支持Temporal.DATE,Temporal.TIME,Temporal.TIMESTAMP，分别对应于数据库date,time,timestamp类型的数据列。 @Embedded和@Embeddable: 映射复合类型。@Embeadded修饰这个复合类型属性，@Embeaddable修饰这个复合类。@AttributeOverride用来指定复合类型的成员属性的映射配置，它支持的属性： 属性 是否必要 说明 name 是 指定对复合类型中哪个属性进行配置 column 是 指定该属性所映射的数据列的列名 12345678910111213141516171819@Entity@Table(name=&quot;person_table&quot;)public class Person&#123;@Idprivate int id;@Column(name=&quot;person_name&quot;,length=50)private String name;@Embedded@AttributeOverrides(&#123; @AttributeOverride(name=&quot;name&quot;,column=@Column(name=&quot;cat_name&quot;,length=35)), @AttributeOverride(name=&quot;color&quot;,column=@Column(&quot;cat_color&quot;))&#125;)private Cat cat;&#125;@Embeddablepublic class Cat&#123; private String name; private String color;&#125; @IdClass和@EmbeddedId: 定义复合类型的主键。(修饰属性)定义复合类型的主键有两种方式：(1). 使用@IdClass和多个@Id;(2). 使用一个@EmbeddedId即可。 123456789101112131415161718192021222324252627282930313233方式一：使用@IdClass和多个@Id @Entity @Table(name=&quot;person_table&quot;) @IdClass(Cat.class) public class Person&#123; //两个@Id定义联合主键 @Id private int id; @Id private String name; private Cat cat; &#125;方式二：用一个@EmbeddedId @Entity @Table(name=&quot;person_table&quot;) public class Person&#123; @Id private int id; @Column(name=&quot;person_name&quot;,length=50) private String name; @EmbeddedId @Embedded @AttributeOverrides(&#123; @AttributeOverride(name=&quot;name&quot;,column=@Column(name=&quot;cat_name&quot;,length=35)), @AttributeOverride(name=&quot;color&quot;,column=@Column(&quot;cat_color&quot;)) &#125;) private Cat cat; &#125; @Embeddable public class Cat&#123; private String name; private String color; &#125; @OrderBy: 对关联实体进行排序 123456789101112131415161718192021222324252627282930313233//Example 1: @Entity public class Course &#123; @ManyToMany @OrderBy(&quot;lastname ASC&quot;) public List&lt;Student&gt; getStudents() &#123;&#125;; &#125; //Example 2: @Entity public class Student &#123; @ManyToMany(mappedBy=&quot;students&quot;) @OrderBy // ordering by primary key is assumed public List&lt;Course&gt; getCourses() &#123;&#125;; &#125; //Example 3: @Entity public class Person &#123; @ElementCollection @OrderBy(&quot;zipcode.zip, zipcode.plusFour&quot;) public Set&lt;Address&gt; getResidences() &#123;&#125;; &#125; @Embeddable public class Address &#123; protected String street; protected String city; protected String state; @Embedded protected Zipcode zipcode; &#125; @Embeddable public class Zipcode &#123; protected String zip; protected String plusFour; &#125; @JoinColumn: 定义外键。(修饰属性) 属性 是否必要 说明 columnDefinition 否 指定JPA使用该属性值指定的SQL片段来创建外键列 name 否 指定该外键列的列名 insertable 否 指定该列是否包含在JPA生成的insert语句的列列表中。默认为true updatable 否 指定该列是否包含在JPA生成的update语句的列列表中。默认为true nullable 否 指定该列是否允许为null。默认为true table 否 指定该列所在的数据表的表名 unique 否 指定是否为该列增加唯一约束 referenceColumnName 否 指定该列所参照的主键列的列名 @ManyToOne: 映射多对一关系。(修饰属性) 属性 是否必要 说明 cascade 否 指定JPA对关联实体采用怎样的级联策略，该级联策略支持四个属性值。CascadeType.ALL：指定JPA将所有的持久化操作都级联到关联实体；CascadeType.MERGE: 指定JPA将merge操作都级联到关联实体；CascadeType.PERSIST：指定JPA将persist操作级联到关联实体；CascadeType.REFRESH: 指定JPA将refresh操作级联到关联实体；CascadeType.REMOVE: 指定JPA将remove操作关联到关联实体 fetch 否 指定抓取关联实体时抓取策略，该属性支持两个值。FetchType.EAGER: 抓取实体时，立即抓取关联实体，默认值；FetchType.LAZY：抓取实体时延迟抓取关联实体，等到真到用到时再去抓取。 optional 否 该属性指定关联关系是否可选。 targetEntity 否 该属性指定关联实体的类名。 在默认情况下，JPA通过反射判断 @OneToOne: 映射一对一关系。(修饰属性) 属性 是否必要 说明 cascade 否 指定JPA对关联实体采用怎样的级联策略，该级联策略支持四个属性值。CascadeType.ALL：指定JPA将所有的持久化操作都级联到关联实体；CascadeType.MERGE: 指定JPA将merge操作都级联到关联实体；CascadeType.PERSIST：指定JPA将persist操作级联到关联实体；CascadeType.REFRESH: 指定JPA将refresh操作级联到关联实体；CascadeType.REMOVE: 指定JPA将remove操作关联到关联实体 fetch 否 指定抓取关联实体时抓取策略，该属性支持两个值。FetchType.EAGER: 抓取实体时，立即抓取关联实体，默认值；FetchType.LAZY：抓取实体时延迟抓取关联实体，等到真到用到时再去抓取。 optional 否 该属性指定关联关系是否可选。 targetEntity 否 该属性指定关联实体的类名。 在默认情况下，JPA通过反射判断 mappedBy 否 该属性合法的属性值为关联实体的属性名，该属性指定关联实体中哪一个属性可引用到关联实体时采取抓取。 @OneToMany：映射一对多关系。(修饰属性) 属性 是否必要 说明 cascade 否 指定JPA对关联实体采用怎样的级联策略，该级联策略支持四个属性值。CascadeType.ALL：指定JPA将所有的持久化操作都级联到关联实体；CascadeType.MERGE: 指定JPA将merge操作都级联到关联实体；CascadeType.PERSIST：指定JPA将persist操作级联到关联实体；CascadeType.REFRESH: 指定JPA将refresh操作级联到关联实体；CascadeType.REMOVE: 指定JPA将remove操作关联到关联实体 fetch 否 指定抓取关联实体时抓取策略，该属性支持两个值。FetchType.EAGER: 抓取实体时，立即抓取关联实体，默认值；FetchType.LAZY：抓取实体时延迟抓取关联实体，等到真到用到时再去抓取。 targetEntity 否 该属性指定关联实体的类名。 在默认情况下，JPA通过反射判断 mappedBy 否 该属性合法的属性值为关联实体的属性名，该属性指定关联实体中哪一个属性可引用到关联实体时采取抓取。 @ManyToMany：映射多对多关系。(修饰属性) 属性 是否必要 说明 cascade 否 指定JPA对关联实体采用怎样的级联策略，该级联策略支持四个属性值。CascadeType.ALL：指定JPA将所有的持久化操作都级联到关联实体；CascadeType.MERGE: 指定JPA将merge操作都级联到关联实体；CascadeType.PERSIST：指定JPA将persist操作级联到关联实体；CascadeType.REFRESH: 指定JPA将refresh操作级联到关联实体；CascadeType.REMOVE: 指定JPA将remove操作关联到关联实体 fetch 否 指定抓取关联实体时抓取策略，该属性支持两个值。FetchType.EAGER: 抓取实体时，立即抓取关联实体，默认值；FetchType.LAZY：抓取实体时延迟抓取关联实体，等到真到用到时再去抓取。 targetEntity 否 该属性指定关联实体的类名。 在默认情况下，JPA通过反射判断 mappedBy 否 该属性合法的属性值为关联实体的属性名，该属性指定关联实体中哪一个属性可引用到关联实体时采取抓取。 @JoinTable：专门用于多对多关联关系指定连接表的配置信息。 属性 是否必要 说明 name 否 指定该连接表的表名 catalog 否 设置将该连接表放入指定的catalog内。如果没有指定该属性，连接表放入默认的catalog中。 schema 否 设置将该连接表放入指定的schema内。 如果没有指定该属性，连接表放入默认的schema中。 joinColumns 否 该属性值可接受多个@JoinColumn，用于配置连接表中外键列的列信息，这些列参照当前实体对应表的主键列 inverseJoinColumns 否 该属性值可接受多个@JoinColumn，用于配置连接表中外键列的列信息，这些列参照当前实体的关联实体对应表的主键列 uniqueConstraints 否 该属性为连接表增加唯一约束。 @MapKey: 使用Map集合记录关联实体。 MappedSuperClass: 映射为非实体父类，该实体父类不会生成对应的数据表 12345678910111213141516171819202122232425262728293031323334353637@MappedSuperclass public class Employee &#123; @Id protected Integer empId; @Version protected Integer version; @ManyToOne @JoinColumn(name=&quot;ADDR&quot;) protected Address address; public Integer getEmpId() &#123; &#125; public void setEmpId(Integer id) &#123; &#125; public Address getAddress() &#123; &#125; public void setAddress(Address addr) &#123; &#125; &#125; // Default table is FTEMPLOYEE table @Entity public class FTEmployee extends Employee &#123; // Inherited empId field mapped to FTEMPLOYEE.EMPID // Inherited version field mapped to FTEMPLOYEE.VERSION // Inherited address field mapped to FTEMPLOYEE.ADDR fk // Defaults to FTEMPLOYEE.SALARY protected Integer salary; public FTEmployee() &#123;&#125; public Integer getSalary() &#123; &#125; public void setSalary(Integer salary) &#123; &#125; &#125; @Entity @Table(name=&quot;PT_EMP&quot;) @AssociationOverride( name=&quot;address&quot;, joincolumns=@JoinColumn(name=&quot;ADDR_ID&quot;)) public class PartTimeEmployee extends Employee &#123; // Inherited empId field mapped to PT_EMP.EMPID // Inherited version field mapped to PT_EMP.VERSION // address field mapping overridden to PT_EMP.ADDR_ID fk @Column(name=&quot;WAGE&quot;) protected Float hourlyWage; public PartTimeEmployee() &#123;&#125; public Float getHourlyWage() &#123;&#125; public void setHourlyWage(Float wage) &#123;&#125; &#125; @Inheritance：指定映射策略 InheritanceType.SINGLE_TABLE： 整个类层次对应一张表策略,这是继承映射的默认策略。 InheritanceType.JOINED：连接子类策略。父亲的放在一张表，儿子只是保存和父亲不一样的，增加的属性。 InheritanceType.TABLE_PER_CLASS： 每个具体的类一个表的策略。 @DiscriminatorColumn:在整个类层次对应一张表策略的映射策略中配置辨别列。 属性 是否必要 说明 columnDefinition 否 指定JPA使用该属性值指定的SQL片段来创建外键列 name 否 指定辨别列的名称，默认值为”DTYPE” discriminatorType 否 指定该辨别者列的数据类型。 DiscriminatorType.CHAR: 辨别者列的类型是字符类型，即该列只接受单个字符；DiscriminatorType.INTEGER：辨别者列的类型是整数类型，即该列只接受整数值；DiscriminatorType.STRING：辨别者列的类型是字符串类型，即该列只接受字符串值，为默认值 length 否 该属性指定辨别者的字符长度 2. JPA生命周期注解 @PerPersist：保存实体之前回调它修饰的方法。 @PostPersist：保存实体之后回调它修饰的方法。 @PreRemove：删除实体之前回调它修饰的方法。 @PostRemove：删除实体之后回调它修饰的方法。 @PreUpdate：更新实体之前回调它修饰的方法。 @PostUpdate：更新实体之后回调它修饰的方法。 @PostLoad：记载实体之后回调它修饰的方法。 @EntityListeners: 自定义专门的监听器 123@Entity@EntityListeners(PersonListener.class)public class Person implements Serializable&#123;&#125; @ExcludeDefaultListeners和@ExcludeSuperclassListeners：排除监听器。 3. 关联 单向N-1关联：使用@ManyToOne注解。比如一个人对应多个手机号,仅通过手机号获取用户，无需获取用户的手机号的场景。当使用@JoinColumn通过外键实现，否则通过第三方表实现。1234567891011121314151617181920212223242526272829303132333435363738@Entity(name = &quot;Person&quot;)public static class Person &#123; @Id @GeneratedValue private Long id; public Person() &#123; &#125;&#125;@Entity(name = &quot;Phone&quot;)public static class Phone &#123; @Id @GeneratedValue private Long id; @Column(name = &quot;`number`&quot;) private String number; @ManyToOne(optional=false,cascade=CascadeType.ALL,fetch=FetchType.LAZY,targetEntity=Person.class) @JoinColumn(name = &quot;person_id&quot;, foreignKey = @ForeignKey(name = &quot;PERSON_ID_FK&quot;) ) private Person person; public Phone() &#123; &#125; public Phone(String number) &#123; this.number = number; &#125; public Long getId() &#123; return id; &#125; public String getNumber() &#123; return number; &#125; public Person getPerson() &#123; return person; &#125; public void setPerson(Person person) &#123; this.person = person; &#125;&#125; 对应的sql语句：12345678910111213CREATE TABLE Person ( id BIGINT NOT NULL , PRIMARY KEY ( id ))CREATE TABLE Phone ( id BIGINT NOT NULL , number VARCHAR(255) , person_id BIGINT , PRIMARY KEY ( id ) )ALTER TABLE PhoneADD CONSTRAINT PERSON_ID_FKFOREIGN KEY (person_id) REFERENCES Person 单向1-1关联: 使用@OneToOne注解。比如一个人对应一个身份证Id,只需获取一个人的身份证号，而无需通过身份证号获取用户的情况。当使用@JoinColumn通过外键实现，否则通过第三方表实现。 1234567891011121314151617@Entity@Table(name=&quot;person_table&quot;)public class Person&#123;@Idprivate int personid;private String name;@OneToOne(optional=false,cascade=CascadeType.ALL,fetch=FetchType.LAZY,targetEntity=IdCard.class)@JoinColumn(name=&quot;id_card_id&quot;,nullable=false,updatable=false)//映射外键列private IdCard idCard;&#125;@Entity@Table(name=&quot;id_card_table&quot;)public class IdCard&#123;@Idprivate int idCardId;private String cardNumber;&#125; 单向1-N关联：使用@OneToMany注解。-对于1-N关联，应尽量设计为双向关联，而不是单向比如一个人有多个手机号，仅需要获取一个人的手机号，而无需通过手机号获取用户的场景。当使用@JoinColumn通过外键实现，否则通过第三方表实现。 1234567891011121314151617181920212223242526272829303132@Entity(name = &quot;Person&quot;)public static class Person &#123; @Id @GeneratedValue private Long id; @OneToMany(cascade = CascadeType.ALL, orphanRemoval = true) private List&lt;Phone&gt; phones = new ArrayList&lt;&gt;(); public Person() &#123; &#125; public List&lt;Phone&gt; getPhones() &#123; return phones; &#125;&#125;@Entity(name = &quot;Phone&quot;)public static class Phone &#123; @Id @GeneratedValue private Long id; @Column(name = &quot;`number`&quot;) private String number; public Phone() &#123; &#125; public Phone(String number) &#123; this.number = number; &#125; public Long getId() &#123; return id; &#125; public String getNumber() &#123; return number; &#125;&#125; 对应的sql：12345678910111213141516171819202122CREATE TABLE Person ( id BIGINT NOT NULL , PRIMARY KEY ( id ))CREATE TABLE Person_Phone ( Person_id BIGINT NOT NULL , phones_id BIGINT NOT NULL)CREATE TABLE Phone ( id BIGINT NOT NULL , number VARCHAR(255) , PRIMARY KEY ( id ))ALTER TABLE Person_PhoneADD CONSTRAINT UK_9uhc5itwc9h5gcng944pcaslfUNIQUE (phones_id);ALTER TABLE Person_PhoneADD CONSTRAINT FKr38us2n8g5p9rj0b494sd3391FOREIGN KEY (phones_id) REFERENCES Phone;ALTER TABLE Person_PhoneADD CONSTRAINT FK2ex4e4p7w1cj310kg2woisjl2FOREIGN KEY (Person_id) REFERENCES Person 单向N-N关联：使用@ManyToMany注解。比如一个人有多个住址，一个住址又对应多个用户，仅需通过用户获取住址列表的场景。对于多对多关系，数据库底层只能通过关联表实现。方式一：使用默认12345678910111213141516171819202122232425262728293031323334353637@Entity(name = &quot;Person&quot;)public static class Person &#123; @Id @GeneratedValue private Long id; @ManyToMany(cascade = &#123;CascadeType.PERSIST, CascadeType.MERGE&#125;) private List&lt;Address&gt; addresses = new ArrayList&lt;&gt;(); public Person() &#123; &#125; public List&lt;Address&gt; getAddresses() &#123; return addresses; &#125;&#125;@Entity(name = &quot;Address&quot;)public static class Address &#123; @Id @GeneratedValue private Long id; private String street; @Column(name = &quot;`number`&quot;) private String number; public Address() &#123; &#125; public Address(String street, String number) &#123; this.street = street; this.number = number; &#125; public Long getId() &#123; return id; &#125; public String getStreet() &#123; return street; &#125; public String getNumber() &#123; return number; &#125;&#125; 对应的sql：1234567891011121314151617181920CREATE TABLE Address ( id BIGINT NOT NULL , number VARCHAR(255) , street VARCHAR(255) , PRIMARY KEY ( id ))CREATE TABLE Person ( id BIGINT NOT NULL , PRIMARY KEY ( id ))CREATE TABLE Person_Address ( Person_id BIGINT NOT NULL , addresses_id BIGINT NOT NULL)ALTER TABLE Person_AddressADD CONSTRAINT FKm7j0bnabh2yr0pe99il1d066uFOREIGN KEY (addresses_id) REFERENCES Address;ALTER TABLE Person_AddressADD CONSTRAINT FKba7rc9qe2vh44u93u0p2auwtiFOREIGN KEY (Person_id) REFERENCES Person 方式二：通过@JoinTable配置关联表123456789101112131415161718@Entity(name = &quot;Person&quot;)public static class Person &#123; @Id @GeneratedValue private Long id; @ManyToMany(cascade = &#123;CascadeType.PERSIST, CascadeType.MERGE&#125;,targetEntity=Address.class) @JoinTable( name=&quot;person_address&quot;, joinColumns=@JoinColumn(name=&quot;person_id&quot;), inverseJoinTableColumns=@JoinColumn(name=&quot;address_id&quot;) ) private List&lt;Address&gt; addresses = new ArrayList&lt;&gt;(); public Person() &#123; &#125; public List&lt;Address&gt; getAddresses() &#123; return addresses; &#125;&#125; 双向1-1关联: 使用两边@OneToOne注解和mappedBy属性双向需要两边实体类都增加@OneToOne，可在一边的实体类增加mappedBy属性。当使用mappedBy属性后表示当前实体不再控制关联联系，因此不可使用@JoinColumn。比如一个人一个精确住址，既可以通过用户获取住址，又可以通过住址获取该住户的场景。 1234567891011121314151617181920212223@Entity@Table(name=&quot;person_table&quot;)public class Person&#123;@Id@GeneratedValue(strategy=GenerationType.IDENTITY)private int personId;private String name;private int age;@OneToOne(mappedBy=&quot;person&quot;,cascade=CascadeType.ALL)private Address address;//...&#125;@Entity@Table(name=&quot;address_table&quot;)public class Address&#123; @Id private int addressId; private String detail; @OneToOne(optional=false,cascade=CascadeType.ALL) @JoinColumn(name=&quot;person_id&quot;,nullable=false,updatable=false) private Person person; //...&#125; 双向1-N关联：使用@OneToMany和@ManyToOne注解和mappedBy属性对于1-N关联，应尽量设计为双向关联，而不是单向，并且尽量使用N的一端来控制关联。1的一端使用@OneToMany注解和mappedBy属性，N的一端使用@ManyToOne和@JoinColumn。比如一个人有多个住址，既可以通过用户获取住址，又可以通过住址获取用户的场景。 1234567891011121314151617181920212223@Entity@Table(name=&quot;person_table&quot;)public class Person&#123;@Id@GeneratedValue(strategy=GenerationType.IDENTITY)private int personId;private String name;private int age;@OneToMany(mappedBy=&quot;person&quot;,cascade=CascadeType.ALL)private Set&lt;Address&gt; addresses=new HashSet&lt;Address&gt;();//...&#125;@Entity@Table(name=&quot;address_table&quot;)public class Address&#123; @Id private int addressId; private String detail; @ManyToOne(optional=false,cascade=CascadeType.ALL) @JoinColumn(name=&quot;person_id&quot;,nullable=true) private Person person; //...&#125; 双向N-N关联: 使用两边@ManyToMany注解，一边mapperBy属性和。对于N-N关联，底层数据库必须通过关联表来关联实体之间的关系。对于双向N-N关联，两边实体对等，一边通过mappedBy不再控制关系，另一边通过@JoinTable控制关系即可。比如多个人住在同一个地址，但一个人也可有多个住址，既可以通过用户找到住址列表，又可以通过住址找到用户列表的场景。 12345678910111213141516171819202122232425262728@Entity@Table(name=&quot;person_table&quot;)public class Person&#123;@Id@GeneratedValue(strategy=GenerationType.IDENTITY)private int personId;private String name;private int age;@ManyToMany(mappedBy=&quot;persons&quot;,cascade=CascadeType.ALL)private Set&lt;Address&gt; addresses=new HashSet&lt;Address&gt;();//...&#125;@Entity@Table(name=&quot;address_table&quot;)public class Address&#123; @Id private int addressId; private String detail; @ManyToMany(optional=false,cascade=CascadeType.ALL) @JoinColumn(name=&quot;person_id&quot;,nullable=true) @JoinTable( name=&quot;person_address&quot;, joinColumns=@JoinColumn(name=&quot;address_id&quot;), inverseJoinTableColumns=@JoinColumn(name=&quot;person_id&quot;) ) private Set&lt;Person&gt; persons=new HashSet&lt;Person&gt;(); //...&#125; 使用Map集合记录关联实体：使用@MapKey注解：比如一个人有多个住址，既可以通过用户获取住址，又可以通过住址获取用户的场景。使用@MapKey时必须指定一个name属性，name属性的属性值为当前实体的关联实体中标识属性的属性名。 12345678910111213@Entity@Table(name=&quot;person_table&quot;)public class Person&#123;@Id@GeneratedValue(strategy=GenerationType.IDENTITY)private int personId;private String name;private int age;@OneToMany(mappedBy=&quot;person&quot;,cascade=CascadeType.ALL)@MapKey(name=&quot;pk&quot;)private Map&lt;AddressPk,Address&gt; addresses=new HashMap&lt;AddressPk,Address&gt;();//...&#125; 4. JPA映射策略1234567891011121314JPA提供了3种映射策略：(1)、 整个类层次对应一张表策略,这是继承映射的默认策略。即如果实体类B继承实体类A，实体类C也继承自实体A，那么只会映射成一个表，这个表中包括了实体类A、B、C中所有的字段，JPA使用一个叫做“discriminator列”来区分某一行数据是应该映射成哪个实体。注解为：@Inheritance(strategy = InheritanceType.SINGLE_TABLE)(2)、 连接子类策略。父亲的放在一张表，儿子只是保存和父亲不一样的，增加的属性。这种情况下子类的字段被映射到各自的表中，这些字段包括父类中的字段，并执行一个join操作来实例化子类。注解为：@Inheritance(strategy = InheritanceType.JOINED)(3)、 每个具体的类一个表的策略。注解为：@Inheritance(strategy = InheritanceType.TABLE_PER_CLASS)可使用@Inheritance指定映射策略InheritanceType.SINGLE_TABLE：第一种InheritanceType.JOINED：第二种InheritanceType.TABLE_PER_CLASS：第三种 整个类层次对应一张表策略。这种策略下，整个类层次所有的实体都存放在一张数据表中，系统通过在该表增加额外的一个辨别列，用来区分每行记录到底是哪一个类的实例。使用@DiscriminatorColumn来配置辨别列。 123456789101112131415161718192021@Entity@Inheritance(strategy=InheritanceType.SINGLE_TABLE)// 定义辨别者列的列名为person_type，列类型为字符串@DiscriminatorColumn(name=&quot;person_type&quot; , discriminatorType=DiscriminatorType.STRING)// 指定Person实体对应的记录在辨别者列的值为&quot;普通人&quot;@DiscriminatorValue(&quot;普通人&quot;)@Table(name=&quot;person_inf&quot;)public class Person&#123;&#125;// 顾客类继承了Person类@Entity// 指定Customer实体对应的记录在辨别者列的值为&quot;顾客&quot;@DiscriminatorValue(&quot;顾客&quot;)@Table(name=&quot;customer_inf&quot;)public class Customer extends Person&#123;&#125;// 员工类继承了Person类@Entity// 指定Employee实体对应的记录在辨别者列的值为&quot;员工&quot;@DiscriminatorValue(&quot;员工&quot;)@Table(name=&quot;employee_inf&quot;)public class Employee extends Person&#123;&#125; 连接子类的映射策略这种策略中父类实体保存在父类表中，而子类实体由父亲表和子类表共同存储，父类和子类共有部分存储在父类表，子类单独存在属性存储在子类表中。无需使用辨别者，只需要在继承树的根实体类上使用@Inheritance,指定strategy=InheritanceType.JOINED即可 12345678910@Entity@Inheritance(strategy=InheritanceType.JOINED)@Table(name=&quot;person_inf&quot;)public class Person&#123;&#125;@Entity@Table(name=&quot;customer_inf&quot;)public class Customer extends Person&#123;&#125;@Entity@Table(name=&quot;employee_inf&quot;)public class Employee extends Person&#123;&#125; 每个具体的类一个表的策略子类实例仅保存在子类表中，在父类表中没有任何记录。单从数据库来看，几乎难以看出继承关系，只是多个实体之间主键存在某种连续性，因此不能让数据库自动生成主键，因此不能使用GenerationType.IDENTITY和GenerationType.AUTO这两种主键生成策略。无需使用辨别者，只需要在继承树的根实体类上使用@Inheritance,指定strategy=InheritanceType.TABLE_PER_CLASS即可 1234@Entity@Inheritance(strategy=InheritanceType.TABLE_PER_CLASS)@Table(name=&quot;person_inf&quot;)public class Person&#123;&#125; 5. spring data注解 @CreatedBy：Declares a field as the one representing the principal that created the entity containing the field. @CreatedDate：Declares a field as the one representing the date the entity containing the field was created. @Id：Demarcates an identifier. @LastModifiedBy：Declares a field as the one representing the principal that recently modified the entity containing the field. @LastModifiedDate：Declares a field as the one representing the date the entity containing the field was recently modified. @ReadOnlyProperty：Marks a field to be read-only for the mapping framework and therefore will not be persisted. @Reference：Meta-annotation to be used to annotate annotations that mark references to other objects. @Transient：Marks a field to be transient for the mapping framework. Thus the property will not be persisted and not further inspected by the mapping framework. @TypeAlias：Annotation to allow String based type aliases to be used when writing type information for PersistentEntitys. @version: 定义一个属性为版本字段用于实现乐观锁 参考 《经典JAVAEE企业应用实战》 JPA API spring data commons源码 http://blog.csdn.net/u012881904/article/details/51059156","tags":[{"name":"java,JPA","slug":"java-JPA","permalink":"http://yoursite.com/tags/java-JPA/"}]},{"title":"GitLearn in 15 minutes","date":"2017-03-22T05:44:44.325Z","path":"2017/03/22/GitLearn in 15 minutes/","text":"学习来源：https://try.github.io/levels/1/challenges/1Git是一个开源的分布式版本控制系统（DVCS），可以显着改善您在项目中的工作方式和协作。 Git允许您保留对本地文件进行重大更改的历史记录。它还可以通过像GitHub这样的远程托管服务来备份这个历史记录。1.1 Got 15 minutes and want to learn Git?Git allows groups of people to work on the same documents (often code) at the same time, and without stepping on each other’s toes. It’s a distributed version control system. Our terminal prompt below is currently in a directory we decided to name “octobox”. To initialize a Git repository here, type the following command: Git允许一群人同时处理相同的文档（通常是代码），而不会踩在彼此的脚趾上。它是一个分布式版本控制系统。 我们的终端提示如下，目前我们决定命名为“octobox”。要在此处初始化Git存储库，请键入以下命令： 1git init 现在就创建了一个Git储存仓库并且生成了 .git文件夹 这个文件夹是用来存放有关仓库的所有的信息 1.2 Checking the Status （检查状态） Good job! As Git just told us, our “octobox” directory now has an empty repository in /.git/. The repository is a hidden directory where Git operates. To save your progress as you go through this tutorial – and earn a badge when you successfully complete it – head over to create a free Code School account. We’ll wait for you here. Next up, let’s type the git status command to see what the current state of our project is: 做得好！正如Git刚刚告诉我们的，我们的“octobox”目录现在在/.git/中有一个空的存储库。存储库是Git操作的隐藏目录。 通过本教程来节省您的进度，并在成功完成课程时获得徽章，以创建免费的Code School帐户。我们会在这里等你 接下来，我们输入git status命令来查看我们项目的当前状态： 1git status 经常运行git status是很健康的。有时事情改变，你不注意它。 可以看到当前的状态是 master 也就是主分支的状态 初始化commit 检查到没有东西要提交 因为仓库中是空的现在 1.3 Adding &amp; Committing I created a file called octocat.txt in the octobox repository for you (as you can see in the browser below). You should run the git status command again to see how the repository status has changed: 我在octobox存储库中为您创建了一个名为octocat.txt的文件（您可以在下面的浏览器中看到）。 您应该再次运行git status命令以查看存储库状态如何更改： staged: Files are ready to be committed. 这时候是用红色字体来显示的 说明文件已准备好提交。 unstaged: Files with changes that have not been prepared to becommitted. 在检查的时候发现一个具有尚未准备提交的更改的文件 Files aren’t tracked by Git yet. This usually indicates a newlycreated file. deleted: Git尚未跟踪文件。这通常表示新创建的文件。 deleted: File has been deleted and is waiting to be removed from Git.文件已被删除，正在等待从Git中删除 1.4 Adding ChangesGood, it looks like our Git repository is working properly. Notice how Git says octocat.txt is “untracked”? That means Git sees that octocat.txt is a new file. To tell Git to start tracking changes made to octocat.txt, we first need to add it to the staging area by using git add. 好的，看起来我们的Git仓库正常工作。注意Git如何说octocat.txt是“未被追踪的”？这意味着Git看到octocat.txt是一个新的文件。 要告诉Git开始跟踪对octocat.txt进行的更改，我们首先需要使用git add将其添加到暂存区域。 add all: You can also type git add -A . where the dot stands for thecurrent directory, so everything in and beneath it is added. The -Aensures even file deletions are included. 您也可以输入git add -A。代表当前目录下的所有文件都被添加到暂存仓库中。 -A 确保包括文件删除。 git reset: You can use git reset &lt;filename&gt; to remove a file or filesfrom the staging area 您可以使用git reset 从分段区域中删除文件。 1.5 Checking for Changes再次检查状态 Staging Area: A place where we can group files together before we“commit” them to Git. Commit 暂存区域：在我们将“提交”到Git之前，我们可以将文件暂存在一起的地方。 A “commit” is a snapshot of our repository. This way if we ever needto look back at the changes we’ve made (or if someone else does), wewill see a nice timeline of all changes. 一次“提交”是我们存储库的一个快照。这样，如果我们需要回顾我们所做的更改（或者如果有人做的），我们将会看到一个很好的时间轴关于这些的改变。 1.6 CommittingNotice how Git says changes to be committed? The files listed here are in the Staging Area, and they are not in our repository yet. We could add or remove files from the stage before we store them in the repository. To store our staged changes we run the commit command with a message describing what we’ve changed. Let’s do that now by typing: 注意Git如何说改变被提交了？这里列出的文件位于“暂存区”中，它们不在我们的存储库中。我们可以在将它们存储在存储库之前，从暂存区添加或删除文件。 要存储我们改变了什么，我们运行commit命令，并附带一条描述我们已经更改的消息。现在我们来输入： 1$ git commit -m \"Add cute octocat story\" Wildcards: We need quotes so that Git will receive the wildcard before our shell can interfere with it.Without quotes our shell will only execute the wildcard search within the current directory.Git will receive the list of files the shell found instead of the wildcard andit will not be able to add the files inside of the octofamily directory. 通配符： 我们需要引号，以便在我们的shell可以干扰之前，Git会收到通配符。没有引号，我们的shell只会在当前目录中执行通配符搜索。 Git将收到shell找到的文件列表，而不是通配符，它​​将无法在octofamily目录中添加文件。 1.7 Adding All Changes Great! You also can use wildcards if you want to add many files of the same type. Notice that I’ve added a bunch of .txt files into your directory below. I put some in a directory named “octofamily” and some others ended up in the root of our “octobox” directory. Luckily, we can add all the new files using a wildcard with git add. Don’t forget the quotes! 棒极了，如果要添加相同类型的许多文件，也可以使用通配符。请注意，我已经将一堆.txt文件添加到您的目录下面。 一个名为“octofamily”的目录中有两个，其他一些最终在我们的“octobox”目录的根。幸运的是，我们可以使用git add通配符添加所有新文件。不要忘记引号！ Check all the things!When using wildcards you want to be extra careful when doing commits. Make sure to check what files and folders &gt;are staged by using git status before you do the actual commit. This way you can be sure you’re committing only the things you want. 检查所有的事情！ 当使用通配符时，你在做提交时要特别小心。确保在执行实际提交之前使用git status检查要暂存的文件和文件夹。这样，你可以确保你t提交的只是你想要的东西。 1.8 Committing All Changes Okay, you’ve added all the text files to the staging area. Feel free to run git status to see what you’re about to commit. If it looks good, go ahead and run: More useful logs:Use git log –summary to see more information foreach commit. You can see where new files were added for the first timeor where files were deleted. It’s a good overview of what’s going on in the project. 更有用的日志： 使用git log –summary查看每个提交的更多信息。您可以看到第一次添加新文件的位置或删除文件的位置。这是一个很好的概述，在项目中发生了什么。 1.9 HistorySo we’ve made a few commits. Now let’s browse them to see what we changed. Fortunately for us, there’s git log. Think of Git’s log as a journal that remembers all the changes we’ve committed so far, in the order we committed them. Try running it now: 所以我们做了一些提交。现在让我们浏览他们看看我们改变了什么。 幸运的是，我们有git log。想想Git的日志是一本记录，记录我们迄今为止所做的所有变化，按照我们提交的顺序。尝试运行它： git remote: Git doesn’t care what you name your remotes, but it’s typical to name your main one origin. It’s also a good idea for your main repository to be on a remote server like GitHub in case yourmachine is lost at sea during a transatlantic boat cruise or crushedby three monkey statues during an earthquake. git远程 Git不在乎你命名你的远程，但它的典型名称是你的主要来源（orign）。 如果您的主机位于远程服务器，如GitHub，如果您的机器在海洋中丢失，在跨大西洋的船只巡航或在地震期间被三只猴子雕像压碎，这也是一个好主意。 1.10 Remote Repositories（远程仓库）Great job! We’ve gone ahead and created a new empty GitHub repository for you to use with Try Git at https://github.com/try-git/try_git.git. To push our local repo to the GitHub server we’ll need to add a remote repository. This command takes a remote name and a repository URL, which in your case is https://github.com/try-git/try_git.git. Go ahead and run git remote add with the options below: 做得好！我们已经开始创建了一个新的空的GitHub存储库，供您与Try Git一起使用，网址为https：//github.com/try-git/try_git.git。要将我们的本地repo推送到GitHub服务器，我们需要添加一个远程仓库。 此命令使用远程名称和存储库URL，在您的情况下，它是https://github.com/try-git/try_git.git。 继续运行git远程添加与以下选项： 1git remote add origin https://github.com/try-git/try_git.git Cool Stuff:When you start to get the hang of git you can do some really cool things with hooks when you push.For example, you can upload directly to a webserver whenever you push to your master remoteinstead of having to upload your site with an ftp client. Check outCustomizing Git - Git Hooks for more information. 很酷的东西： 当你开始得到git的挂起，你可以做一些非常酷的东西与钩子，当你push。 例如，您可以直接上传到网络服务器，只要您推送到主控远程，而不必使用ftp客户端上传您的站点。查看自定义Git - Git Hooks了解更多信息。 1.11 Pushing RemotelyThe push command tells Git where to put our commits when we’re ready, and now we’re ready. So let’s push our local changes to our origin repo (on GitHub). The name of our remote is origin and the default local branch name is master. The -u tells Git to remember the parameters, so that next time we can simply run git push and Git will know what to do. Go ahead and push it! push命令告诉Git当我们准备好时，在哪里放置我们的提交，现在我们准备好了。所以我们把我们的地方变化推到我们的起始地位（在GitHub上）。 我们的远程的名称是origin，默认的本地分支名称是master。 -u告诉Git记住参数，所以下次我们可以简单的运行git push，Git会知道该怎么做。继续推动！ 1$ git push -u origin master 1.12 Pulling RemotelyLet’s pretend some time has passed. We’ve invited other people to our GitHub project who have pulled your changes, made their own commits, and pushed them. We can check for changes on our GitHub repository and pull down any new changes by running: 假设有一段时间过去了我们邀请其他人加入我们的GitHub项目，他们已经拉下了你的修改，提交了自己的提交，并推送他们。 我们可以检查我们的GitHub存储库中的更改，并通过运行以下命令来删除任何新的更改 1git pull origin master HEADThe HEAD is a pointer that holds your position within all yourdifferent commits. By default HEAD points to your most recent commit,so it can be used as a quick way to reference that commit withouthaving to look up the SHA. 头 HEAD是一个指针，可以在您所有不同的提交内保持您的位置。默认情况下，HEAD指向您最近的提交，因此可以将其用作引用该提交的快速方式，而无需查找SHA 1.13 DifferencesUh oh, looks like there have been some additions and changes to the octocat family. Let’s take a look at what is different from our last commit by using the git diff command. In this case we want the diff of our most recent commit, which we can refer to using the HEAD pointer. 呃哦，看起来已经有了一些补充和改变octocat家庭。让我们通过使用git diff命令来看看与上一次提交不同的是什么。 在这种情况下，我们需要我们最近提交的diff，我们可以参考使用HEAD指针。 1git diff HEAD Commit Etiquette: You want to try to keep related changes together in separate commits. Using ‘git diff’ gives you a good overview ofchanges you have made and lets you add files or directories one at atime and commit them separately. 提交礼仪： 您想尝试将相关更改保留在单独的提交中。使用’git diff’可以很好地概述所做的更改，并允许您一次添加一个文件或目录，并单独提交它们。 1.14 Staged DifferencesAnother great use for diff is looking at changes within files that have already been staged. Remember, staged files are files we have told git that are ready to be committed. Let’s use git add to stage octofamily/octodog.txt, which I just added to the family for you. diff的另一个很好的用途是查看已经上架的文件中的更改。记住，暂存文件是我们已经告诉git的文件，可以提交。 让我们使用git add来分配octofamily / octodog.txt，我刚刚为你添加了家庭。 1git add octofamily/octodog.txt 1.15 Staged Differences (cont’d)Good, now go ahead and run git diff with the –staged option to see the changes you just staged. You should see that octodog.txt was created.好，现在继续运行git diff与–staged选项，以查看刚刚暂存的更改。你应该看到octodog.txt被创建。 1git diff --staged 1.16 Resetting the StageSo now that octodog is part of the family, octocat is all depressed. Since we love octocat more than octodog, we’ll turn his frown around by removing octodog.txt. You can unstage files by using the git reset command. Go ahead and remove octofamily/octodog.txt. 所以现在octodog是家庭的一部分，octocat是所有郁闷。因为我们喜欢octocat超过octodog，我们将转过他的皱眉，删除octodog.txt。 您可以使用git reset命令来解压缩文件。继续去除octofamily / octodog.txt。 1git reset octofamily/octodog.txt The ‘–’So you may be wondering, why do I have to use this ‘–’ thing? git checkout seems to work fine without it. It’s simply &gt;promising the command line that there are no more options after the ‘–’. This way if you happen to have a branch &gt;named octocat.txt, it will still revert the file, instead of switching to the branch of thesame name. ‘ - ‘ 所以你可能会想，为什么我必须使用这个’ - ‘的东西？ git结帐似乎工作正常没有它。它只是承诺命令行，在’ - ‘之后没有更多的选项。这样，如果碰巧有一个名为octocat.txt的分支，它仍然会还原文件，而不是切换到相同名称的分支。 1.17 Undogit reset did a great job of unstaging octodog.txt, but you’ll notice that he’s still there. He’s just not staged anymore. It would be great if we could go back to how things were before octodog came around and ruined the party. Files can be changed back to how they were at the last commit by using the command: git checkout – . Go ahead and get rid of all the changes since the last commit for octocat.txt git reset做了一个伟大的工作，不在暂存octodog.txt，但你会注意到，他还在那里。他只是没有在暂存区了。如果我们可以回到上次的时候，那将是很美好的。 可以使用以下命令将文件更改回上次提交的方式：git checkout - &lt;target&gt;。继续前进，摆脱上次提交octocat.txt以来的所有更改 1git checkout -- octocat.txt Branching Branches are what naturally happens when you want to work onmultiple features at the same time. You wouldn’t want to end up with amaster branch which has Feature A half done and Feature B half done.Rather you’d separate the code base into two “snapshots” (branches)and work on and commit to them separately. As soon as one was ready,you might merge this branch back into the master branch and push it tothe remote server. 分枝 当您想同时处理多个功能时，分支机构是自然会发生的。你不想结束一个主分支，其中功能A一半完成，功能B一半完成。 相反，你会将代码库分成两个“快照”（分支），并分别处理和提交。一旦准备就绪，您可以将该分支合并回主分支并将其推送到远程服务器。 1.18 Branching OutWhen developers are working on a feature or bug they’ll often create a copy (aka. branch) of their code they can make separate commits to. Then when they’re done they can merge this branch back into their main master branch. We want to remove all these pesky octocats, so let’s create a branch called clean_up, where we’ll do all the work: 当开发人员正在开发一个功能或错误时，他们经常会创建一个他们的代码的副本（也称为分支），他们可以单独提交。然后当他们完成后，他们可以合并这个分支回他们的主要分支。 我们想删除所有这些讨厌的octocats，所以让我们创建一个名为clean_up的分支，我们将在其中完成所有的工作： 1$ git branch clean_up You can use:git checkout -b new_branch to checkout and create abranch at the same time. This is the same thing as doing: git branchnew_branch git checkout new_branch 中文(简体)您可以使用： git checkout -b new_branch 同时创建并且创建一个分支。他们和这样是在做事情： git branch new_branch git checkout new_branch Remove all the things! Removing one file is great and all, but what if you want to remove an entire folder? You can use the recursive option on git rm: git rm -r folder_of_cats This will recursively remove allfolders and files from the given directory. 删除一个文件是伟大的，所有，但如果要删除整个文件夹怎么办？您可以在git rm上使用递归选项： git rm -r folder_of_cats 这将递归地删除给定目录中的所有文件夹和文件。 1.20 Removing All The ThingsOk, so you’re in the clean_up branch. You can finally remove all those pesky octocats by using the git rm command which will not only remove the actual files from disk, but will also stage the removal of the files for us. You’re going to want to use a wildcard again to get all the octocats in one sweep, go ahead and run: 的，所以你在clean_up分支。您可以使用git rm命令，最终删除所有那些讨厌的octocats，它不仅可以从磁盘中删除实际的文件，还可以为我们移除文件。 您将要再次使用通配符将所有octocats一次性扫描，然后运行： 1git rm '*.txt' The ‘-a’ option If you happen to delete a file without using ‘git rm’you’ll find that you still have to &#39;git rm&#39; the deleted files from the working tree. You can save this step by using the ‘-a’ option on &#39;git commit&#39;, which auto removes deleted files with the commit. git commit -am &quot;Delete stuff&quot; ‘-a’选项 如果你碰巧删除一个文件而不使用’git rm’，你会发现你仍然需要从工作树中删除已删除的文件。您可以使用’git commit’上的’-a’选项来保存此步骤，该选项会通过提交自动删除已删除的文件。 git commit -am“删除东西” 1.21 Commiting Branch ChangesNow that you’ve removed all the cats you’ll need to commit your changes. Feel free to run git status to check the changes you’re about to commit.现在你已经删除了所有需要提交更改的猫。 随意运行git状态以检查您要提交的更改。 1.22 Switching Back to masterGreat, you’re almost finished with the cat… er the bug fix, you just need to switch back to the master branch so you can copy (or merge) your changes from the clean_up branch back into the master branch. Go ahead and checkout the master branch:好的，你几乎完成了这个错误修复，你只需要切换回主分支，所以你可以将你的更改从clean_up分支复制（或合并）到主分支中。 继续检查主分支： 1git checkout master Pull RequestsIf you’re hosting your repo on GitHub, you can do something called a pull request.A pull request allows the boss of the project to look through your changes and make comments before deciding to merge in the change. It’s a really great feature that is used all the time for remote workers and open-source projects.Check out the pull request help page for more information. 拉取请求 如果您在GitHub上托管您的项目，您可以进行一些称为拉动请求的操作。 拉动请求允许项目的老板在决定合并更改之前，先查看更改并发表评论。这是一个非常好的功能，它一直用于远程工作和开源项目。 请查看拉动请求帮助页面以获取更多信息。 1.23 Preparing to MergeAlrighty, the moment has come when you have to merge your changes from the clean_up branch into the master branch. Take a deep breath, it’s not that scary. We’re already on the master branch, so we just need to tell Git to merge the clean_up branch into it: 好的，当你必须将clean_up分支中的更改合并到主分支时，现在已经到了。深吸一口气，这不是那么可怕。 我们已经在主分支上，所以我们只需要告诉Git将clean_up分支合并到它中： 1git merge clean_up Merge ConflictsMerge Conflicts can occur when changes are made to afile at the same time. A lot of people get really scared when aconflict happens, but fear not! They aren’t that scary, you just needto decide which code to keep. Merge conflicts are beyond the scope ofthis course, but if you’re interested in reading more, take a look thesection of the Pro Git book on how conflicts are presented. 合并冲突 合并冲突可能会发生在同时对文件进行更改时。很多人在发生冲突时真的害怕，但不要害怕！他们不是那么可怕，你只需要决定保留哪些代码。 合并冲突超出了本课程的范围，但如果您有兴趣阅读更多内容，请查看Pro Git书中有关如何呈现冲突的部分 Force deleteWhat if you have been working on a feature branch and youdecide you really don’t want this feature anymore? You might decide todelete the branch since you’re scrapping the idea. You’ll notice thatgit branch -d bad_feature doesn’t work. This is because -d won’t letyou delete something that hasn’t been merged. You can either add the--force (-f) option or use -D which combines -d -f together into one command. 强制删除 如果您在功能部门工作，而且您决定不再需要此功能，该怎么办？你可能会决定删除分支，你会注意到git branch -d bad_feature不工作。这是因为-d不会让您删除未合并的内容。 您可以添加–force（-f）选项，或者使用-D组合-d -f到一个命令中。 1.24 Keeping Things CleanCongratulations! You just accomplished your first successful bugfix and merge. All that’s left to do is clean up after yourself. Since you’re done with the clean_up branch you don’t need it anymore. You can use git branch -d &lt;branch name&gt; to delete a branch. Go ahead and delete the clean_up branch now: 恭喜！你刚刚完成了你的第一个成功的修正和合并。所有剩下要做的就是清理自己。因为你已经完成了clean_up分支，你不再需要它。 你可以使用git branch -d &lt;branch name&gt;删除一个分支。继续并删除clean_up分支： 1.25 The Final PushHere we are, at the last step. I’m proud that you’ve made it this far, and it’s been great learning Git with you. All that’s left for you to do now is to push everything you’ve been working on to your remote repository, and you’re done! 在这里，我们在最后一步。我很自豪，你已经做到这一点，这是伟大的学习Git与你。现在剩下的一切就是把你一直在做的一切都推送到你的远程仓库，你已经完成了！ 1git push Learning more about GitWe only scratched the surface of Git in this course. There is so much more you can do with it. Check out the Git documentation for a full list of functions.The Pro Git book, by Scott Chacon, is an excellent resource to teach you the inner workings of Git.help.github and GitHub Training are also great for anything related to Git in general and using Git with GitHub. 学习更多关于Git 我们在这个课程中只刮了Git的表面。还有更多的你可以做到这一点。查看Git文档的完整功能列表。 由Scott Chacon撰写的Pro Git书是教你Git内部工作的绝佳资源。 help.github和GitHub培训对于与Git有关的任何事情也是非常好的，并且使用Git与GitHub。","tags":[{"name":"git","slug":"git","permalink":"http://yoursite.com/tags/git/"}]},{"title":"通过Git上传项目的Github","date":"2017-03-22T03:15:43.018Z","path":"2017/03/22/通过Git上传项目的Github/","text":"通过Git上传项目的Github首先我们先来介绍一下GitGit 与版本控制 版本控制是一种记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统。 虽然基于 Git 的工作流可能并不是一个非常好的实践，但是在这里我们以这个工作流做为实践来开展我们的项目。如下图所示是一个基于 Git 的项目流： 我们日常会工作在 “develop” 分支（那条线）上，通常来说每个迭代我们会发布一个新的版本，而这个新的版本将会直接上线到产品环境。那么上线到产品环境的这个版本就需要打一个版本号——这样不仅可以方便跟踪我们的系统，而且当出错的时候我们也可以直接回滚到上一个版本。如果在上线的时候有些 Bug 不得不去修复，并且由于上线的新功能很重要，我们就需要 修补程序。而从整个过程来看，版本控制起了一个非常大的作用。 不仅仅如此，版本控制的最大重要是在开发的过程中扮演的角色。通过版本管理系统，我们可以： 将某个文件回溯到之前的状态。 将项目回退到过去某个时间点。 在修改 Bug 时，可以查看修改历史，查出修改原因 只要版本控制系统还在，你可以任意修改项目中的文件，并且还可以轻松恢复。 常用的版本管理系统有 Git、SVN，但是从近年来看 Git 似乎更受市场欢迎。 ##Git 从一般开发者的角度来看，Git 有以下功能： 从服务器上克隆数据库（包括代码和版本信息）到单机上。 在自己的机器上创建分支，修改代码。 在单机上自己创建的分支上提交代码。 在单机上合并分支。 新建一个分支，把服务器上最新版的代码 fetch 下来，然后跟自己的主分支合并。 -生成补丁（patch），把补丁发送给主开发者。 看主开发者的反馈，如果主开发者发现两个一般开发者之间有冲突（他们之间可以合作解决的冲突），就会要求他们先解决冲突，然后再由其中一个人提交。如果主开发者可以自己解决，或者没有冲突，就通过。 一般开发者之间解决冲突的方法，开发者之间可以使用 pull 命令解决冲突，解决完冲突之后再向主开发者提交补丁。从主开发者的角度（假设主开发者不用开发代码）看，Git 有以下功能：1.查看邮件或者通过其它方式查看一般开发者的提交状态。2.打上补丁，解决冲突（可以自己解决，也可以要求开发者之间解决以后再重新提交，如果是开源项目，还要决定哪些补丁有用，哪些不用）。3.向公共服务器提交结果，然后通知所有开发人员。 Git 初入如果是第一次使用 Git，你需要设置署名和邮箱： 12$ git config --global user.name \"用户名\"$ git config --global user.email \"电子邮箱\" 你可以在 GitHub 新建免费的公开仓库或在 Coding.net 新建免费的私有仓库。 新建一个Repository 按照 GitHub 的文档 或 Coding.net 的文档 配置 SSH Key，然后将代码仓库 clone 到本地，其实就是将代码复制到你的机器里，并交由 Git 来管理： 12$ git clone git@github.com:username/repository.git或$ git clone git@git.coding.net:username/repository.git 或使用 HTTPS 地址进行 clone： 123$ git clone https://username:password@github.com/username/repository.git或$ git clone https://username:password@git.coding.net/username/repository.git 复制地址： 克隆到本地： 克隆完成后的样子，会在文件夹下生成.git这就说明已经和远程仓库建立了连接 这里的代码我后来加进去的 如果项目是空的 只有.git 你可以修改复制到本地的代码了（ symfony-docs-chs 项目里都是 rst 格式的文档）。当你觉得完成了一定的工作量，想做个阶段性的提交： 向这个本地的代码仓库添加当前目录的所有改动： 1$ git add . 或者只是添加某个文件： 1$ git add -p 我在项目中添加了了一个文件用 ==ｇｉｔ ｓｔａｔｕｓ== 来查看状态 红色的说明还没有被添加到ｇｉｔ仓库中 添加完之后 我们再次查看状态 发现已经变绿了 我们可以输入 1$ git status 可以看到状态的变化是从红色色到绿色，即 unstage 到 add。在完成添加之后，我们就可以写入相应的提交信息——如这次修改添加了什么内容 、这次修改修复了什么问题等等。在我们的工作流程里，我们使用 Jira 这样的工具来管理我们的项目，也会在我们的 Commit Message 里写上作者的名字，如下： 1$ git commit -m \"nengneng : first commit\" 在这里的nengneng 对应于用户名，后面的提交信息也会写明这个任务是干嘛的。 由于有测试的存在，在完成提交之后，我们就需要运行相应的测试来保证我们没有破坏原来的功能。因此，我们就可以PUSH我们的代码到服务器端： 1$ git push 最后 我们去github 上传的仓库看看我们上传的项目： 大功告成","tags":[{"name":"Git","slug":"Git","permalink":"http://yoursite.com/tags/Git/"}]},{"title":"Web开发全栈工程师2017路线图","date":"2017-03-20T02:10:00.484Z","path":"2017/03/20/Web开发全栈工程师2017路线图/","text":"100+免费资源用于学习全栈Web开发下面的列表并不意味着是排他性的，它更像是一个链接的集合，帮助我一路上（并希望可以帮助你）。如你所见，我专注于Javascript，React和Node.js.还有大量关于面试准备和申请工作的信息 我还有很多书签，所以我会更新和添加链接，因为我去。如果你有贡献，请随时提交公关！目录 开始 怎么学 什么是最有用的CS书签 程序和类 Learn HTML Learn CSS Learn Javascript Learn React.js Full Stack Tutorials Learn Node.js Learn APIs Learn Databases 学习认证 Learn Git Games &amp; Challenge Websites Free Programming Books Open Source Contribution Opportunities Am I Ready to be a Developer? Software Developer Success Stories Resume’s，Portfolio，LinkedIn，面试准备和薪资信息 Start Here Take a look at the big picture: Web Developer Roadpath Youtube video outlining what to learn (similar to above, but in video format) - Watch this if you want to become a web developer My journey to becoming a web developer from scratch without a CS degree (and what I learned from it) (Medium) What happens when you type google into your address bar? [Reddit Link] Tuts Plus - The http protocol every web developer must know Find a local Web Development related Meetup! How to Learn How to Learn. Coursera Course (Not CS Specific) - Learning how to learn Repetition, Repetition, Repetition - A great discussion on study techniques Reddit Post What is the Single most useful CS Bookmark you have? What is the single most useful CS Bookmark you have? [Reddit Link] Learn X in Y Minutes What CS Majors Should Know Google’s Technical Development Guide CSS Tricks - Complete Flexbox Guide Regex Cheat Sheet DevDocs Awesome List of Everything Programming How to Break Into the Tech Industry—a Guide to Job Hunting and Tech Interviews Programs and Classes Programs The Odin Project freeCodeCamp The Essential Web Developer Course Classes SANITIZED list of 530+ free online programming/CS courses (MOOCs) with feedback(i.e. exams/homeworks/assignments) that you can start this month (December 2016) - Needs Updating Udacity Free Web Development Courses (Google) Assorted Reddit Links (Still need to sort) Tutorial/Screencast: Let’s Learn Algorithms: An Intro to Binary Search Thoughts on Coding Boot camps The Complete Guide to Bootcamps Self Study - My programming notes. 275 Pages of Content [Updated Reddit Link] [Original Reddit Link] Javascript / Node / Angular 1 &amp; 2 / React / Elm / C# / PHP / SQL / Git Google Drive What to do after Colt Steele’s course Watch And Code RegexOne - Learn Regular Expressions Google University Github Repo Learn HTMLAnyone have any cool HTML links? Learn CSS Everything you need to know about Flexbox Seriously the best Flexbox resource I’ve found A visual guide to CSS - CSS Reference CSS Pro Tips - A collection of tips to help take your CSS skills pro. 10 principles for smooth web animations Learn Javascript Javascript Docs Courses/Tutorials Courses.AngularClass.com - Topics Include: webpack, nodejs, npm, es5, es6, esnext, &amp; rxjs, typescript [Course Link] [Reddit Post] Edabit - Learn Javascript With Interactive Challenges: Earn XP, Unlock Achievements &amp; Climb The Leaderboard [Edabit - Website Link] [Reddit Post] Free Advanced JavaScript Courses - Learn Object Oriented Programming, Call Apply, and Bind, Testing, Functional Programming, and much more Intermediate Course - Udacity - OOP JS Projects JS 30 For 30 - 30 Projects for 30 Days Learn to Code with Projects - enlight.ml 13 Weeks of Javascript (Medium) - TONS of links to JS resources Articles/Books Recursion, Recursion, Recursion (Medium) Eloquent JS - Free Javascript Ebook You don’t know JS - Free, hosted on Github Javascript Garden - learn about the quirky parts of JS JS - The Good Parts .pdf Learning js Design patterns - Reusable solutions to commonly occurring problems Asynchronous Module Definition Learn React JS Official React Docs Official React Tutorial 3rd Party Tutorials 10 React Mini Patterns Top 5 Tutorials for getting started with React 10 best ReactJS tutorials React Starter Project Search Exploring the react Ecosystem! - Article Code academy React program Great Free React books - Use this link first Medium Links: React Components, Elements, and Instances (Medium) Working with React Beginners guide to React Router (Medium) Angular JS vs React JS (Medium) Full Stack Tutorials Intro to Back End Web Development Deploying Applications with Heroku Client Server Communication Serverless Stack is a comprehensive guide to creating full-stack serverless applications. Create a note taking app from scratch using React.js, AWS Lambda, API Gateway, DynamoDB, and Cognito. Express - Using a DB with Mongoose Node JS and Databases Node JS and Authentication Express JS Database Integration MERN Stack Tutorial - Mongo, Express, React, Node MongoDB MERN Tutorial Series Full Stack MERN Tutorial - Youtube Build a URL Shortener with Node, Hapi, and Mongo How to Create a Complete Express.js + Node.js + MongoDB CRUD and REST Skeleton Building web app using react.js, express.js, node.js and mongodb - Part 1, 2 Trello tribute with Phoenix, React, Redux, PostgreSQL - 12 parts Create a character voting app using React, Node.js, MongoDB and Socket.IO Building a React Universal Blog App: A Step-by-Step Guide Building a Secure RESTful Node.js app Cool stuff other people have built: Belgian Beer Explorer with React, Bootstrap, Node.js and Postgres 90 Full Stack React Examples (some with tuts) Learn Node JS Official Node.js Docs Best Resource for learning Node.js [Reddit Link] Youtube Colt Steele’s Bootcamp Node School Medium - Why the hell would you use Node? Building a modern backend API with Node Node JS Login with Passport - Youtube 10 Best Practices for Writing Node.js REST APIs Learn APIs Where to start with learning APIs [Reddit Link] What is an API? In English Please. (Medium) Build Node.js RESTful APIs in 10 Minutes Free Intro to APIs Book/Course by Zapier Google Maps API Distance Calculator Web Services API Build and Secure a Backend API Server Learn Databases SQL vs NoSQL Intro to Relational Databases - SQL, DB-API, and More! MongoDB University - Numerous classes on learning MongoDB PostgreSQL Tutorial PostgreSQL Exercises Learn PostgreSQL (Github) Try Redis Redis Tutorial Learn Authentication Authentication &amp; Authorization: OAuth Learn about JSON Web Tokens OAuth 2 Passwordless Authentication with React and Auth0 Learn Git Official Tutorial - Learn Git in 15 Minutes Official Docs Other Tuts: Git, the simple guide Learn Git Branching - Level by Level learning Learn Git in 30 Minutes - Article Here are all the Git commands I used last week and what they do (Medium) Why to Use GIT No, I have no side projects to show you Games and Challenge Websites Games to learn Programming in an easy and fun way [Reddit Link] Flex Box Froggy Flex Box Defense Edabit Coding Game Elevator Saga - JS Scratch - Absolute Basics Hacked - Mobile App teaching through puzzles Coding Challenge Websites [Reddit Link] [Reddit Link #2] Medium - 10 most popular coding challenge sites of 2016 Code Wars Coding Game Hacker Rank (some debate about this being good/bad Project Euler (math focus) Exercism Free Programming Books O’Reilly Offering Programming eBooks for Free (Reddit) GitHub - Thousands of free programming Books on every topic Non-Technical Books to make you a better Programmer (Reddit) Open Source Contribution Opportunities Contributing to Open Source on GitHub - The official GitHub guide. How do I get skilled enough to work on open source projects? Open Source Contribution Opportunites [Reddit Discussion] Redditor Form to fill out to get notified about Open Source Opportunities Up For Grabs - Browse a list of projects with curated tasks Hacktoberfest - Open source activity held every October. Easy to participate, and you get a free t-shirt! I’m afraid if I say anything on Github people will laugh at me and I will die. Am I Ready to be a Developer? Readiness Self taught front end devs… When did you know that you were “Job ready”? People who are self-taught developers, how long did it take you to get your first job? When do you know when you’re ready to start interviewing? Software developers- what is the best advice you have for people learning CS? I want a career in programming What should you know as a web dev just out of college? Reddit Discussion - newer What CS Majors Should Know - older How I got started with Side Projects - link What are some goals a beginning Self-Taught Developer should have? Computer programmers of Reddit, what is your best advice to someone who is currently learning how to code? I began teaching myself to code a year ago. I got hired at my first job 4 months ago. Here is a breakdown of somethings I was not ready for (FYI job is remote ruby/rails dev) Software Developer Success Stories Success Stories 18 months ago I didn’t know how to code, I’m now a self-taught programmer who’s made apps for the NBA, NHL, and schools like Purdue, Notre Dame, Alabama and Clemson. I’m now releasing my software under the MIT license for anyone’s use — AMA! Last year I was unemployed and miserable. Using this sub and resources, I’ve been full time employed for a year. I did it with all free resources. I wanna share with you how I did it. (IOS) I began teaching myself to code a year ago. I got hired at my first job 4 months ago. Here is a breakdown of somethings I was not ready for (FYI job is remote ruby/rails dev) I’m 32 years old, and just started my first full-time job as a developer. One year ago my programming knowledge was basically nil. Everything I learned, I found via /r/learnprogramming, so just wanted to share my experience. From zero to software developer - Not really a success story, but a lot of redditors share how they learned. Great for beginners with no path Get The JobResume, Portfolio, LinkedIn, Interview Prep, and Salary Information How to Apply I spent 3 months applying to jobs after a coding bootcamp. Here’s what I learned. (Medium) Lessons from my Post-bootcamp Job search (Medium) How to land a six figure job in tech with no connections (Medium) Resume &amp; LinkedIn What are some of the best resuмe formats you’ve seen? Model examples for Fullstack Developer LinkedIn profiles Personal Projects Recruiters, what kind of CS projects impress? Interview Prep CS50 - Prep and Practice for Technical Interviews [YouTube] How to Break Into the Tech Industry—a Guide to Job Hunting and Tech Interviews Common Javascript Interview Questions Repo Github Repo - All questions and answers Reddit Post - Discussion, with additional questions and answers Ammon Bartram - Ask an interviewer anything: interview questions, answers, mistakes Sharing some interview tips (Silicon valley employee) Job interview questions to ask the interviewer I suck at programming interviews. When solving an interview problem, talk all the time. Hiring managers (or other seasoned developers), what qualities do you look for in your ideal candidate? Post your best interview questions Been interviewing with a lot of tech startups as a frontend dev, here are the technical questions I’ve been asked (MID-SENIOR LEVEL) 10 Interview Questions every JS Developer should know (Medium) Salary Information 12/2016 Salary Sharing Thread (&lt;2 yrs Experience) Salary Negotiations and how not to set a bunch of money on fire (Medium) 10 Rules for negotiating a job offer (Medium) How not to bomb your offer negotiation (Medium)","tags":[{"name":"Web开发","slug":"Web开发","permalink":"http://yoursite.com/tags/Web开发/"}]},{"title":"Web开发者2017路线图","date":"2017-03-20T01:38:27.548Z","path":"2017/03/20/Web开发者2017路线图/","text":"2017年Web开发者的学习路线图 下面您将找到一组图表，说明您可以采取的路径和您想要采用的技术，以便成为前端，后端或devops。我为我的一位老教授制作了这些图表，他想要与大学生分享他们的观点。 如果你认为这些都可以改进反正，请做建议。 🚀 介绍 🎨前端路线图 👽 后端路线图对于后端，我个人喜欢Node JS和PHP-7的全时间，我已经尝试了最近的Go和我非常喜欢它。除了这些，如果我要选择另一个，我会去Ruby。但这只是我个人的喜好，你可以选择任何显示的语言，你会好的。 👷 DevOps的路线图 🚦 Wrap Up如果你认为任何路线图可以改进，请打开公关与任何更新，并提交任何问题。此外，我会继续改进这一点，所以你可能想要观察/ star这个存储库重新访问。 ☑ TODO [X] Add Frontend Roadmap [X] Add Backend Roadmap [X] Add DevOps Roadmap [ ] Add relevant resources for each 👬 ContributionThe roadmaps are built using Balsamiq. Project file can be found at /ROADMAPS.bmpr, open it in balsamiq, do the necessary modifications, export the diagrams as PNG files, put them in the Readme at relevant places and create a PR. Open pull request with improvements Discuss ideas in issues Spread the word Reach out to me directly at kamranahmed.se@gmail.com or on twitter @kamranahmedse Licence Roadmap to becoming a web developer in 2017 Below you find a set of charts demonstrating the paths that you can take and the technologies that you would want to adopt in order to become a frontend, backend or a devops. I made these charts for an old professor of mine who wanted something to share with his college students to give them a perspective. If you think that these can be improved in anyway, please do suggest. 🚀 Introduction 🎨 Frontend Roadmap 👽 Backend RoadmapFor the backend, personally I would prefer Node JS and PHP-7 for the full time plus I have been experimenting lately with Go and I quite like it. Apart from these, if I have to choose another one, I would go for Ruby. However this is just my personal preference, you can choose any of the shown languages and you will be good. 👷 DevOps Roadmap 🚦 Wrap UpIf you think any of the roadmaps can be improved, please do open a PR with any updates and submit any issues. Also, I will continue to improve this, so you might want to watch/star this repository to revisit. ☑ TODO [X] Add Frontend Roadmap [X] Add Backend Roadmap [X] Add DevOps Roadmap [ ] Add relevant resources for each 👬 ContributionThe roadmaps are built using Balsamiq. Project file can be found at /ROADMAPS.bmpr, open it in balsamiq, do the necessary modifications, export the diagrams as PNG files, put them in the Readme at relevant places and create a PR. Open pull request with improvements Discuss ideas in issues Spread the word Reach out to me directly at kamranahmed.se@gmail.com or on twitter @kamranahmedse Licence","tags":[{"name":"Web开发","slug":"Web开发","permalink":"http://yoursite.com/tags/Web开发/"}]},{"title":"JVM学习笔记（三）垃圾收集器与内存分配策略","date":"2017-03-18T05:20:25.061Z","path":"2017/03/18/JVM学习笔记（三）垃圾收集器与内存分配策略/","text":"第二部分 垃圾收集器与内存分配策略Java与C++之间有一堵由内存动态分配和垃圾收集技术所围成的“高墙”，墙外面的人想进去，墙里面的人想出来。概述垃圾收集（Garbage Collection，GC）需要完成的三件事情: 1 哪些内存需要回收？ -[] 内存区域-回收条件2 什么时候回收？ -[] 多线程/安全点3 如何回收？ -[] 回收算法 当要排查各种内存溢出、内存泄漏问题时，当垃圾收集称为系统达到更高并发量的瓶颈时，我们就需要对这些”自动化”的技术实施必要的监控和调节。 1.程序计数器、虚拟机栈、本地方法栈3个区域随线程而生，随线程而灭；每一个栈帧中分配多少内存基本上在类结构确定下来的时候就已知。因此这几个区域的内存分配和回收都具有确定性，不需过多考虑回收问题，方法结束或者线程结束时，内存自然就随之回收了。2.Java堆和方法区则不一样，一个接口中的多个实现类需要的内存可能不一样，一个方法中的多个分支需要的内存也可能不一样，只有在程序处于运行期间才知道会创建哪些对象，这部分内存的分配和回收都是动态的，垃圾收集器所关注的是这部分内存！ 对象已死吗？垃圾回收器在对堆进行回收前，首要确定的事情就是这些对象之间哪些还存活着，哪些已经死去？ 引用计数算法 定义：引用计数算法（Reference Counting）:给对象添加一个引用计数器，每当一个地方引用它时，计数器值就+1；当引用失效时，计数器值就-1；任何时刻计数器为0的对象就是不可能被再使用的； 优点：实现简单，判定效率高；微软的COM技术、Python中都使用了Reference Couting算法进行内存管理 缺点：由于其很难解决对象之间相互循环引用的问题，主流Java虚拟机里面都没有选用Refrence Couting算法来管理内存； 程序计数器 程序计数器（Program Counter Register）是一块比较小的内存空间，它可以看作是当前线程所执行的字节码的行号指示器； PCR为线程私有内存； 是唯一一个在Java虚拟机规范中没有规定任何OOM情况的区域； 可达性分析算法 定义：可达性分析（Reachability Analysis）判断对象存活的基本思路：通过一系列的称为GC Roots的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链（Reference Chain）,当一个对象到GC Roots没有任何引用链相连（即GC Roots到这个对象不可达）时，则证明此对象是不可用的； ![enter description here][1] Java语言中，可作为GC Roots对象包括： 虚拟机栈（栈帧中的本地变量表）中引用的对象； 方法区中类静态属性引用的对象； 方法区中产量引用的对象； 本地方法栈中JNI（即一般的Native方法）引用的对象 再谈引用JDk1.2之后，Java对引用概念进行了扩充，将引用分为强引用、软引用、弱引用、虚引用4种，4种强度一次逐渐减弱。 强引用（Strong Reference）是指在程序代码之中普遍存在的，类似Object obj=new Object()这类的引用，只要强引用存在，对象就不会发生GC； 软引用（Soft Reference）是用来描述一些还有用但并非必须的对象。对于软引用关联着的对象，在系统将要发生OOM异常之前，将会把这些对象列进回收范围之中进行第二次回收，如果这次回收后还没有足够的内存，才会抛出OOM异常。 弱引用（Weak Reference）是用来描述非必须对象的，强度比软引用更弱，被弱引用关联的对象只能生存到下一次GC发生之前。当垃圾回收器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象 虚引用（Phantom Reference）也称为幽灵引用或者幻影引用，它是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。 回收方法区 在方法区中进行垃圾收集的性价比一般比较低；而在Heap中，尤其是在新生代，常规应用进行一次垃圾收集一般回收70%~95%的空间，而永久代的垃圾收集效率远低于此； 永久代的垃圾收集主要回收两部分内容：废弃常量和无用的类； 回收废弃常量与回收Java堆中的对象类似； 判定一个类是否是无用的类条件相对苛刻： 该类所有实例都已被回收，即Java堆中不存在该类的任何实例； 加载该类的ClassLoader已经被回收； 该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该方法。 在大量使用反射、动态代理、CGLib等ByteCode框架、动态生成JSP以及OSGi这类自定义ClassLoader的场景都需要虚拟机具备类卸载的功能，以保证永久代不会溢出。 垃圾收集算法只介绍内存回收的方法论（算法思想及发展过程），不讨论具体算法实现。 G1收集器（Garbage-First）面向服务器端应用的垃圾收集器，计划未来替代CMS收集器。 理解GC日志垃圾收集器参数总结内存分配与回收策略对象优先在Eden分配大对象直接进入老年代长期存活的对象将进入老年代动态对象年龄判定空间分配担保","tags":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/tags/JVM/"}]},{"title":"JVM学习笔记（二）Java内存区域与内存溢出异常","date":"2017-03-18T02:35:33.376Z","path":"2017/03/18/JVM学习笔记（二）Java内存区域与内存溢出异常/","text":"第二部分 自动内存管理机制《深入理解Java虚拟机 JVM高级特性与最佳实践》 第二章 Java内存区域与内存溢出异常运行时的数据区域 程序计数器 程序计数器（Program Counter Register）是一块比较小的内存空间，它可以看作是当前线程所执行的字节码的行号指示器； PCR为线程私有内存； 是唯一一个在Java虚拟机规范中没有规定任何OOM情况的区域； Java虚拟机栈 Java虚拟机栈（Java Virtual Machine Stacks）描述的是Java方法执行的内存模型：每个方法在在执行的同时都会创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法接口等信息。每个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈出栈的过程。 Java虚拟机栈也是线程私有，它的生命周期与线程相同。 Java内存区常分为堆内存（Heap）和栈内存（Stack）； OOM情况：（1）线程请求的栈深度&gt;虚拟机所运行的最大深度；（2）虚拟机动态扩展时无法申请到足够的内存 本地方法栈 本地方法栈（Native Method Stack）与虚拟机所发挥的作用非常相似的，他们之间的区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则为虚拟机所使用的Native方法服务。 HotSpot虚拟机把本地方法栈和虚拟机栈合二为一； 此区域会抛StackOverflowError 和 OutofMemoryError异常 Java堆 Java堆（Java Heap）是Java虚拟机所管理的内存中最大的一块，Java Heap是所有线程共享的一块内存区域，在VM启动时创建 所有的对象实例以及数组都要在堆上分配（不绝对：栈上分配、标量替换优化技术）； Java堆是垃圾收集器管理的主要区域，也可称做GC堆（Garbage Collected Heap） 从内存回收的角度，现代收集器基本都采用分代收集算法，Java Heap可细分为新生代和老年代，再细致可分为Eden空间、From Survivor空间、To Survivor空间等–&gt;更好回收内存。 从内存分配的角度，线程共享的Java堆中可能分出多个线程私有的分配缓存区（TLAB：Thread Local Allocation Buffer）–&gt;更快分配内存。 Java堆出于逻辑连续的内存空间中，物理上可不连续，如磁盘空间一样； Java堆在实现上可时，可以实现成固定大小的，也可以按照可扩展实现（-Xmx和-Xms控制）； OOM情况：堆中没有内存完成实例分配，堆也无法再扩展时 方法区方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 也称为永久代（Permanent Generation）但随着Java8的到来，已放弃永久代改为采用Native Memory来实现方法区的规划。 此区域回收目标主要是针对常量池的回收和对类型的卸载。 运行时常量池 运行时常量池（Runtime Constants Pool）是方法区的一部分 Class文件中除了有类的版本、字段、方法、接口等描述的信息外，还有一项信息是常量池（Constant Pool Table）,用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放。 直接内存直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域。 能在一些场景中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据。 直接内存的分配不会受到Java堆大小的限制，但会收到本机总内存（RAM以及SWAP/分页文件）大小以及处理器寻址空间的限制。 设置Xmx等参数信息时注意不能忽略直接内存，不然会引起OOM。 HotSpot虚拟机对象的创建为新生对象分配内存的分配方式由Java堆是否规整决定，而Java堆是否规整又由所采用的垃圾回收器是否带有压缩整理功能决定。 指针碰撞（Bump the Pointer）分配方式：Serial、ParNew等带有Compact过程的收集器 空闲列表（Free List）分配方式：类CMS这种基于Mark-Sweep算法的收集器 对分配内存空间的动作进行同步处理—VM采用CAS配上失败重试的方式保证更新操作的原子性； 本地线程分配缓冲（Thread Local Allocation Buffer,TLAB）：把内存分配动作按线程划分在不同 空间中进行，即每个线程在Java堆中预先分配一小块内存，虚拟机是否启用TLAB，可由-XX:+/-UseTLAB参数设定； 对象的内存布局 对象在内存中存储的布局可以分为3块区域：对象头（Header）、实例数据（Instance Data）、和对齐填充（Padding）; 对象头包含2部分信息 Mark Word,存储对象自身的运行时数据（如哈希码、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳）；由于对象头与对象自身定义的数据存储大小无关，考虑到VM的空间效率，Mark Word被设计成非固定的数据结构以便在极小的空间内存储尽量多的信息，他会根据对象的状态复用自己的存储空间。 类型指针，即对象指向它的类元数据的指针，VM通过这个指针来确定这个对象是哪个类的实例。 实例数据是对象真正存储的有效信息，也似乎程序代码中定义的各种类型的字段内容。 对齐填充，并不必然存在，没有特别含义，仅仅起占位符的作用，8byte对齐。 对象的访问定位Java程序需要通过栈上的reference数据来操作堆上的具体对象，对象访问方法取决于VM实现而定，目前主流访问方式有使用句柄和直接指针2种： 句柄访问Java堆中划分出一块内存作为句柄池，reference中存储对象的句柄地址，句柄中包含对象实例数据与类型数据各自的具体地址信息； 直接指针访问 Java堆对象的布局中必须考虑如何放置访问类型数据的相关信息，reference中存储对象地址； 两种访问方式各有优势 使用句柄访问最大的好处是reference中存储的是稳定的句柄地址，在对象被移动（GC时移动对象是很普遍的行为）时只会改变句柄中的实例数据指针，而reference本身不需要修改； 使用直接指针访问方式的最大好处是速度更快，它节省了一次指针定位的时间开销，由于对象访问在Java中非常频繁，因此这类开销积少成多后也是一项非常可观的执行成本； HotSpot虚拟机采用指针访问方式进行对象访问，从整个软件开发范围看，各种语言和框架使用句柄来访问的情况也非常常见。 实战OOM异常Java堆溢出 Java堆用于存储对象实例，只要不断创建对象，并保证GC Roots到对象之间有可达路径来避免回收机制清除这些对象，那么当对象数量到达最大堆的容量限制后就会产生OOM。 控制参数 -Xms：堆最小值 -Xmx：堆最大值 -XX:+HeapDumpOnOutOfMemoryError：让虚拟机在出现OOM异常时Dump出当前内存堆转储快照以便事后进行分析 异常信息Java.lang.OutOfMemory + Java Heap Space 解决办法以内存映像分析工具（Eclipse Memory Analyzer）对Dump出来的堆转储快照进行分析，重点是确认内存中的对象是否是必要的，即判断是内存泄漏（Memory Leak）还是内存溢出（Memory Overflow） 如果是内存泄漏：通过工具查看泄漏对象到GC Roots的引用链，掌握泄漏对象的类型信息及引用链的信息后可较准确的定位代码位置； 如果是内存溢出：可通过检查VM的堆参数（-Xmx和-Xms），与机器物理内存对比看是否可以调大；从代码检查是否存在某些对象生命周期过长，持有状态时间过长的情况，尝试减少程序运行期的内存消耗 虚拟机栈和本地方法栈溢出控制参数HotSpot虚拟机不区分虚拟机栈和本地方法栈， -Xoss（设置本地方法栈大小）：参数设置无效; -Xss（栈容量）; 异常信息关于虚拟机栈和本地方法栈，在Java虚拟机规范中描述了两种异常： 如果线程请求的栈深度 &gt; 虚拟机所允许的最大深度，抛出StackOverFlowError异常 如果虚拟机在扩展栈时无法申请到足够的内存空间，抛出OutOfMemoryError异常 解决办法 操作系统分配给每个进程的内存是有限制的，如32位Windwos限制为2G。虚拟机提供了参数来控制Java堆和方法区这两部分内存的最大值， 虚拟机栈和本地方法栈可瓜分的剩余内存=2G（操作系统限制）-Xmx（最大堆容量）-MaxPermSize（最大方法区容量）-虚拟机进程本身耗费内存；程序计数器消耗内存很小，可以忽略。 每个线程分配到的栈容量越大，可以建立的线程数就越少，建立线程时候就越容易耗尽剩余内存。 按虚拟机默认参数，栈深度在大多数情况下达到1000~2000完全没问题，对于正常方法调用（包括递归），这个深度应该完全够用；但如果是建立过多线程导致内存溢出，在不能减少线程数或者更换X64位虚拟机的情况下，就只能通过减少最大堆和减少栈容量来换取更多的线程 方法区和运行时常量区溢出运行时常量池是方法区的一部分，因此这两个区域的溢出可放在一起进行。 控制参数 -XX:PermSize（方法区最小容量） -XX:MaxPermSize （方法区最大容量） 异常信息OutOfMemoryError 后面跟随PermGen space 说明运行时常量池属于方法区（HotSpot虚拟机中的永久代）的一部分 本机直接内存溢出控制参数 DirectMemory容量可通过-XX:MaxDirectMemorySize指定，不指定默认与-Xmx(Java堆最大值)一样。 异常信息由DirectMemory导致的内存溢出，一个明显的特征是在Heap Dump文件中不会看见明显的异常； 如果发现OOM之后Dump文件很小，而程序又直接或简介使用了NIO，可以考虑是不是这方面的原因。","tags":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/tags/JVM/"}]},{"title":"深入理解Java虚拟机（一）","date":"2017-03-17T03:47:06.765Z","path":"2017/03/17/深入理解Java虚拟机（一）/","text":"第一部分 走进Java世界上没有完美的程序，但我们不能因此而沮丧，因为写程序本来就是一个不断追求完美的过程。1.1 概述Java不仅仅是一门变成语言，还是一个由一系列计算机软件和规范形成的技术体系，这个技术体系提供的完整的 用于软件开发和跨平台部署的支持环境，并且广泛应用于嵌入式系统，移动终端，企业服务器，大型机等各种场所。 Java能获得如此广泛的认可，除了他拥有一门结构严谨，面向对象的编程语言之外，还有许多不可忽视的优点：他摆脱了硬件平台的束缚，实现了一次编写，到处运行的理想，他提供了一个向对安全的内存管理和访问机制，避免了绝大部分的内存泄漏和指针越界问题，它实现了热点检测代码和运行时编译以及优化，这使得Java应用能随着运行使劲按的增加而获得更高的性能，它有一套完整的应用程序接口，还有无数来自商业机构和开源社区的第三方库莱帮着它实现各种各样的功能。。。。。 当我们在使用一种技术的时候，如果不在依赖书本和他人就能得到这些答案，那才算是得到了“不惑”的境界 1.2 Java技术体系从广义上讲，Clojure，JRuby，Groovy等运行在Java虚拟机上的语言以及相关的程序都属于Java中技术体系中的一部分，如果型传统意义上来说，Sun公司官方定义的Java技术体系包括以下几个组成部分： Java程序设计语言 各种硬件平台上的Java虚拟机 Class文件格式 Java的API 来自商业机构和开源社区的第三方Java类库 JDK 包含了Java程序设计语言，Java虚拟机，和Java的API，来用于支持Java开发的最小的环境，另外的，Java API中的Java SE API子集和Java虚拟机这两部分统称为JRE（Java Runtime Environment），JRE 支持Java运行的标准环境。 以上Java技术体系图是根据各个组成部分的功能来进行划分的。如果按照Java技术服务的领域来划分，可分为以下4个平台： 1.Java Caard2.Java ME3.JavaSE（Standard Edition）：支持面向桌面级应用的java平台，提供了完整的Java核心API，这个版本以前称为J2SE。 JavaEE（Enterprise Edition）：支持使用多层架构的企业应用（如ERP、CRM应用)的Java平台，除了提高Java SE API外，还对其做了打了扩充，并提供了相关部署支持，这个版本以前称为J2EE。javaEE对JavaSE提供的扩展一般以java.作为包名，而以java.为包名的都是javaSE API的核心包，但由于历史原因，一部分曾经是扩展包的API后来进入了核心包，因此核心包中也包含了不少javax.*的包名。 Java语言口号 Write Once , Run Anywhere。 JDK命名JDK从1.5版本开始，官方在正式文档与宣传上不再使用类似JDK1.5的命名，只在程序内部使用的的开发版本号（Developer Version，例如java –version的输出）中才继续沿用1.5,1.6…。而攻克版本号（Product Version）则改为JDK5、JDK6、JDK7的命名方式。Java开源 2006年11月13日的JavaOne大会上，Sun公司宣布开源java,JDK1.6在12月11日发布。并建立了OpenJDK组织对浙西源码进行独立管理，除了极少量的产权代码（Encumbered Code，这部分代码大多史Sun本身也无权限进行开源处理的）外，OpenJDK几乎包括了Sun JDK的全部代码。Java虚拟机发展史 Sun公司的java虚拟机Sun Classic VM： JDK1.0提供的一个纯解释执行的Java虚拟机。Exact VM:JDK1.2提供，具有两级及时编译器、编译器与解释器混合工作模式，使用了准确式内存管理（Exact Memory Management，也叫Non-Conservative/Accurate Memory Management）而得名，即虚拟机可以知道内存中某个位置的数据具体式什么类型。譬如内存中有一个32位的整数123456，它到底式一个reference类型指向123456的内存地址还是一个数值位123456的整数，虚拟机将有能力分辨出来，这样才能在GC（垃圾收集）的时候准确判断堆上的数据是否还可能被使用。Exact VM抛弃了Classic VM基于handler的对象查找方式（原因是进行GC后对象将可能会被移动位置，如果将地址为123456的对象移动到654321，在没有明确信息表明内存中哪些数据是reference的前提，虚拟机不敢把内存中所有为123456的值改成654321的，所以要使用句柄来保持reference值的稳定），这样每次对象都少了一次间接查找的开销，提升执行性能。HotSpot VM：(目前一直使用)JDK1.2提供，内置了JIT(Just in Time)编译器，继承了前面2款虚拟机的优点如：Exact Memory Management。自己新技术，如其名：HotSpot指的就是它的热点代码探测技术，ExactVM中也有，热点探测可以通过执行计数器找出最具有编译价值的代码，然后通知JIT编译器以方法为单位进行编译。其它公司的Java虚拟机 JRockit VM：BEA公司收购的，并将其发展为一款专门为服务器硬件和服务器端应用场景高度优化的虚拟机，由于不太关注程序启动速度只专注与服务端应用，因此JRockit内部不包含解析器实现，全部代码都靠即使编译器编译执行，JRockit的垃圾收集器和MissionControl服务套件等部分的实现，在众多Java虚拟机中也处于领先。 可以运行在Java虚拟机上的语言 对于这些运行于java虚拟机之上，Java语言之外的语言，来自系统级的、底层底层的支持正在迅速增强，JSR-292为核心的一系列项目和功能改进，推动java虚拟机从“Java语言的虚拟机”向“多语言虚拟机”的方向发展 编写JDK使用的语言 OpenJDK的各个组成部分（Hotspot、JDK API、JAXWS、JAXP….)有的是使用C++编写的，更多的代码则是使用Java自身实现的。","tags":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/tags/JVM/"}]},{"title":"深入理解Java虚拟机（目录）","date":"2017-03-17T02:48:59.770Z","path":"2017/03/17/深入理解Java虚拟机（目录）/","text":"本书一共分为5个章节，13个小结第一部分 走进Java本书的第一部分为后文的讲解建立了良好的基础，尽管了解Java技术的来龙去脉，以及编译自己的OpenJDK对于读书理解Java虚拟机并不是必需的，但是这些准备可以过程可以为走进Java技术和虚拟机提供良好的引导，第一分部只有第一章： 第一章介绍了Java技术体系的过去，现在和未来的一些发展趋势，并且介绍了如何独立的编译一个OpenJDK 7。 第二部分 自动内存管理机制因为程序员把内存控制的权利交给了Java虚拟机，所以可以在编码的时候享受自动内存管理的诸多优势，不过也正是这个原因，一旦出现内存泄漏和溢出得问题，如果不了解虚拟机是怎样使用内存的，那么排查错误将会成为一项艰难的工作。第二部分有2~5章。 第二章讲解了虚拟机内存是如何划分的，以及那部分区域，什么样的操作和代码可以导致内存溢出异常，讲解了各个区域出现内存溢出异常常见的原因。 第三章分析了垃圾收集的算法和JDK 1.7 中提供的几款垃圾收集器的特点以及运行的原理，通过代码示例验证了Java虚拟机中自动内存分配以及回收的主要规则。 第四章加少了JDK发布的6个命令工具和两个可视化的故障处理工具的使用方法。 第五章与读者分享了几个比较比较有代表性的实际案例。还准备了所有开发人员都能亲身实战的练习，读者可以通过实践来获得故障处理和调优的经验。 第三部分 虚拟机执行子系统执行子系统是虚拟机中必不可少的组成部分，了解了虚拟机如何执行程序，才能写出优秀的代码。第三部分包括6~9章： 第六章讲解了Class文件中的各个组成部分，以及每个部分中的定义，数据结构和使用方法，以实战的方法演示了Class文件的数据是如何储存和访问的。 第七章介绍了类加载过程中的“加载”，“验证”，“准备”，“解析”和“初始化”的5个阶段和虚拟机分别执行了那些动作，还介绍了类加载器的工作原理以及其对虚拟机的意义。 第八章分析了虚拟机在执行代码的时候如何找到正确的方法，如何执行方法内的字节码，以及执行代码时设计的内存结构。 第九章通过四个类加载以及执行子系统的案例，分享了使用类加载器和处理字节码的一些值得欣赏和借鉴的思路，并且通过一些实战练习来加深对前面理论知识的理解。 第四部分Java程序从源码编译到字节码以及从字节码编译成本地机器码的两个过程，合并起来就等同于一个传统编译器所执行的编译过程，第四部分主要包括10~11章 第十章分析了Java语言中的泛型，主动装箱和拆箱，条件编译等多种语法糖的前因后果。并且通过实战演示了如何插入式注解处理器来实现一个检查程序命名规范的编译器插件。 第十一章讲解了虚拟机的热点探测方法，HotSpot的即时编译器。编译触发条件，以及如何从虚拟机外部观察和分析JIT编译的数据和结果，此外，还讲解了几种常见的编译优化技术。 第五部分Java语言和虚拟机提供的原生的，完善的多线程支持，这使得它天生就适合开发多线程并发的应用程序。不过我们不能期望系统来完成所有的并打相关的处理，了解并发的内幕也是一个高级程序员不可缺少的课程，第五部分有12~13章 第十二章讲解了虚拟机Java内存的结构和操作，以及原子性，可见性和有序性在Java内存模型中的体现，介绍了先行发生原则的规则和使用，还了解了线程在Java语言中是如何实现的。 第十三章介绍了线程安全涉及的概念和分类，同步实现的方法以及虚拟机的底层运作原理，并且介绍了虚拟机实现高效并发所采取的一系列的锁优化措施。","tags":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/tags/JVM/"}]},{"title":"undertow嵌入式web服务器初体验","date":"2017-03-16T02:15:54.206Z","path":"2017/03/16/undertow嵌入式web服务器初体验/","text":"Github源码做的一个项目，在这里开源，删除了大部分业务代码，将逐步改为一个基于netty5的框架，目前只算得上是一个手脚架吧 netty同时处理HTTP和Websocket，并将HTTP请求路由到相应Action中;使用ehcache实现Session；spring IOC做管理容器，mybatis做sql数据库ORM；spring data mongoDB做mongo的ORM；HikariCP做sql数据库连接池；Gson用于json解析和生成；logback日志处理 ####netty处理HTTP和websocket smart.core.netty.HttpHandler：是一个自定义的ChannelHandler用于处理HTTP和Websocket请求 Handler分别处理HTTP和Websocket 1234567public void messageReceived(ChannelHandlerContext ctx, Object msg) &#123; if (msg instanceof FullHttpRequest) &#123;//如果是HTTP请求，进行HTTP操作 handleHttpRequest(ctx, (FullHttpRequest) msg); &#125; else if (msg instanceof WebSocketFrame) &#123;//如果是Websocket请求，则进行websocket操作 handleWebSocketFrame(ctx, (WebSocketFrame) msg); &#125; &#125; 由于websocket也是基于HTTP的，需要判断是websocket后，将HTTP升级为Websocket 12345678910111213141516171819202122private void handleHttpRequest(ChannelHandlerContext ctx, FullHttpRequest req) &#123; logger.warn(\"uri:\" + req.uri()); if (req.uri().startsWith(\"/ws/join\")) &#123;//如果urL开头为/ws/join则升级为websocket mac = wsBeforeHandler(ctx, req); if (mac == null || mac.length() &lt; 1) &#123; RespTools.paraErrorBack(ctx,req,null); return; &#125; WebSocketServerHandshakerFactory wsFactory = new WebSocketServerHandshakerFactory( getWebSocketLocation(req), null, true); handshaker = wsFactory.newHandshaker(req); if (handshaker == null) &#123; WebSocketServerHandshakerFactory.sendUnsupportedVersionResponse(ctx.channel()); &#125; else &#123; handshaker.handshake(ctx.channel(), req); &#125; &#125; else &#123;//是HTTP请求则路由到Action RouteResult&lt;Action&gt; routeResult = rs.getRouter().route(req.method(), req.uri()); Action action = routeResult.target(); action.act(ctx, req); &#125; &#125; websocket请求处理,这里是从websocket请求中获取客户端传来的json字符串，并将字符串转为javabean 12345678910111213141516171819private void handleWebSocketFrame(ChannelHandlerContext ctx, WebSocketFrame frame) &#123; // Check for closing frame if (frame instanceof CloseWebSocketFrame) &#123; handshaker.close(ctx.channel(), (CloseWebSocketFrame) frame.retain()); return; &#125; if (frame instanceof PingWebSocketFrame) &#123; ctx.write(new PongWebSocketFrame(frame.content().retain())); return; &#125; if (frame instanceof TextWebSocketFrame) &#123; devicePool.join(ctx.channel(), mac); String json = ((TextWebSocketFrame) frame).text(); Logic.ReqRespType data= JsonTools.read(json,Logic.ReqRespType.class); //... return; &#125; &#125; 如果是HTTP则需在RouterSetting中配置路由.比如r.POST(“api/get_verify_code”, getVerifyCodeAct):将url为”api/get_verify_code”的POST请求路由到LoginAct中 123456789101112131415161718192021public class RouterSetting &#123; @Autowired private Router&lt;Action&gt; router; @Autowired private GetVerifyCodeAct getVerifyCodeAct;//w @Autowired private LoginAct loginAct; @Autowired private RegisterAct registerAcc; public Router&lt;Action&gt; getRouter() &#123; routerConfig(this.router); return this.router; &#125; private void routerConfig(Router&lt;Action&gt; r) &#123; r.POST(\"api/get_verify_code\", getVerifyCodeAct); r.ANY(\"api/login\", loginAct); r.GET(\"api/register\", registerAcc); &#125;&#125; Action处理HTTP请求并返回 12345678910111213@Controllerpublic class LoginAct implements Action &#123; private static final Logger logger = LoggerFactory.getLogger(LoginAct.class); @Override public void act(ChannelHandlerContext ctx, FullHttpRequest req) &#123; String ip = HttpTools.getIp(req); String body = Convert.buf2Str(req.content()); Get.Login get = JsonTools.read(body, Get.Login.class);//1.得到HTTP传来的json数据解析为javabean Sub.Register back;//构建返回给客户端的javabean的实例 //... HttpTools.sendCorrectResp(ctx, req, back);//返回给客户端HTTP Response &#125;&#125; 添加Session(依靠ehcache) 12345private void addSession(long userId, String ip) &#123; Logic.DeviceSession session = new Logic.DeviceSession(ip, \"\"); Cache.add(userId + \"\", session, \"6mn\");//设置session的缓存时间为6分钟 //debugSession(userId); &#125; 从HTTP请求中获取IP地址1String ip = HttpTools.getIp(req)； ####netty参数设置12345port=8090netty.boss.thread.count=2netty.worker.thread.count=1netty.so.keepalive=truenetty.so.backlog=100 ####项目依赖1234567891011121314151617181920212223242526272829//---------------------单元测试---------------------------- testCompile group: 'junit', name: 'junit', version: '4.11' //--------------------数据库驱动---------------------------- compile 'org.mongodb:mongodb-driver:3.2.2' compile 'mysql:mysql-connector-java:5.1.38' //-------------------数据库连接池--------------------------- compile 'com.zaxxer:HikariCP:2.4.5' //----------------------ORM------------------------------ compile group: 'org.mybatis', name: 'mybatis', version:mybatisVersion compile group: 'org.mybatis', name: 'mybatis-spring', version:mybatisSpringVersion //-----------------------缓存---------------------------- compile group: 'net.sf.ehcache', name: 'ehcache', version:ehcacheVersion //----------------------工具包---------------------------- compile 'commons-httpclient:commons-httpclient:3.1-rc1' compile 'org.javassist:javassist:3.20.0-GA' //---------------------日志处理---------------------------- compile 'org.slf4j:slf4j-api:1.7.21' compile 'ch.qos.logback:logback-core:1.1.7' compile 'ch.qos.logback:logback-classic:1.1.7' //---------------------json处理--------------------------- compile 'com.google.code.gson:gson:2.6.2' //---------------------netty----------------------------- compile group: 'io.netty', name: 'netty-all', version:nettyVersion //---------------------spring---------------------------- compile group: 'org.springframework', name: 'spring-test', version:springVersion compile group: 'org.springframework', name: 'spring-jdbc', version:springVersion compile(group: 'org.springframework', name: 'spring-context', version:springVersion) &#123; exclude(module: 'commons-logging') &#125;","tags":[{"name":"undertow","slug":"undertow","permalink":"http://yoursite.com/tags/undertow/"}]},{"title":"Springboot 整合 Mybatis","date":"2017-03-16T02:14:30.993Z","path":"2017/03/16/Springboot 整合 Mybatis/","text":"为什么使用Mybatis？ Mybatis是目前很火的SSM框架中的ORM组件，相比Hibernate更加灵活小巧，学习成本也更低，我觉得可维护性也更好些。 但是spring boot官方更只提供了自家的spring data jpa及hibernate的整合方案，而没有给出Mybatis的整合组件。于是上Github，发现了Mybatis提供了它的spring-boot-starter。 ##整合方法 gradle中加入依赖1compile(\"org.mybatis.spring.boot:mybatis-spring-boot-starter:1.1.1\") spring.boot:mybatis-spring-boot-starter中已经包含了对mybatis和mybatis-spring的依赖 在application.yml中配置mybatis12345mybatis: #指定mapper和domain(实体)所在的包 type-aliases-package: me.jcala.blog.domain,me.jcala.blog.mapping #指定使用的类型转换器 type-handlers-package: org.apache.ibatis.type.LocalDateTypeHandler 除此之外mybatis还提供了一下配置12345mybatis: config-location: #mybatis的xml注册文件位置 mapper-locations: #Mapper xml config files (optional) executor-type: #执行类型为: SIMPLE, REUSE还是BATCH configuration: #mybatis的其他配置 在Spring Boot中配置好数据源DataSource可以使用任意数据源，mybatis会自动使用spring boot中所配置的数据库连接池 以上就完成了spring boot对mybatis的整合，超级简单啊 测试一下因为在type-aliases-package: me.jcala.blog.domain,me.jcala.blog.mapping中指定的mapping扫描包为me.jcala.blog.mapping，所以要把写的mapper放到me.jcala.blog.mapping包下。 在me.jcala.blog.mapping下新建一个TestMapper接口123456@Repository@Mapperpublic interface TestMapper &#123; @Insert(\"insert into users set username='zzp',password='zzp105'\") void insert();&#125; 再随便写一个测试的类12345678public class TestForMapper&#123;@AutowiredTestMapper testMapper;@Testpublic void testInsert()&#123; testMapper.insert(); &#125;&#125;","tags":[{"name":"springboot mybatis","slug":"springboot-mybatis","permalink":"http://yoursite.com/tags/springboot-mybatis/"}]},{"title":"微服务","date":"2017-03-16T02:03:09.621Z","path":"2017/03/16/微服务/","text":"欢迎使用 {小书匠}(xiaoshujiang)编辑器，您可以通过==设置==里的修改模板来改变新建文章的内容。 微服务一个新架构术语的定义微服务架构是将软件应用程序设计为一套可独立部署的服务组件。虽然在架构风格上没有精确的定义，但在业务功能、自动化部署、端点智能化以及对语言与数据的离散化控制能力上具备通用特征 “微服务” 是在已经人满为患的软件架构领域出现的新名词。虽然我们对于新的事物往往会抱有一种轻视的态度去认识它。但慢慢的会发现这种软件架构风格变得越发的吸引人。过去几年，我们看到许多实际的项目去使用它。应用后的结果至今也是蛮不错的。更有甚一些同事干脆把它当作构建企业级应用程序的首选。遗憾的是，到目前为止没有更多官方的信息指导我们如何在项目中使用它。 简而言之， 微服务架构的风格 1 是将单一的应用程序作为一组小服务套件来开发的一种方法，每个服务都运行在各自的进程中，并利用轻量化机制（通常是HTTP资源API）实现通信。并且围绕着业务能力构建，通过自动化部署机制实现独立部署。这些服务匹配一套最低限度的中央式管理机制，每个服务可通过不同的编程语言编写，使用不同数据存储技术。 对比着单体式架构风格来理解为服务是再好不过了，一个单体式应用作为一个单一的单元进行构建。构建企业级应用程序通常包含一下三个主要部分： 客户端用户界面（由运行在用户设备上的浏览器中的HTML页面以及JavaScript代码构成） 后端数据库（由大量插入至数据库管理系统的表构成，通常采用关系数据库） 服务器端应用程序 服务器端的应用程序将会处理HTTP请求，执行域逻辑。检索与更新数据库。同时选定HTML视图并将其发送至浏览器端。服务器端应用程序通常为单一逻辑的可执行程序 [15]。任何针对该系统的变更都需要对该服务器端应用程序进行新版本构建与部署。 这样的单体服务器机制在构建此类系统中可谓不可或缺。我们用于处理请求的全部逻辑都运行在单一进程当中，允许大家使用语言中的基本功能以将该应用程序拆分为类、函数以及命名空间。通过这种方式，我们能够在开发人员的笔记本设备上运行并测试应用程序，同时利用一整套部署流程以确保全部变更都经过妥善测试而后被部署在生产环境当中。大家可以将大量实例运行在一套负载均衡方案之后，从而实现横向扩展能力。 单体式应用程序当然能够切实起效，但人们却逐渐发现其中存在着诸多弊端，特别是在将大量应用程序部署在云环境当中的情况下。由于变更周期被大量集中于一处，即使仅仅指向应用程序中的一小部分，单一变更亦要求我们对应用程序整体进行重构与重新部署。随着时间推移，我们往往很难保证理想的模块化结构，这意味着本应只影响单一模块的变更往往会扩散至该模块之外。规模伸缩亦要求我们对整体应用程序进行规模调整，而非单纯为其中必要的部分进行资源扩容。 单体应用程序与微服务应用程序图一：单体应用程序与微服务应用程序 正是这些弊端造就了如今的微服务架构风格：即以服务套件的形式构建应用程序。除了各服务能够单独进行部署与规模伸缩之外，每项服务还具备牢固的模块边界，甚至允许我们在不同的服务当中使用不同的编程语言进行代码编写。另外，各服务亦可由不同团队负责管理。 我们认为微服务风格并不算什么新鲜事物或者创新成果，其历史至少可以追溯至Unix设计时代。但我们同时亦坚信，微服务架构一直未能受到足够的重视，而其确实能够帮助大家更好地完成软件开发工作。 微服务架构的特性我们无法给微服务架构风格出具一条确切的定义，但我们却可以根据该架构表现出的各类共同特性对其加以描述。正如各类根据共同特性做出的定义一样，并不是所有微服务架构都符合这些特性，但可以肯定的是具备这些特性的微服务架构占据大部分比例。尽管我们各部分内容的作者仅仅是相关技术社区中的活跃成员，但制作这份文档是为了对采用微服务架构的工作流程及成果做出总结，而且其中仍有相当一部分表述并非严格定义，只应作为常见情况考量。 通过服务实现组件化长久以来，我们一直参与软件行业之内并意识到人们对利用组件整合方式构建系统的渴望——这种思路与我们在物理世界中采取的构建机制非常相似。而在过去几十年当中，我们发现已经有大量公共库渗透到多数语言平台当中并成为其坚实的组成部分。 在谈到我们所使用的组件时，大家可能会发现不同群体对组件的定义也有所区别。我们对组件做出的定义是，其属于软件中的一类单元，且具备可更替性与可升级性。 微服务架构会使用这些库，但其实现组件化的主要手段则是将软件拆分成多个服务。我们将“库”定义为与程序相对接且可通过内存内函数调用发挥作用的组件，而“服务”则为进程之外的组件，其可通过Web服务请求或者远程程序调用等方式实现通信。（这里的服务概念与多数OO程序 3 中的服务对象概念有所区别）。 将服务作为组件加以使用（而非库）的一大原因在于，服务具备独立可部署能力。如果大家的应用程序 4 由单一进程中的多个库 构成，那么指向任何单一组件的变更都会致使该应用程序必须进行重新部署。但如果该应用程序被拆分成多项服务，那么单一服务变更将只会致使该服务进行重新部署。虽然这并非绝对，例如某些变更会导致服务接口受到影响，但一套优秀的微服务架构旨在尽可能少地对服务协议中的服务边界及演进机制产生干扰。 将服务作为组件的另一个理由在于实现更为明确的组件接口。大多数编程语言并不具备用于定义明确发布接口的良好机制。一般来讲，其只会提供说明文档及规则以防止用户打破组件封装，但这同时亦会导致不同组件之间的耦合程度过高。利用明确的远程调用机制，服务能够轻松避免此类难题。 但以这种方式使用服务亦存在一定弊端。远程调用在资源需求方面往往远高于进程内调用，因此远程API需要采取粗粒度设计，但这亦会增加API的使用难度。如果大家需要更改不同组件间的职能分配，那么这类需求在跨越进程边界时往往不易实现。 通过粗略观察，我们往往会发现这些服务会与各运行时进程相映射——但这仅仅只是第一印象。一项服务可能由多个进程构成，且各进程始终共同进行开发与部署——这方面实例包括只由单一服务所使用的应用程序进程以及数据库。 围绕业务功能构建组织当着眼于将单一大型应用程序拆分成多个组成部分时，管理人员通常更重视技术层，其中具体包括UI团队、服务器端逻辑团队以及数据库团队。当这些团队据此进行拆分时，即使是最简单的变更也将给项目造成跨团队协作负担，并因此导致时间与预算的双重支出。睿智的团队会对此进行优化，同时采取两害相权取其轻的办法——即强制要求逻辑存在于一切与之相对接的应用程序当中。换言之，也就是实现逻辑的普遍存在性。这正是所谓康威法则 5 的一种实际表现形式。 任何组织在设计一套系统（广义层面的系统）时，其设计成果都会直接体现该组织所使用的沟通结构。 –梅尔文·康威，1967年 康威定律的实际体现图二：康威定律的实际体现 微服务方案对于各部门而言是一种不同于以往，且以业务功能为核心的服务拆分及组织途径。此类服务采用软件方案在业务层面中的广泛实现堆栈，具体包括用户界面、持久性存储以及任何外部协作机制。因此，各团队将拥有跨职能特性，包括开发过程当中要求的全部技能组合：用户体验、数据库以及项目管理等等。 由团队边界决定的服务边界图三：由团队边界决定的服务边界 采取此类组织方式的企业实例可参见comparethemarket，其各职能团队共同负责构建并运营每款产品，而每款产品则被拆分为一系列独立的服务——且各服务间通 过一套消息收发总线实现通信。 大型整体应用程序亦可以始终围绕业务功能实际模块化，不过这种状况并不常见。诚然，我们都听说过由大型团队构建的单一整体应用程序根据自身业务线进行设计与划分。然而在这类情况下，最大的问题在于整体应用程序在组织当中需要考虑太多背景信息。如果其整体范畴当中包含太多模块边界，那么团队中的单一成员将很难通过短期记忆对其进行管理。除此之外，我们发现这种模块化业务线的维护工作还要求相关人员具备极高的专业技能水平。相比之下，服务组件能够令拆分方式更为明确，从而大大简化团队边界的设定与认知。 微服务架构有多“微”？ 尽管“微服务”早已成为一种极具人气的架构类型，但这一名称却并不能准确反映服务的实际规模——换言之，“微”服务并不一定微。在与众多微服务从业者的交流当中，我们发现服务的具体规模可谓多种多样。其中规模最大的成果源自Amazon公司旗下的“两块披萨”团队（即整个团队只需两块披萨即可填饱肚子），这意味着其总人数在十位左右。而规模较小的团队则由六人组成，负责支持六项服务。那么这就带来了新的问题：这种十二人对单项服务的机制同一人对单项服务之间存在着怎样的差别？二者也许不可一概而论。就目前而言，我们姑且认为双方属于同类团队结构，但随着对微服务认识的持续深入，也许我们未来将抱持新的观点。 产品而非项目大部分应用程序开发工作都会遵循项目模式：其目标在于交付软件方案中的特定部分，并拥有直观的完成指标。在软件开发工作完成后，其会被传递至运维部门，这时负责构建该软件的团队也将即刻解散。 微服务的支持者们则认为这种模式并不可取——他们的主张是相关团队应该伴随产品走过整个生命周期。这方面最典型的例子应该是Amazon公司提出的“谁构建，谁运行”原则，其中开发团队需要对生产环境下的软件成果承担全部责任。这就要求开发人员在日常工作中全程关注其软件的生产运行情况，同时掌握来自用户的反馈意见，意味着他们需要在一定程度上为用户提供技术支持服务。 产品的定位应始终与业务功能相协调。相较于以往将软件视为一整套已经完成的功能集的心态，微服务架构要求我们全程与之保持关联，并思考该软件能够如何协助用户加强业务功能。 当然，我们完全可以将同样的思路引入整体应用程序当中，不过大量小型服务集合能够显著简化服务开发人员与及用户之间的个人联系。 智能化端点与傻瓜式流程在跨越不同进程构建通信结构时，我们发现很多产品及方案会直接把智能化机制塞进通信机制本体当中。这方面的典型实例就是企业服务总线（简称ESB），ESB产品当中通常包含复杂度极高的消息跌幅、编排、转换以及业务规则应用等机制。 微服务社区则倾向于使用另一种实现方式：智能化端点与傻瓜式流程。采用微服务架构的应用程序旨在尽可能实现解耦化与关联性——它们各自拥有自己的域逻辑，而且在经典Unix场景下的运作方式更像是过滤器机制——接收请求、应用合适的逻辑并生成响应。这一切都通过简单的REST类协议实现编排，而非经由WS-Choreography或者BPEL等复杂协议以及中央编排工具实现。 目前最常用的两类协议为配合源API的HTTP请求-响应与轻量化消息收发协议 6 。对于前者，最简练而准确的说明是： 立足于Web，而非居于Web背后。– Ian Robinson 微服务团队采用的正是万维网（在很大程度上亦包括Unix在内）所遵循的原则与协议。一般来讲，其使用的资源能够为开发人员或者运维人员轻松实现缓存处理。 第二类作法则是立足于轻量化消息总线实现消息收发。这类基础设施选项通常具备傻瓜式特性（这种傻瓜特性体现在实现操作上，即只需匹配消息路由机制，再无其它）——以RabbitMQ或者ZeroMQ为代表的简单实现方案仅仅需要提供一套可靠的异步结构，而服务的全部智能化元素仍然存在于端点当中并负责消息的生成与消费。 在整体应用程序当中，各组件在进程内执行并通过方法调用或者函数调用的方式实现彼此通信。将整体应用程序转化为微服务形式的最大难题在于改变这种通信模式。由内存内方法调用指向PC通信机制的简单转换往往无法良好起效。相反，大家需要利用粗粒度方式取代原本的细粒度通信机制。 微服务与SOA当我们探讨微服务时，经常出现的问题就是其到底是不是我们十年前就听说过的面向服务架构（简称SOA）的另一种表现形式？二者之间确实存在一定联系，因为微服务风格拥有与SOA相似的逻辑主张。然而问题在于，SOA的实际含义太过广泛，而且当我们提到所谓“SOA”时，实际所指的对象往往跟这里提到的微服务概念差之千里——具体来讲，其通常代表那些专注于利用ESB实现的集成化整体应用程序。 值得强调的是，我们也见证了大量表现糟糕的面向服务实现手段——从将复杂性隐藏在ESB当中 7 的作法，到投入多年以及数百万资金却毫无成效的尝试，再到以聚合型治理模式抑制变更，我们几乎看不到面向服务架构能够带来什么显著的积极影响。 诚然，微服务社区当中使用的不少技术成果都源自开发人员在大型企业当中积累到的集成化服务成果。Tolerant Reader模式正是其中的典型代表。对Web的运用确实带来可观回报，而使用简单协议正是经验积累的直接产物——这显然是为了解决标准汇聚所导致的高复杂性难题（无论何时，如果大家需要利用一种实体来管理其它实体，那么就意味着各位已经面临着大麻烦）。 SOA的这些弊端导致一部分微服务布道者很讨厌人们把SOA的标签加在微服务头上——尽管也有一些人认为微服务正是SOA的一种实现方式 8，或者说我们可以将微服务称为“面向服务的正确实现”。无论如何，事实上SOA含义的宽泛性意味着其更适合作为一种用于定义架构风格的术语，而非具体解决方案。 离散化治理聚合型治理的一大影响在于使得单一技术平台上出现标准化趋势。经验表明这类方案具备收缩特性——意味着各个实际问题并不能够轻松与解决方案对应起来。我们更倾向于使用正确的工具执行正确的任务，而且虽然部分整体应用程序能够发挥不同编程语言的独特优势，但这种情况并不常见。 通过将整体应用程序的各组件拆分成服务，我们能够对各服务进行分别构建。各位可能希望利用Node.js建立一套简单报告页面？照此办理即可。打算利用C++构建特定的近实时组件？没问题。打算利用不同类型的数据库以匹配单一组件的读取行为？目前的技术方案已经能够实现这种独立重构需求。 当然，我们能够实现以上目标，并不代表我们必须这么做——但对系统进行拆分意味着大家能够拥有更多备用选项。 采用微服务架构的团队倾向于以不同的方式实现所谓标准。相较于以往编写一整套定义标准集的作法，他们更乐于开发实用工具并交付给其他开发人员，从而利用其解决自身面临的类似问题。这些工具通常能够在更为广泛的层面得到实现与共享，但同时又不至于转化为排他性内部开源模式。现在git与github都已经成为客观层面的版本控制系统选项，而开源实践也越来越多地成为内部环境中的常见组成部分。 Netflix公司就是个很好的例子，他们遵循的正是这样一种理念。将具备实用性且经过严格考验的代码作为库，并鼓励其他开发人员利用其以类似的方式解决的类似的问题，这就为各团队成员在必要时选择其它工具保留了空间。共享式库专注于数据存储、进程间通信以及我们在后文中将要探讨的基础设施自动化等问题的解决。 对于微服务社区而言，资源成本显然是种不受欢迎的因素。这并不是说该社区不承认服务协议的价值。恰恰相反，这是因为他们希望构建起大量服务协议。他们希望能够采用多种完全不同的方式对这些协议进行管理。像Tolerant Reader以及Consumer-Driven Contacts这样的模式在微服务架构中非常常见。这些服务协议也各自以独立方式不断演进。将消费者驱动型协议作为构建工作组成部分的作法能够显著增强参与者信心，同时快速获取服务功能能否确切实现的反馈意见。事实上，澳大利亚的某个团队就在积极利用消费者驱动型协议进行新服务构建。他们使用的简单工具确保其能够针对单一服务实现协议定义。其甚至在面向新服务的代码被编写出来之前就已经成为自动化构建流程中的一部分。这意味着服务只有在切实满足该协议要求的前提下才能够实现构建——这就有效解决了构建新软件时经常出现的“YAGNI” [9] 难题。这些技术与工具成果围绕协议而生，并通过降低不同服务间的耦合性限制了其对中央协议管理机制的依赖。 多种语言，多种选项JVM作为平台的快速发展已经成为多种语言混成于单一通用平台内的最新明证。这种作法已经成为一类常见实践，旨在充分发挥高级语言在过去数十年中发展所实现的种种高级抽象优势。其甚至以涓滴效应影响到裸机以及通过低级语言编写的性能敏感型代码。然而，众多整体应用程序并不需要这种级别的性能优化效果，亦非常见的DSL与高级别抽象开发成果。相反，整体应用程序往往使用单一语言，这也严重限制了其能够使用的技术手段。[10] 也许离散化治理的人气正是源自Amazon方面提出的“谁构建，谁运行”原则。各团队需要为其构建的软件的各个方面承担责任，包括为软件提供24/7全天候运维支持。这种程度的责任下放当然还没有成为常态，不过我们已经看到越来越多的企业开始将责任交付至开发团队。Netflix公司亦是另一家采取这种理念 [11] 的企业。为了不至于在凌晨三点被紧急来电叫醒，开发人员们当然会全力以赴提升所编写代码的质量水平。这些思路与传统的集中化治理模式明显相去甚远。 离散化数据管理数据管理离散化拥有多种不同的表现形式。从最为抽象的级别来看，这意味着全局概念模型将在不同系统之间有所区别。这种问题常见于解决方案在大型企业当中的部署，毕竟销售团队对于客户概念的理解方式必须不同于技术支持团队的理解方式。被销售人员视为客户的对象也许根本不会出现的技术支持团队的视野当中。不同属性甚至是相同属性的不同理解方式都可能在语义层面产生细微的差异。 这一问题通常出现在不同应用程序之间甚至是应用程序之内，特别是在将应用程序拆分为多个独立组件的情况下。解决问题的一类可行思路在于基于背景边界化的区域驱动型设计（简称DDD）方案。DDD机制将一个复杂的区域拆分成多个具备边界的背景单元，并对各单元之间的关系加以映射。这种方式同时适用于整体与微服务架构，但服务与背景边界间的自然关联性有助于声明我们曾在业务功能章节中提到过的区分效果。 除了对概念模式进行离散化处理，微服务同时也能够拆分数据存储决策。尽管整体性应用程序倾向于使用单一逻辑数据库保存持久性数据，但企业通常更乐于利用单一数据库涵盖一系列应用程序——而且大多数此类决策立足于具体供应商提供的授权商业模式。微服务机制则选择由每项服务管理其自身数据库的方式，而非不同实例基于同一数据库技术或者完全使用多种不同数据库系统——这种方式亦被称为混合持久化。大家可以利用混合持久化方案打理整体应用程序，但其在微服务架构中的亮相频率明显更高一些。 对微服务架构内数据责任关系的离散化处理也影响到了更新管理工作。常见的更新处理方案是在更新多种资源时，利用事务处理机制来保证其一致性。这种方式通常被用于整体性应用程序汉中。 这种事务处理使用方式确实有助于保障一致性，但却会带来显著的临时性耦合效果，而这在跨越多项服务时会带来新的难题。分布式事务处理非常难以实现，因此微服务架构更强调服务之间的事务处理协调性，同时明确强调只需保障最终一致性并通过补偿运算解决其中的冲突问题。 利用这种方式管理一致性问题已经成为众多开发团队的新困境，但其却能够切实匹配业务实践。一般来讲，企业需要保留一定程度的不一致性以实现某种程度的逆转能力，从而利用快速响应处理错误状况。这种权衡有其必要性，只要确定失误成本要低于高一致性条件下可能造成的业务损失成本即可。 实践性规范与执行标准这种态度实际有点二分法的意味：微服务团队倾向于回避由企业架构部门制定的硬性执行标准，但却乐于使用甚至积极推广HTTP、ATOM以及其它微格式开放标准。 二者之间的本质区别在于标准的开发方式以及执行方式。由IETF等组织管理的标准只会在得到广泛采用之后才能真正成为业界规范，而且其往往脱胎自成功的开源项目。 这些标准拥有与商业世界完全不同的立场与定位——事实上，商业标准的制定工作往往由那些几乎不具备编程经验的团队所负责，或者受到具体厂商的过度影响。 基础设施自动化基础设施自动化技术在过去几年中得到了长足发展——而云与AWS的演进则显著降低了构建、部署及运维微服务架构所带来的复杂性水平。 大部分利用微服务机制构建的产品或者系统都是由具备丰富的持续交付及其前者——持续集成——经验的团队所完成。通过这种方式构建软件的团队能够充分发挥基础设施自动化技术成果的潜在能力。我们可以将整个流程整理成以下图表： 基本构建流程图五：基本构建流程 整体应用程序的构建、测试与推送流程能够在此类环境下顺利完成。事实证明，一旦大家利用自动化流程进行整体应用开发，那么部署更多应用程序也将成为顺理成章的轻松任务。请记住，持续交付的目标之一就是令部署变得无脑化，这意味着无论是一款应用还是三款，其实际部署流程都不会有什么区别 [12]。 我们还发现，不少团队在利用这种广泛的基础设施自动化能力管理生产环境下的微服务架构。相较于前面提到的整体与微服务应用在部署层面并没有太大区别，实际运维环境下的具体条件则存在着巨大差异。 模块部署的具体方式往往差别巨大 图六：模块部署的具体方式往往差别巨大 让正确决定更易于执行 作为一项连带效应，我们发现实现持续交付与部署能够帮助开发人员及运维人员创造出高实用性工具。这类工具能够创建artifact、管理代码库、建立简单服务或者实现标准监控与记录等常见功能。这方面最典型的实例当数Netflix公司发布的一系列开源工具，险些之外Dropwizard等方案亦得到广泛使用。 故障应对设计将服务作为组件加以使用的结果之一在于，应用程序需要经过针对性设计以确保其具备服务故障容错能力。任何服务调用都有可能因为供应程序不可用而发生问题。在这种情况下，客户端必须要尽可能做出适当的回应。相较于整体应用程序来说，服务即组件机制会增加额外的处理复杂性，这也是微服务架构的一大弊端。在这种情况下，微服务团队需要不断审视服务故障对用户体验造成的影响。Netflix公司的“猴子军团”项目就专门负责在正常运营期间对服务进行破坏，甚至利用数据中心故障来测试应用程序的弹性及监控能力。 这类自动化测试机制往往会令正等待周末下班的运维团队们感到不寒而慄。这并不是说整体架构风格就无法使用高复杂性监控机制——只不过这种情况确实不太常见。 由于服务随时可能发生故障，因此最重要的就是保持对故障的快速检测能力，并在可能的情况下对其进行自动恢复。微服务应用程序高度强调对应用程序的实时监控能力，同时不断对架构元素（数据库每秒钟接收到的请求数量）以及业务相关指标（例如每分钟收到的订单数量）进行记录。语义监控能够通过早期预警系统抢先一步做出警示，并引导开发团队对问题加以跟进与调查。 这一点对于微服务架构尤为重要，因为微服务更倾向于采用由编排及事件协作实现的应急处理方式。尽管很多专家都对应急处理方案偶尔带来的收益表示认同，但其实际上往往也是让事情变糟的罪魁祸首。为了及时阻断糟糕的应急处理并确保其拥有可恢复性，监控系统就变得极为重要。 整体应用程序的构建方式可与微服务架构同样透明——事实上也本应如此。二者的区别在于，在面对整体应用时我们需要在确切了解其运行在不同进程中的服务何时发生断开。考虑到同一进程当中可能包含多套库，这种透明度水平实际上很难实现。 微服务团队需要利用复杂的监控与记录机制处理各项服务，例如通过仪表板显示上线/下线状态以及一系列运营与业务相关指标。另外，我们还需要面对断路器状态、当前数据吞吐量以及延迟等其它常见的衡量数据。 演进设计断路器与可交代生产环境之代码 断路器模式出现在Amazon的Release It!当中，其中提到的其它模式还包括隔板模式与超时模式等。在加以结合之后，这些模式将在构建通信应用方面发挥巨大作用。Netflix公司发布的一系列博文就很好地解释了他们对这些模式选项的具体使用方式。 演进设计微服务从业者通常都具备演进设计工作背景，并将服务拆分视为一种深入型工具，旨在帮助应用程序开发人员在无需拖慢变更速度的前提下实现面向应用程序的变更控制。变更控制并不一定意味着变更数量削减——配合正确的态度与工具，大家完全可以帮助软件提供快速、频繁且经过良好控制的变更。 当尝试将一套软件系统拆分为多个组件时，我们往往面临着与具体拆分工作相关的决策任务——即我们应该遵循怎样的方针对应用程序进行拆分？而组件中的关键属性则在于其独立替换与可升级特性 [13] ——这意味着我们要找到确切的平衡点，保证自身能够在不影响其它协作对象的前提下对单一组件进行重写。事实上，很多微服务团队会更进一步，直接清退某些服务而非对其进行长期升级。 英国《卫报》网站就是个很好的例子，其应用程序在设计与构建方面作为整体应用存在，但却在逐步面向微服务架构演进。该网站的核心部分仍然属于整体性项目，但他们更倾向于通过构建微服务利用整体API实现新功能添加。这套方案对于临时性功能的实现非常重要，例如加设专题页面以显示体育赛事报道。网站中的这类组成部分能够通过快速开发语言在短时间内编写完成，并在对应事件结束后立即下线。我们还发现其它一些金融机构亦采取类似的方式公布突发性市场波动，并在数周或者数月之后将其下线。 这也强调了可替换性在模块化设计中的重要地位，其主旨正在于将模块机制贯彻整个变更模式 [14] 。大家希望只变更其中必须变更的部分，而其它模块则继续保持原样。系统当中那些几乎很少变动的部分应该立足于不同于高变更频率组件的服务。如果大家发现自己经常需要同时对两项服务做出变更，那么明显应该将二者加以合并。 将组件纳入服务也让我们能够以更高的细粒度水平进行规划制定。在整体应用程序当中，任何一项变更都需要对应用整体进行重构与重新部署。但在微服务架构方面，我们只需要重新部署包含对应变更的服务。这能够显著简化并加快发布流程。不过其弊端在于，我们必须考虑针对单一服务的变更是否会影响到其它服务。传统的整体性方案能够通过版本控制解决这类难题，但微服务领域则倾向于将版本控制作为最后一种应急办法。我们可以通过设计保证服务拥有强大的容错能力，从而应对其供应程序中出现的各类代码修改。 同步调用殊不可取 无论何时时，一旦在不同服务之间进行多次同步调用，那么可能引发宕机的概率也会以乘法形式增长。简单来讲，系统的总体宕机时间为各单个部件宕机时间的乘积。这时我们就面临着具体选择，到底是以异步方式进行调用，还是以计划方式管理由同步调用带来的宕机时间。英国《卫报》网站在其全新平台上执行了一项简单的规则——每个用户请求对应一次同步调用，而Netflix公司所使用的API则经历重新设计，确保其结构内采用异步调用机制。 微服务是否代表着未来？我们撰写这篇文章的主要目的在于解释微服务架构的基本思路与原则。而在撰写过程当中，我们明确意识到微服务架构风格确实是一项值得重视的关键成果——企业级应用程序开发人员应当对其加以了解。我们最近利用该架构构建了多套系统，而且了解到亦有其它多家企业将其纳入业务体系。 我们了解到的微服务架构先驱企业包括Amazon、Netflix、英国《卫报》、英国政府数字化服务局、realestate.com.au、Forward以及comparethemarket.com等等。2013年召开的相关会议则公布了更多参与其中的重要厂商。除此之外，另有相当一部分企业一直在使用类似的实现思路——但却并没有使用‘微服务’这样的称谓。（其通常将其冠以SOA标签——不过正如我们之前提到，SOA是一类存在大量矛盾取向的概念组合。[15] ） 尽管拥有这些积极的经验，但我们仍然无法完全肯定微服务架构就代表着软件未来的发展方向。虽然我们的实际经历证明微服务架构截至目前仍拥有优于整体性应用程序的积极优势，但必须承认只有充分的时间积累才能帮助我们做出真正完整则准确的判断结论。 我们的同事Sam Newman曾于2014年倾尽心力撰写出这本关于我们如何构建微服务架构类应用的论著。如果大家希望进一步探讨这个议题，请千万不要错过。 通常来说，架构决策的实际影响可能需要几年之后才能逐步显现出来。我们已经看到不少优秀的团队带着巨大的热情与愿景而投入工作，但最终却构建起一套陈旧不堪的整体性架构。很多人认为同样的情况不太可能发生在微服务架构身上，因为其服务边界非常明确因此不太可能发生相互影响。但由于时间尚短且系统程度不足，我们目前还无法真正评估微服务架构的成熟度水平。 人们对微服务成熟度抱持的怀疑态度也有其理由。在任何组件化尝试工作当中，最终结果的成功与否都取决于该软件与拆分后组件的契合效果。我们目前仍然很难说明组件边界的选择原则。演进设计导致边界划分变得非常困难，因此最重要的是保证其重构的简易性。但一旦将组件作为服务处理以实现远程通信，那么其重构难度将远远高于进程内库。在不同服务边界之间进行代码移动难度极大，而任何接口变更都需要在不同相关服务间实现，同时添加层的向下兼容能力，这无疑会令测试工作更加复杂。 另一大问题在于，如果相关组件间的关系不够简洁，那么我们就相当于把组件内部的复杂性转移到了不同组件间的连接当中。这样做不仅会导致复杂性扩散，同时亦会导致其明确性缺失且难以控制。立足于小型、简单组件审视问题总是更为直观，而在不同服务间进行纵览则往往会错失关注点。 最后，团队的技能水平也将起到决定性作用。新型技术成果往往要求高水平技术团队加以实施。不过高水平团队能够顺畅利用的技术方案并不一定能够在低水平人员手中发挥作用。我们已经见证了众多低水平团队构建起的如一团乱麻般的整体架构，但仍需要时间来了解微服务架构是否会在同样的情况下引发同样的状况。诚然，糟糕的团队创建出的始终只能是糟糕的系统——但我们不知道微服务架构到底是会缓解这种状况，还是令状况更中惨不忍睹。 目前有一种较为理性的论调，认为我们不应将微服务架构作为起步方案。相反，大家可以从整体性开发风格出发，保证其结合模块化机制，并在整体性特征引发实际问题后逐步将其拆分为微服务形式。（不过这样的建议并非完全理想，因为良好的进程内接口往往并不能成为良好的服务接口。） 因此我们对此抱持谨慎的乐观态度。到目前为止，我们已经了解到关于微服务架构的方方面面，而且其应该能够成为一种极具价值的开发手段。虽然还不能做出最终判断，但软件开发工作的固有挑战之一，正是我们只能根据目前掌握的远称不上完美的信息做出决策。 脚注1: “微服务”一词最早被威尼斯附近的一个软件架构师小组于2011年5月首次提及，当时他们用这个词汇来描述自己近期研究项目当中所涉及的通用性架构机制。2012年5月，该小组作出最终决议，认为“微服务”是最适合的架构名称。2012年3月，James在《微服务-Java以及Unix方式》当中就此发表了一篇案例研究报告，而Fred George也几乎在同一时间进行了相同的工作。Netflix公司的Adrian Cockcroft将微服务架构称为“细化SOA”，并认为这是一套在Web规模下具备开创意义的架构类型。Joe Walnes、Dan North、Evan Botcher以及Graham Tackley也分别在这篇文章中对此作出了评论。 2: 文章中所使用的“整体”一词长久以来一直被Unix业界所使用。其首次出现在《Unix编程艺术》一书中，用于描述那些过于庞大的系统方案。 3: 很多面向对象设计人员，也包括我们自己，都会在域驱动设计当中使用“服务对象”这一表述，专指那些并不具备实质性联系但却拥有重要作用的对象。这与我们在本文中所使用的“服务”一词在表意上完全不同。遗憾的是，服务这个词汇同时具备两种含义，而我们对这种多义词也没有更好的处理办法。 4: 我们将一款应用程序视为一套社会性体系，其中融合了代码库、函数组以及供应主体。 5: 大家可以查看梅尔文 康韦网站上的原文论述。 6: 对于规模极为庞大的应用体系，企业通常会采用二进制协议——例如protobufs。使用二进制协议的系统仍然符合智能化端点与傻瓜式通道的特性——并为了规模化而在透明度方面作出妥协。不过大多数Web方案与绝大多数企业不需要在这方面考虑太多——一般来讲，透明度越高、效果就越好。 7: 虽然无关紧要，但Jim Webber曾经将ESB解释成“Egregious Spaghetti Box”，也就是“恐怖意面盒”。 8: Netflix公司最近将其架构类型称为“细化SOA”。 9: “YAGNI”的全称是“You Aren’t Going To Need It（你根本不需要它）”，这是一项经典的用户体验原则，即不要自作聪明地添加非必要性功能。 10: 我们所宣称的整体型应用只支持单一语言确实有些不尽不实——在当下的Web系统构建过程中，大家可能需要掌握JavaScript、XHTML以及CSS，而在服务器端的语言选项则包括SQL以及某种ORM（即对象关系映射）衍生语言。没错，单一语言肯定玩不转，但我相信大家明白我想要强调的意思。 11: Adrian Cockcroft在2013年11月的Flowcon大会上作出了精彩演讲，并特别提到了“开发者自助服务”与“开发者应亲自运行所编写代码”的观点。 12: 我们在这里的说法并不准确。很明显，在更为复杂的拓扑结构中部署大量服务肯定要比在单一整体型架构内进行部署困难得多。幸运的是，各类模式能够显著降低这种复杂性——当然，在工具方面的投入仍然不可或缺。 13: 事实上，Dan North将这种类型称为“可替代式组件架构”而非微服务架构。由于其强调内容属于微服务架构的一类子集，所以我们更倾向于使用后一种表达方式。 14: Kent Beck将此作为其《实施模式》一文中的设计原则之一。 15: SOA几乎是此类架构的历史起源。我记得当SOA一词在本世纪初刚刚出现时，很多人表示“我们几年前就已经将其引入日常工作了”。也有意见认为这种架构类型似乎最早出现于早期企业计算当中，COBOL程序通过数据文件实现通信的处理机制。而在另一方面，也有人认为微服务架构与Erlang编程模型其实是同一回事，不过后者只被应用在企业应用程序当中。 Microservicesa definition of this new architectural term The term “Microservice Architecture” has sprung up over the last few years to describe a particular way of designing software applications as suites of independently deployable services. While there is no precise definition of this architecural style, there are certain commom characteristics around organization around business capablity, automated deployment, intelligence in the endpoints, and decentralized control of languages and data. Microservices “Microservices” - yet another new term on the crowded streets of software architecture. Although our natural inclination is to pass such things by with a contemptuous glance, this bit of terminology describes a style of software systems that we are finding more and more appealing. We’ve seen many projects use this style in the last few years, and results so far have been positive, so much so that for many of our colleagues this is becoming the default style for building enterprise applications. Sadly, however, there’s not much information that outlines what the microservice style is and how to do it. In short, the microservice architectural style 1 is an approach to developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanisms, often an HTTP resource API. These services are built around business capabilities and independently deployable by fully automated deployment machinery. There is a bare minimum of centralized management of these services, which may be written in different programming languages and use different data storage technologies. To start explaining the microservice style it’s useful to compare it to the monolithic style: a monolithic application built as a single unit. Enterprise Applications are often built in three main parts: a client-side user interface (consisting of HTML pages and javascript running in a browser on the user’s machine) a database (consisting of many tables inserted into a common, and usually relational, database management system), and a server-side application. The server-side application will handle HTTP requests, execute domain logic, retrieve and update data from the database, and select and populate HTML views to be sent to the browser. This server-side application is a monolith - a single logical executable 2. Any changes to the system involve building and deploying a new version of the server-side application. Such a monolithic server is a natural way to approach building such a system. All your logic for handling a request runs in a single process, allowing you to use the basic features of your language to divide up the application into classes, functions, and namespaces. With some care, you can run and test the application on a developer’s laptop, and use a deployment pipeline to ensure that changes are properly tested and deployed into production. You can horizontally scale the monolith by running many instances behind a load-balancer. Monolithic applications can be successful, but increasingly people are feeling frustrations with them - especially as more applications are being deployed to the cloud . Change cycles are tied together - a change made to a small part of the application, requires the entire monolith to be rebuilt and deployed. Over time it’s often hard to keep a good modular structure, making it harder to keep changes that ought to only affect one module within that module. Scaling requires scaling of the entire application rather than parts of it that require greater resource. Monoliths and MicroservicesFigure 1: Monoliths and Microservices These frustrations have led to the microservice architectural style: building applications as suites of services. As well as the fact that services are independently deployable and scalable, each service also provides a firm module boundary, even allowing for different services to be written in different programming languages. They can also be managed by different teams . We do not claim that the microservice style is novel or innovative, its roots go back at least to the design principles of Unix. But we do think that not enough people consider a microservice architecture and that many software developments would be better off if they used it. Characteristics of a Microservice ArchitectureWe cannot say there is a formal definition of the microservices architectural style, but we can attempt to describe what we see as common characteristics for architectures that fit the label. As with any definition that outlines common characteristics, not all microservice architectures have all the characteristics, but we do expect that most microservice architectures exhibit most characteristics. While we authors have been active members of this rather loose community, our intention is to attempt a description of what we see in our own work and in similar efforts by teams we know of. In particular we are not laying down some definition to conform to. Componentization via Services For as long as we’ve been involved in the software industry, there’s been a desire to build systems by plugging together components, much in the way we see things are made in the physical world. During the last couple of decades we’ve seen considerable progress with large compendiums of common libraries that are part of most language platforms. When talking about components we run into the difficult definition of what makes a component. Our definition is that a component is a unit of software that is independently replaceable and upgradeable. Microservice architectures will use libraries, but their primary way of componentizing their own software is by breaking down into services. We define libraries as components that are linked into a program and called using in-memory function calls, while services are out-of-process components who communicate with a mechanism such as a web service request, or remote procedure call. (This is a different concept to that of a service object in many OO programs 3.) One main reason for using services as components (rather than libraries) is that services are independently deployable. If you have an application 4 that consists of a multiple libraries in a single process, a change to any single component results in having to redeploy the entire application. But if that application is decomposed into multiple services, you can expect many single service changes to only require that service to be redeployed. That’s not an absolute, some changes will change service interfaces resulting in some coordination, but the aim of a good microservice architecture is to minimize these through cohesive service boundaries and evolution mechanisms in the service contracts. Another consequence of using services as components is a more explicit component interface. Most languages do not have a good mechanism for defining an explicit Published Interface. Often it’s only documentation and discipline that prevents clients breaking a component’s encapsulation, leading to overly-tight coupling between components. Services make it easier to avoid this by using explicit remote call mechanisms. Using services like this does have downsides. Remote calls are more expensive than in-process calls, and thus remote APIs need to be coarser-grained, which is often more awkward to use. If you need to change the allocation of responsibilities between components, such movements of behavior are harder to do when you’re crossing process boundaries. At a first approximation, we can observe that services map to runtime processes, but that is only a first approximation. A service may consist of multiple processes that will always be developed and deployed together, such as an application process and a database that’s only used by that service. Organized around Business Capabilities When looking to split a large application into parts, often management focuses on the technology layer, leading to UI teams, server-side logic teams, and database teams. When teams are separated along these lines, even simple changes can lead to a cross-team project taking time and budgetary approval. A smart team will optimise around this and plump for the lesser of two evils - just force the logic into whichever application they have access to. Logic everywhere in other words. This is an example of Conway’s Law 5 in action. Any organization that designs a system (defined broadly) will produce a design whose structure is a copy of &gt; the organization’s communication structure. – Melvyn Conway, 1967 Service boundaries reinforced by team boundariesFigure 2: Conway’s Law in action The microservice approach to division is different, splitting up into services organized around business capability. Such services take a broad-stack implementation of software for that business area, including user-interface, persistant storage, and any external collaborations. Consequently the teams are cross-functional, including the full range of skills required for the development: user-experience, database, and project management. Service boundaries reinforced by team boundariesFigure 3: Service boundaries reinforced by team boundaries One company organised in this way is comparethemarket. Cross functional teams are responsible for building and operating each product and each product is split out into a number of individual services communicating via a message bus. Large monolithic applications can always be modularized around business capabilities too, although that’s not the common case. Certainly we would urge a large team building a monolithic application to divide itself along business lines. The main issue we have seen here, is that they tend to be organised around too many contexts. If the monolith spans many of these modular boundaries it can be difficult for individual members of a team to fit them into their short-term memory. Additionally we see that the modular lines require a great deal of discipline to enforce. The necessarily more explicit separation required by service components makes it easier to keep the team boundaries clear. How big is a microservice? Although “microservice” has become a popular name for this architectural style, its name does lead to an unfortunate focus on the size of service, and arguments about what constitutes “micro”. In our conversations with microservice practitioners, we see a range of sizes of services. The largest sizes reported follow Amazon’s notion of the Two Pizza Team (i.e. the whole team can be fed by two pizzas), meaning no more than a dozen people. On the smaller size scale we’ve seen setups where a team of half-a-dozen would support half-a-dozen services. This leads to the question of whether there are sufficiently large differences within this size range that the service-per-dozen-people and service-per-person sizes shouldn’t be lumped under one microservices label. At the moment we think it’s better to group them together, but it’s certainly possible that we’ll change our mind as we explore this style further. Products not Projects Most application development efforts that we see use a project model: where the aim is to deliver some piece of software which is then considered to be completed. On completion the software is handed over to a maintenance organization and the project team that built it is disbanded. Microservice proponents tend to avoid this model, preferring instead the notion that a team should own a product over its full lifetime. A common inspiration for this is Amazon’s notion of “you build, you run it” where a development team takes full responsibility for the software in production. This brings developers into day-to-day contact with how their software behaves in production and increases contact with their users, as they have to take on at least some of the support burden. The product mentality, ties in with the linkage to business capabilities. Rather than looking at the software as a set of functionality to be completed, there is an on-going relationship where the question is how can software assist its users to enhance the business capability. There’s no reason why this same approach can’t be taken with monolithic applications, but the smaller granularity of services can make it easier to create the personal relationships between service developers and their users. Smart endpoints and dumb pipes When building communication structures between different processes, we’ve seen many products and approaches that stress putting significant smarts into the communication mechanism itself. A good example of this is the Enterprise Service Bus (ESB), where ESB products often include sophisticated facilities for message routing, choreography, transformation, and applying business rules. The microservice community favours an alternative approach: smart endpoints and dumb pipes. Applications built from microservices aim to be as decoupled and as cohesive as possible - they own their own domain logic and act more as filters in the classical Unix sense - receiving a request, applying logic as appropriate and producing a response. These are choreographed using simple RESTish protocols rather than complex protocols such as WS-Choreography or BPEL or orchestration by a central tool. The two protocols used most commonly are HTTP request-response with resource API’s and lightweight messaging 6. The best expression of the first is Be of the web, not behind the web – Ian Robinson Microservice teams use the principles and protocols that the world wide web (and to a large extent, Unix) is built on. Often used resources can be cached with very little effort on the part of developers or operations folk. The second approach in common use is messaging over a lightweight message bus. The infrastructure chosen is typically dumb (dumb as in acts as a message router only) - simple implementations such as RabbitMQ or ZeroMQ don’t do much more than provide a reliable asynchronous fabric - the smarts still live in the end points that are producing and consuming messages; in the services. In a monolith, the components are executing in-process and communication between them is via either method invocation or function call. The biggest issue in changing a monolith into microservices lies in changing the communication pattern. A naive conversion from in-memory method calls to RPC leads to chatty communications which don’t perform well. Instead you need to replace the fine-grained communication with a coarser -grained approach. Microservices and SOA When we’ve talked about microservices a common question is whether this is just Service Oriented Architecture (SOA) that we saw a decade ago. There is merit to this point, because the microservice style is very similar to what some advocates of SOA have been in favor of. The problem, however, is that SOA means too many different things, and that most of the time that we come across something called “SOA” it’s significantly different to the style we’re describing here, usually due to a focus on ESBs used to integrate monolithic applications. In particular we have seen so many botched implementations of service orientation - from the tendency to hide complexity away in ESB’s 7, to failed multi-year initiatives that cost millions and deliver no value, to centralised governance models that actively inhibit change, that it is sometimes difficult to see past these problems. Certainly, many of the techniques in use in the microservice community have grown from the experiences of developers integrating services in large organisations. The Tolerant Reader pattern is an example of this. Efforts to use the web have contributed, using simple protocols is another approach derived from these experiences - a reaction away from central standards that have reached a complexity that is, frankly, breathtaking. (Any time you need an ontology to manage your ontologies you know you are in deep trouble.) This common manifestation of SOA has led some microservice advocates to reject the SOA label entirely, although others consider microservices to be one form of SOA 8, perhaps service orientation done right. Either way, the fact that SOA means such different things means it’s valuable to have a term that more crisply defines this architectural style. Decentralized Governance One of the consequences of centralised governance is the tendency to standardise on single technology platforms. Experience shows that this approach is constricting - not every problem is a nail and not every solution a hammer. We prefer using the right tool for the job and while monolithic applications can take advantage of different languages to a certain extent, it isn’t that common. Splitting the monolith’s components out into services we have a choice when building each of them. You want to use Node.js to standup a simple reports page? Go for it. C++ for a particularly gnarly near-real-time component? Fine. You want to swap in a different flavour of database that better suits the read behaviour of one component? We have the technology to rebuild him. Of course, just because you can do something, doesn’t mean you should - but partitioning your system in this way means you have the option. Teams building microservices prefer a different approach to standards too. Rather than use a set of defined standards written down somewhere on paper they prefer the idea of producing useful tools that other developers can use to solve similar problems to the ones they are facing. These tools are usually harvested from implementations and shared with a wider group, sometimes, but not exclusively using an internal open source model. Now that git and github have become the de facto version control system of choice, open source practices are becoming more and more common in-house . Netflix is a good example of an organisation that follows this philosophy. Sharing useful and, above all, battle-tested code as libraries encourages other developers to solve similar problems in similar ways yet leaves the door open to picking a different approach if required. Shared libraries tend to be focused on common problems of data storage, inter-process communication and as we discuss further below, infrastructure automation. For the microservice community, overheads are particularly unattractive. That isn’t to say that the community doesn’t value service contracts. Quite the opposite, since there tend to be many more of them. It’s just that they are looking at different ways of managing those contracts. Patterns like Tolerant Reader and Consumer-Driven Contracts are often applied to microservices. These aid service contracts in evolving independently. Executing consumer driven contracts as part of your build increases confidence and provides fast feedback on whether your services are functioning. Indeed we know of a team in Australia who drive the build of new services with consumer driven contracts. They use simple tools that allow them to define the contract for a service. This becomes part of the automated build before code for the new service is even written. The service is then built out only to the point where it satisfies the contract - an elegant approach to avoid the ‘YAGNI’ [9] dilemma when building new software. These techniques and the tooling growing up around them, limit the need for central contract management by decreasing the temporal coupling between services. Many languages, many options The growth of JVM as a platform is just the latest example of mixing languages within a common platform. It’s been common practice to shell-out to a higher level language to take advantage of higher level abstractions for decades. As is dropping down to the metal and writing performance sensitive code in a lower level one. However, many monoliths don’t need this level of performance optimisation nor are DSL’s and higher level abstractions that common (to our dismay). Instead monoliths are usually single language and the tendency is to limit the number of technologies in use [10]. Perhaps the apogee of decentralised governance is the build it / run it ethos popularised by Amazon. Teams are responsible for all aspects of the software they build including operating the software 24/7. Devolution of this level of responsibility is definitely not the norm but we do see more and more companies pushing responsibility to the development teams. Netflix is another organisation that has adopted this ethos [11]. Being woken up at 3am every night by your pager is certainly a powerful incentive to focus on quality when writing your code. These ideas are about as far away from the traditional centralized governance model as it is possible to be. Decentralized Data Management Decentralization of data management presents in a number of different ways. At the most abstract level, it means that the conceptual model of the world will differ between systems. This is a common issue when integrating across a large enterprise, the sales view of a customer will differ from the support view. Some things that are called customers in the sales view may not appear at all in the support view. Those that do may have different attributes and (worse) common attributes with subtly different semantics. This issue is common between applications, but can also occur within applications, particular when that application is divided into separate components. A useful way of thinking about this is the Domain-Driven Design notion of Bounded Context. DDD divides a complex domain up into multiple bounded contexts and maps out the relationships between them. This process is useful for both monolithic and microservice architectures, but there is a natural correlation between service and context boundaries that helps clarify, and as we describe in the section on business capabilities, reinforce the separations. As well as decentralizing decisions about conceptual models, microservices also decentralize data storage decisions. While monolithic applications prefer a single logical database for persistant data, enterprises often prefer a single database across a range of applications - many of these decisions driven through vendor’s commercial models around licensing. Microservices prefer letting each service manage its own database, either different instances of the same database technology, or entirely different database systems - an approach called Polyglot Persistence. You can use polyglot persistence in a monolith, but it appears more frequently with microservices. Decentralizing responsibility for data across microservices has implications for managing updates. The common approach to dealing with updates has been to use transactions to guarantee consistency when updating multiple resources. This approach is often used within monoliths. Using transactions like this helps with consistency, but imposes significant temporal coupling, which is problematic across multiple services. Distributed transactions are notoriously difficult to implement and and as a consequence microservice architectures emphasize transactionless coordination between services, with explicit recognition that consistency may only be eventual consistency and problems are dealt with by compensating operations. Choosing to manage inconsistencies in this way is a new challenge for many development teams, but it is one that often matches business practice. Often businesses handle a degree of inconsistency in order to respond quickly to demand, while having some kind of reversal process to deal with mistakes. The trade-off is worth it as long as the cost of fixing mistakes is less than the cost of lost business under greater consistency. Battle-tested standards and enforced standards It’s a bit of a dichotomy that microservice teams tend to eschew the kind of rigid enforced standards laid down by enterprise architecture groups but will happily use and even evangelise the use of open standards such as HTTP, ATOM and other microformats. The key difference is how the standards are developed and how they are enforced. Standards managed by groups such as the IETF only become standards when there are several live implementations of them in the wider world and which often grow from successful open-source projects. These standards are a world apart from many in a corporate world, which are often developed by groups that have little recent programming experience or overly influenced by vendors. Infrastructure Automation Infrastructure automation techniques have evolved enormously over the last few years - the evolution of the cloud and AWS in particular has reduced the operational complexity of building, deploying and operating microservices. Many of the products or systems being build with microservices are being built by teams with extensive experience of Continuous Delivery and it’s precursor, Continuous Integration. Teams building software this way make extensive use of infrastructure automation techniques. This is illustrated in the build pipeline shown below. basic build pipelineFigure 5: basic build pipeline Since this isn’t an article on Continuous Delivery we will call attention to just a couple of key features here. We want as much confidence as possible that our software is working, so we run lots of automated tests. Promotion of working software ‘up’ the pipeline means we automate deployment to each new environment. A monolithic application will be built, tested and pushed through these environments quite happlily. It turns out that once you have invested in automating the path to production for a monolith, then deploying more applications doesn’t seem so scary any more. Remember, one of the aims of CD is to make deployment boring, so whether its one or three applications, as long as its still boring it doesn’t matter [12]. Another area where we see teams using extensive infrastructure automation is when managing microservices in production. In contrast to our assertion above that as long as deployment is boring there isn’t that much difference between monoliths and microservices, the operational landscape for each can be strikingly different. Module deployment often differsFigure 6: Module deployment often differs Make it easy to do the right thing One side effect we have found of increased automation as a consequence of continuous delivery and deployment is the creation of useful tools to help developers and operations folk. Tooling for creating artefacts, managing codebases, standing up simple services or for adding standard monitoring and logging are pretty common now. The best example on the web is probably Netflix’s set of open source tools, but there are others including Dropwizard which we have used extensively. Design for failure A consequence of using services as components, is that applications need to be designed so that they can tolerate the failure of services. Any service call could fail due to unavailability of the supplier, the client has to respond to this as gracefully as possible. This is a disadvantage compared to a monolithic design as it introduces additional complexity to handle it. The consequence is that microservice teams constantly reflect on how service failures affect the user experience. Netflix’s Simian Army induces failures of services and even datacenters during the working day to test both the application’s resilience and monitoring. This kind of automated testing in production would be enough to give most operation groups the kind of shivers usually preceding a week off work. This isn’t to say that monolithic architectural styles aren’t capable of sophisticated monitoring setups - it’s just less common in our experience. Since services can fail at any time, it’s important to be able to detect the failures quickly and, if possible, automatically restore service. Microservice applications put a lot of emphasis on real-time monitoring of the application, checking both architectural elements (how many requests per second is the database getting) and business relevant metrics (such as how many orders per minute are received). Semantic monitoring can provide an early warning system of something going wrong that triggers development teams to follow up and investigate. This is particularly important to a microservices architecture because the microservice preference towards choreography and event collaboration leads to emergent behavior. While many pundits praise the value of serendipitous emergence, the truth is that emergent behavior can sometimes be a bad thing. Monitoring is vital to spot bad emergent behavior quickly so it can be fixed. Monoliths can be built to be as transparent as a microservice - in fact, they should be. The difference is that you absolutely need to know when services running in different processes are disconnected. With libraries within the same process this kind of transparency is less likely to be useful. Microservice teams would expect to see sophisticated monitoring and logging setups for each individual service such as dashboards showing up/down status and a variety of operational and business relevant metrics. Details on circuit breaker status, current throughput and latency are other examples we often encounter in the wild. The circuit breaker and production ready code Circuit Breaker appears in Release It!alongside other patterns such as Bulkhead and Timeout. Implemented together, these patterns are crucially important when building communicating applications. This Netflix blog entry does a great job of explaining their application of them. Evolutionary Design Microservice practitioners, usually have come from an evolutionary design background and see service decomposition as a further tool to enable application developers to control changes in their application without slowing down change. Change control doesn’t necessarily mean change reduction - with the right attitudes and tools you can make frequent, fast, and well-controlled changes to software. Whenever you try to break a software system into components, you’re faced with the decision of how to divide up the pieces - what are the principles on which we decide to slice up our application? The key property of a component is the notion of independent replacement and upgradeability [13] - which implies we look for points where we can imagine rewriting a component without affecting its collaborators. Indeed many microservice groups take this further by explicitly expecting many services to be scrapped rather than evolved in the longer term. The Guardian website is a good example of an application that was designed and built as a monolith, but has been evolving in a microservice direction. The monolith still is the core of the website, but they prefer to add new features by building microservices that use the monolith’s API. This approach is particularly handy for features that are inherently temporary, such as specialized pages to handle a sporting event. Such a part of the website can quickly be put together using rapid development languages, and removed once the event is over. We’ve seen similar approaches at a financial institution where new services are added for a market opportunity and discarded after a few months or even weeks. This emphasis on replaceability is a special case of a more general principle of modular design, which is to drive modularity through the pattern of change [14]. You want to keep things that change at the same time in the same module. Parts of a system that change rarely should be in different services to those that are currently undergoing lots of churn. If you find yourself repeatedly changing two services together, that’s a sign that they should be merged. Putting components into services adds an opportunity for more granular release planning. With a monolith any changes require a full build and deployment of the entire application. With microservices, however, you only need to redeploy the service(s) you modified. This can simplify and speed up the release process. The downside is that you have to worry about changes to one service breaking its consumers. The traditional integration approach is to try to deal with this problem using versioning, but the preference in the microservice world is to only use versioning as a last resort. We can avoid a lot of versioning by designing services to be as tolerant as possible to changes in their suppliers. Synchronous calls considered harmful Any time you have a number of synchronous calls between services you will encounter the multiplicative effect of downtime. Simply, this is when the downtime of your system becomes the product of the downtimes of the individual components. You face a choice, making your calls asynchronous or managing the downtime. At www.guardian.co.uk they have implemented a simple rule on the new platform - one synchronous call per user request while at Netflix, their platform API redesign has built asynchronicity into the API fabric. Are Microservices the Future?Our main aim in writing this article is to explain the major ideas and principles of microservices. By taking the time to do this we clearly think that the microservices architectural style is an important idea - one worth serious consideration for enterprise applications. We have recently built several systems using the style and know of others who have used and favor this approach. Those we know about who are in some way pioneering the architectural style include Amazon, Netflix, The Guardian, the UK Government Digital Service, realestate.com.au, Forward and comparethemarket.com. The conference circuit in 2013 was full of examples of companies that are moving to something that would class as microservices - including Travis CI. In addition there are plenty of organizations that have long been doing what we would class as microservices, but without ever using the name. (Often this is labelled as SOA - although, as we’ve said, SOA comes in many contradictory forms. [15]) Despite these positive experiences, however, we aren’t arguing that we are certain that microservices are the future direction for software architectures. While our experiences so far are positive compared to monolithic applications, we’re conscious of the fact that not enough time has passed for us to make a full judgement. Often the true consequences of your architectural decisions are only evident several years after you made them. We have seen projects where a good team, with a strong desire for modularity, has built a monolithic architecture that has decayed over the years. Many people believe that such decay is less likely with microservices, since the service boundaries are explicit and hard to patch around. Yet until we see enough systems with enough age, we can’t truly assess how microservice architectures mature. There are certainly reasons why one might expect microservices to mature poorly. In any effort at componentization, success depends on how well the software fits into components. It’s hard to figure out exactly where the component boundaries should lie. Evolutionary design recognizes the difficulties of getting boundaries right and thus the importance of it being easy to refactor them. But when your components are services with remote communications, then refactoring is much harder than with in-process libraries. Moving code is difficult across service boundaries, any interface changes need to be coordinated between participants, layers of backwards compatibility need to be added, and testing is made more complicated. Another issue is If the components do not compose cleanly, then all you are doing is shifting complexity from inside a component to the connections between components. Not just does this just move complexity around, it moves it to a place that’s less explicit and harder to control. It’s easy to think things are better when you are looking at the inside of a small, simple component, while missing messy connections between services. Finally, there is the factor of team skill. New techniques tend to be adopted by more skillful teams. But a technique that is more effective for a more skillful team isn’t necessarily going to work for less skillful teams. We’ve seen plenty of cases of less skillful teams building messy monolithic architectures, but it takes time to see what happens when this kind of mess occurs with microservices. A poor team will always create a poor system - it’s very hard to tell if microservices reduce the mess in this case or make it worse. One reasonable argument we’ve heard is that you shouldn’t start with a microservices architecture. Instead begin with a monolith, keep it modular, and split it into microservices once the monolith becomes a problem. (Although this advice isn’t ideal, since a good in-process interface is usually not a good service interface.) So we write this with cautious optimism. So far, we’ve seen enough about the microservice style to feel that it can be a worthwhile road to tread. We can’t say for sure where we’ll end up, but one of the challenges of software development is that you can only make decisions based on the imperfect information that you currently have to hand. Footnotes1: The term “microservice” was discussed at a workshop of software architects near Venice in May, 2011 to describe what the participants saw as a common architectural style that many of them had been recently exploring. In May 2012, the same group decided on “microservices” as the most appropriate name. James presented some of these ideas as a case study in March 2012 at 33rd Degree in Krakow in Microservices - Java, the Unix Way as did Fred George about the same time. Adrian Cockcroft at Netflix, describing this approach as “fine grained SOA” was pioneering the style at web scale as were many of the others mentioned in this article - Joe Walnes, Dan North, Evan Botcher and Graham Tackley. 2: The term monolith has been in use by the Unix community for some time. It appears in The Art of Unix Programming to describe systems that get too big. 3: Many object-oriented designers, including ourselves, use the term service object in the Domain-Driven Design sense for an object that carries out a significant process that isn’t tied to an entity. This is a different concept to how we’re using “service” in this article. Sadly the term service has both meanings and we have to live with the polyseme. 4: We consider an application to be a social construction that binds together a code base, group of functionality, and body of funding. 5: The original paper can be found on Melvyn Conway’s website here 6: At extremes of scale, organisations often move to binary protocols - protobufs for example. Systems using these still exhibit the characteristic of smart endpoints, dumb pipes - and trade off transparency for scale. Most web properties and certainly the vast majority of enterprises don’t need to make this tradeoff - transparency can be a big win. 7: We can’t resist mentioning Jim Webber’s statement that ESB stands for “Egregious Spaghetti Box”. 8: Netflix makes the link explicit - until recently referring to their architectural style as fine-grained SOA. 9: “YAGNI” or “You Aren’t Going To Need It” is an XP principle and exhortation to not add features until you know you need them. 10: It’s a little disengenuous of us to claim that monoliths are single language - in order to build systems on todays web, you probably need to know JavaScript and XHTML, CSS, your server side language of choice, SQL and an ORM dialect. Hardly single language, but you know what we mean. 11: Adrian Cockcroft specifically mentions “developer self-service” and “Developers run what they wrote”(sic) in this excellent presentation delivered at Flowcon in November, 2013. 12: We are being a little disengenuous here. Obviously deploying more services, in more complex topologies is more difficult than deploying a single monolith. Fortunately, patterns reduce this complexity - investment in tooling is still a must though. 13: In fact, Dan North refers to this style as Replaceable Component Architecture rather than microservices. Since this seems to talk to a subset of the characteristics we prefer the latter. 14: Kent Beck highlights this as one his design principles in Implementation Patterns. 15: And SOA is hardly the root of this history. I remember people saying “we’ve been doing this for years” when the SOA term appeared at the beginning of the century. One argument was that this style sees its roots as the way COBOL programs communicated via data files in the earliest days of enterprise computing. In another direction, one could argue that microservices are the same thing as the Erlang programming model, but applied to an enterprise application context.","tags":[{"name":"微服务","slug":"微服务","permalink":"http://yoursite.com/tags/微服务/"}]}]